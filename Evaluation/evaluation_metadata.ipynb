{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da421a1a",
   "metadata": {},
   "source": [
    "# Evaluation of KeyBERTMetadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a77813",
   "metadata": {},
   "source": [
    "This notebook evaluates and compares two different models:\n",
    "\n",
    "- **Base**: the standard KeyBERT model\n",
    "- **Metadata-enhanced**: an extended version, called *KeyBERTMetadata*, which integrates contextual information from the review metadata.\n",
    "\n",
    "Each model predicts a ranked list of top-5 keywords for each review. However, all evaluations in this notebook are **performed globally**, by aggregating predictions across all reviews of the same movie.\n",
    "\n",
    "The notebook uses:\n",
    "- A **ground truth dataset** containing annotated keywords per movie, derived from IMDB.\n",
    "- **Model predictions**: for each movie, a set of predicted keywords with associated confidence scores is extracted across all reviews.\n",
    "\n",
    "We conduct three types of global evaluation:\n",
    "\n",
    "#### **1. Basic (Unweighted) Metrics**\n",
    "\n",
    "- **Precision**, **Recall**, and **F1-score** are computed based on exact (normalized) string matching between predicted and ground truth keywords.\n",
    "- Predictions are aggregated across all reviews, and metrics are calculated on the global set of unique keywords per model.\n",
    "\n",
    "#### **2. Score-Aware Metrics**\n",
    "\n",
    "- **Weighted Precision, Recall, and F1-score**: keywords are matched against ground truth, weighting each match by the model’s confidence score.\n",
    "- **nDCG@5** (Normalized Discounted Cumulative Gain): evaluates how well the model ranks relevant keywords within its top-5 predictions.\n",
    "\n",
    "#### **3. Semantic Evaluation (Embedding-Based)**\n",
    "\n",
    "- Predicted and ground truth keywords are encoded using **sentence-transformer embeddings**.\n",
    "- **Cosine similarity** is used to identify soft matches between keywords.\n",
    "- A predicted keyword is considered correct if its similarity with any ground truth keyword exceeds a threshold (e.g., 0.75).\n",
    "- Based on these matches, we compute **semantic precision, recall, and F1-score**.\n",
    "\n",
    "**Why Not Use BERTScore?**\n",
    "\n",
    "Although **BERTScore** is a powerful metric for evaluating textual similarity, it is designed for **long-form text comparisons** (e.g., sentences or summaries). It is **not appropriate for evaluating keyword-level predictions**, for several reasons:\n",
    "\n",
    "- Each model generates **short keyword lists**, where token-level similarity is not meaningful.\n",
    "- BERTScore expects **equal-length** candidate and reference sequences, which is incompatible with the top-*k* keyword setting.\n",
    "- It is computationally intensive and less interpretable for sparse keyword evaluation.\n",
    "\n",
    "Instead, we adopt a **faster and more interpretable approach** using sentence embeddings and cosine similarity, tailored specifically to **keyword-level semantic evaluation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7526626c",
   "metadata": {},
   "source": [
    "## Setup: Installing and Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0baee66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas is already installed.\n",
      "numpy is already installed.\n",
      "tqdm is already installed.\n",
      "torch is already installed.\n",
      "transformers is already installed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of required packages\n",
    "required_packages = {\n",
    "    \"pandas\", \"numpy\", \"tqdm\", \"transformers\", \"torch\"\n",
    "}\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip if it's not already installed.\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"{package} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Check and install missing packages\n",
    "for package in required_packages:\n",
    "    install_package(package)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "973bef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import os      # File system operations (e.g., listing files)\n",
    "import re      # Regular expressions for text processing\n",
    "import math    # Mathematical functions (e.g., logarithms for nDCG calculation)\n",
    "\n",
    "# Third-Party Libraries\n",
    "import pandas as pd                  # Data manipulation with DataFrames\n",
    "import numpy as np                   # Numerical computations and array operations\n",
    "from tqdm import tqdm                # Progress bars for loops\n",
    "\n",
    "# Transformers and PyTorch for embeddings and models\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b9ee47",
   "metadata": {},
   "source": [
    "## Load Available Movies from Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189c179",
   "metadata": {},
   "source": [
    "This section lists all the available movies stored as `.pkl` files inside the review dataset directory.\n",
    "\n",
    "- It defines the root path (`../Dataset/Reviews_By_Movie`) where all review files are saved.\n",
    "- It automatically detects and lists all movie filenames (removing the `.pkl` extension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55796a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available movies: ['GoodBadUgly', 'HarryPotter', 'IndianaJones', 'LaLaLand', 'Oppenheimer', 'Parasite', 'SW_Episode1', 'SW_Episode2', 'SW_Episode3', 'SW_Episode4', 'SW_Episode5', 'SW_Episode6', 'SW_Episode7', 'SW_Episode8', 'SW_Episode9']\n"
     ]
    }
   ],
   "source": [
    "# Define root directory\n",
    "root_dir = \"../Dataset/Reviews_By_Movie\"\n",
    "\n",
    "# List all available movies\n",
    "available_movies = sorted([f[:-4] for f in os.listdir(root_dir) if f.endswith(\".pkl\")])\n",
    "print(\"Available movies:\", available_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3edbda1",
   "metadata": {},
   "source": [
    "## Select a Movie and Load its Ground Truth Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42602be9",
   "metadata": {},
   "source": [
    "In this step, we load the keyword extraction results for a specific movie and retrieve the corresponding ground truth keywords. The goal is to use these annotated keywords for evaluation and comparison with automatically extracted ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a8e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the movie to be evaluated\n",
    "movie_name = \"SW_Episode6\"\n",
    "\n",
    "# Load the extracted keywords for the selected movie from a pickle file\n",
    "# The file path is dynamically built using the movie name\n",
    "selected_film = pd.read_pickle(f\"../Dataset/Extracted_Keywords/kw_{movie_name}.pkl\")\n",
    "\n",
    "# Retrieve the Movie_ID of the selected film\n",
    "# Assumes that the file contains a DataFrame with at least one row\n",
    "selected_film_id = selected_film[\"Movie_ID\"].iloc[0]\n",
    "\n",
    "# Load the full dataset containing the ground truth keywords\n",
    "# for all movies in the evaluation set\n",
    "keywords = pd.read_pickle(\"../Dataset/keywords_ground_truth.pkl\")\n",
    "\n",
    "# Filter the ground truth dataset to extract only the keywords for the selected movie\n",
    "kw_ground_truth = keywords[keywords[\"Movie_ID\"] == selected_film_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5fd95b",
   "metadata": {},
   "source": [
    "## Keyword Matching and Evaluation Functions (Basic – Unweighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c9a94a",
   "metadata": {},
   "source": [
    "This block defines the core utility functions used to evaluate predicted keywords against the ground truth. These functions perform a **binary, unweighted evaluation**, ignoring confidence scores and ranking information.\n",
    "\n",
    "The evaluation pipeline includes the following steps:\n",
    "\n",
    "- **Normalization**: all keywords are lowercased, stripped of punctuation, and cleaned of extra whitespace to ensure consistent text matching.\n",
    "\n",
    "- **Approximate Matching**: a relaxed rule considers two keywords as a match if:\n",
    "  - They are exactly equal (after normalization), or\n",
    "  - One is a substring of the other (e.g., *\"social satire\"* is considered a match with *\"satire\"*).\n",
    "\n",
    "- **Global Evaluation**: for each model, all keywords predicted across the reviews of a given movie are aggregated, and then compared to the global set of ground truth keywords for that movie.\n",
    "\n",
    "- **Metrics**: we compute **Precision**, **Recall**, and **F1-score** based on the number of approximate matches between the predicted and ground truth keywords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f79c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_kw(kw):\n",
    "    \"\"\"\n",
    "    Normalize a keyword string by:\n",
    "    - Converting to lowercase\n",
    "    - Removing punctuation and non-alphanumeric characters (except spaces)\n",
    "    - Stripping leading and trailing whitespace\n",
    "\n",
    "    Args:\n",
    "        kw (str): The keyword string to normalize.\n",
    "\n",
    "    Returns:\n",
    "        str: The normalized keyword.\n",
    "    \"\"\"\n",
    "    kw = kw.lower()\n",
    "    kw = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", kw)  # Keep only alphanumeric characters and whitespace\n",
    "    return kw.strip()\n",
    "\n",
    "\n",
    "def is_approx_match(kw, gt_keywords):\n",
    "    \"\"\"\n",
    "    Check if a predicted keyword approximately matches any ground truth keyword.\n",
    "\n",
    "    A match is considered approximate if:\n",
    "    - The predicted keyword is exactly equal to a ground truth keyword\n",
    "    - OR the predicted keyword is a substring of a ground truth keyword\n",
    "    - OR a ground truth keyword is a substring of the predicted one\n",
    "\n",
    "    Args:\n",
    "        kw (str): The normalized predicted keyword.\n",
    "        gt_keywords (List[str]): A list of normalized ground truth keywords.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if an approximate match is found, False otherwise.\n",
    "    \"\"\"\n",
    "    for gt in gt_keywords:\n",
    "        if kw == gt or kw in gt or gt in kw:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_keywords(all_pred_keywords, all_gt_keywords):\n",
    "    \"\"\"\n",
    "    Evaluate global precision, recall, and F1-score across a dataset using approximate matching.\n",
    "\n",
    "    This function compares predicted keywords to ground truth keywords for each review.\n",
    "    Matching is performed using approximate string comparison, and each ground truth keyword\n",
    "    can be matched only once to ensure fairness. The metrics are aggregated globally,\n",
    "    not per-review.\n",
    "\n",
    "    Args:\n",
    "        all_pred_keywords (List[List[str]]): \n",
    "            A list where each element is a list of predicted keywords for a single review.\n",
    "        all_gt_keywords (List[List[str]]): \n",
    "            A list where each element is a list of ground truth keywords for the corresponding review.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float]: Global precision, recall, and F1-score based on approximate matching.\n",
    "    \"\"\"\n",
    "    global_match_count = 0     # Total number of matched keywords across all reviews\n",
    "    global_pred_count = 0      # Total number of predicted keywords\n",
    "    global_gt_count = 0        # Total number of ground truth keywords\n",
    "\n",
    "    # Iterate through each review's predictions and ground truths\n",
    "    for pred_keywords, gt_keywords in zip(all_pred_keywords, all_gt_keywords):\n",
    "        # Normalize and sort keywords to ensure consistent behavior\n",
    "        pred_keywords = sorted([normalize_kw(k) for k in pred_keywords])\n",
    "        gt_keywords = sorted([normalize_kw(k) for k in gt_keywords])\n",
    "\n",
    "        global_pred_count += len(pred_keywords)\n",
    "        global_gt_count += len(gt_keywords)\n",
    "\n",
    "        matched_gts = set()  # Track which ground truth keywords have already been matched\n",
    "\n",
    "        for pred in pred_keywords:\n",
    "            for gt in gt_keywords:\n",
    "                if gt not in matched_gts and is_approx_match(pred, [gt]):\n",
    "                    global_match_count += 1\n",
    "                    matched_gts.add(gt)  # Avoid matching the same GT keyword multiple times\n",
    "                    break\n",
    "\n",
    "    # Compute global metrics\n",
    "    precision = global_match_count / global_pred_count if global_pred_count else 0\n",
    "    recall = global_match_count / global_gt_count if global_gt_count else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0cda19",
   "metadata": {},
   "source": [
    "### Evaluate and Compare Models on Keyword Extraction (Basic – Unweighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd0199",
   "metadata": {},
   "source": [
    "This section evaluates two keyword extraction models — **base** and **metadata-enhanced** — against the ground truth annotations.\n",
    "\n",
    "For each model, we collect all predicted keywords across all reviews in the selected movie and compare them to the ground truth keywords using **binary approximate matching**.\n",
    "\n",
    "The evaluation computes **global precision, recall, and F1-score**, considering the entire set of predictions and ground truth keywords as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d333544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f47d2\">\n",
       "  <caption>Global Evaluation Summary</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f47d2_level0_col0\" class=\"col_heading level0 col0\" >Precision</th>\n",
       "      <th id=\"T_f47d2_level0_col1\" class=\"col_heading level0 col1\" >Recall</th>\n",
       "      <th id=\"T_f47d2_level0_col2\" class=\"col_heading level0 col2\" >F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f47d2_level0_row0\" class=\"row_heading level0 row0\" >base</th>\n",
       "      <td id=\"T_f47d2_row0_col0\" class=\"data row0 col0\" >0.9199</td>\n",
       "      <td id=\"T_f47d2_row0_col1\" class=\"data row0 col1\" >0.3577</td>\n",
       "      <td id=\"T_f47d2_row0_col2\" class=\"data row0 col2\" >0.5151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f47d2_level0_row1\" class=\"row_heading level0 row1\" >metadata</th>\n",
       "      <td id=\"T_f47d2_row1_col0\" class=\"data row1 col0\" >0.9206</td>\n",
       "      <td id=\"T_f47d2_row1_col1\" class=\"data row1 col1\" >0.3580</td>\n",
       "      <td id=\"T_f47d2_row1_col2\" class=\"data row1 col2\" >0.5155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x178729940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the models to be evaluated\n",
    "models_to_evaluate = [\"base\", \"metadata\"]\n",
    "\n",
    "# Extract the list of ground truth keywords for the selected movie\n",
    "ground_truth_keywords = [normalize_kw(kw) for kw in kw_ground_truth[\"Keyword\"].tolist()]\n",
    "\n",
    "# Dictionary to store all predicted keywords per model (across all reviews)\n",
    "all_predictions = {model: [] for model in models_to_evaluate}\n",
    "\n",
    "# Iterate over each review in the selected film's predictions\n",
    "for _, row in selected_film.iterrows():\n",
    "    for model in models_to_evaluate:\n",
    "        pred_col = f\"keywords_{model}\"\n",
    "\n",
    "        if pred_col in row and isinstance(row[pred_col], list):\n",
    "            predicted_keywords = [\n",
    "                normalize_kw(kw) for kw, _ in row[pred_col] if isinstance(kw, str)\n",
    "            ]\n",
    "            \n",
    "            # Remove duplicates per review\n",
    "            seen = set()\n",
    "            unique_kw = [kw for kw in predicted_keywords if kw not in seen and not seen.add(kw)]\n",
    "\n",
    "            all_predictions[model].append(unique_kw)\n",
    "\n",
    "# Evaluate each model globally\n",
    "summary = {}\n",
    "for model in models_to_evaluate:\n",
    "    precision, recall, f1 = evaluate_keywords(\n",
    "        all_predictions[model],  # List of lists\n",
    "        ground_truth_keywords\n",
    "    )\n",
    "\n",
    "    summary[model] = {\n",
    "        \"Precision\": round(precision, 4),\n",
    "        \"Recall\": round(recall, 4),\n",
    "        \"F1-score\": round(f1, 4)\n",
    "    }\n",
    "\n",
    "# Convert and display\n",
    "summary_df = pd.DataFrame(summary).T\n",
    "summary_df.columns = [\"Precision\", \"Recall\", \"F1-score\"]\n",
    "summary_df.style.format(precision=4).set_caption(\"Global Evaluation Summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc68d6",
   "metadata": {},
   "source": [
    "## Score-Aware Evaluation: Weighted Metrics and nDCG@k with Graded Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0055848",
   "metadata": {},
   "source": [
    "This extended evaluation considers the **confidence scores** assigned by the model to each predicted keyword, allowing us to measure not only whether the predictions are correct but also how confidently and effectively they are ranked.\n",
    "\n",
    "#### **Score-Aware Metrics**\n",
    "\n",
    "- **Weighted Precision**: Reflects the proportion of the model’s total confidence assigned to correct keywords. High confidence in incorrect predictions lowers this score.\n",
    "- **Weighted Recall**: Measures how much of the ground truth is recovered, weighted by the confidence of correct predictions.\n",
    "- **Weighted F1-score**: The harmonic mean of weighted precision and recall, balancing accuracy with coverage.\n",
    "- **nDCG@k (Normalized Discounted Cumulative Gain)**: A ranking metric that rewards placing relevant keywords near the top of the prediction list. It uses **graded relevance**, which accounts for the importance of ground truth keywords based on their position.\n",
    "\n",
    "#### **How nDCG@k with Graded Relevance is Computed**\n",
    "\n",
    "1. **Assign graded relevance to ground truth keywords** based on their position $pos_{GT}$ (starting from 0):\n",
    "\n",
    "$$\n",
    "rel_{GT} = \\frac{1}{\\log_2(pos_{GT} + 2)}\n",
    "$$\n",
    "\n",
    "2. **Assign relevance to each predicted keyword at position $i$** (starting from 0), using approximate matching:\n",
    "\n",
    "$$\n",
    "rel_i = \\begin{cases}\n",
    "\\frac{1}{\\log_2(pos_{GT} + 2)} & \\text{if predicted keyword matches GT keyword at } pos_{GT} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "3. **Compute DCG@k** (Discounted Cumulative Gain):\n",
    "\n",
    "$$\n",
    "DCG@k = \\sum_{i=0}^{k-1} \\frac{rel_i}{\\log_2(i + 2)}\n",
    "$$\n",
    "\n",
    "4. **Compute IDCG@k** (Ideal DCG using the best ranking):\n",
    "\n",
    "$$\n",
    "IDCG@k = \\sum_{i=0}^{k-1} \\frac{rel^*_i}{\\log_2(i + 2)}\n",
    "$$\n",
    "\n",
    "5. **Compute normalized nDCG**:\n",
    "\n",
    "$$\n",
    "nDCG@k = \\frac{DCG@k}{IDCG@k}\n",
    "$$\n",
    "\n",
    "#### **Example ($k=5$)**\n",
    "\n",
    "**Ground truth keywords (ranked):**  \n",
    "`[\"fraud\", \"poverty\", \"scam\"]`\n",
    "\n",
    "**Their graded relevance (using $rel_{GT} = 1/\\log_2(pos_{GT}+2)$):**\n",
    "\n",
    "- fraud (position 0): $1 / \\log_2(0+2) = 1.0$\n",
    "- poverty (position 1): $1 / \\log_2(1+2) \\approx 0.6309$\n",
    "- scam (position 2): $1 / \\log_2(2+2) = 0.5$\n",
    "\n",
    "#### **First predicted list**:\n",
    "`[\"scam\", \"family\", \"poverty\", \"cinematography\", \"fraud\"]`\n",
    "\n",
    "**Matches and assigned relevances:**\n",
    "\n",
    "| Predicted keyword | Match         | Relevance |\n",
    "|-------------------|---------------|-----------|\n",
    "| scam              | yes (pos 2)   | 0.5       |\n",
    "| family            | no            | 0         |\n",
    "| poverty           | yes (pos 1)   | 0.6309    |\n",
    "| cinematography    | no            | 0         |\n",
    "| fraud             | yes (pos 0)   | 1.0       |\n",
    "\n",
    "**Compute DCG:**\n",
    "\n",
    "$$\n",
    "DCG = \\frac{0.5}{\\log_2(0 + 2)} + \\frac{0}{\\log_2(1 + 2)} + \\frac{0.6309}{\\log_2(2 + 2)} + \\frac{0}{\\log_2(3 + 2)} + \\frac{1.0}{\\log_2(4 + 2)} \\\\\n",
    "= \\frac{0.5}{1.0} + 0 + \\frac{0.6309}{2.0} + 0 + \\frac{1.0}{2.58496} \\approx 0.5 + 0 + 0.31545 + 0 + 0.38685 = \\mathbf{1.2023}\n",
    "$$\n",
    "\n",
    "**Compute IDCG:**\n",
    "\n",
    "Best possible ranking: `[\"fraud\", \"poverty\", \"scam\"]`  \n",
    "Relevance list: $[1.0, 0.6309, 0.5]$\n",
    "\n",
    "$$\n",
    "IDCG = \\frac{1.0}{\\log_2(0 + 2)} + \\frac{0.6309}{\\log_2(1 + 2)} + \\frac{0.5}{\\log_2(2 + 2)} \\\\\n",
    "= \\frac{1.0}{1.0} + \\frac{0.6309}{1.58496} + \\frac{0.5}{2.0} \\approx 1.0 + 0.3979 + 0.25 = \\mathbf{1.6479}\n",
    "$$\n",
    "\n",
    "**nDCG@5:**\n",
    "\n",
    "$$\n",
    "nDCG@5 = \\frac{1.2023}{1.6479} \\approx \\mathbf{0.7294}\n",
    "$$\n",
    "\n",
    "\n",
    "#### **Second predicted list**:\n",
    "`[\"fraud\", \"poverty\", \"scam\", \"family\", \"cinematography\"]`\n",
    "\n",
    "**All matches in top-3, correct order:**\n",
    "\n",
    "| Predicted keyword | Match         | Relevance |\n",
    "|-------------------|---------------|-----------|\n",
    "| fraud             | yes (pos 0)   | 1.0       |\n",
    "| poverty           | yes (pos 1)   | 0.6309    |\n",
    "| scam              | yes (pos 2)   | 0.5       |\n",
    "| family            | no            | 0         |\n",
    "| cinematography    | no            | 0         |\n",
    "\n",
    "**Compute DCG:**\n",
    "\n",
    "$$\n",
    "DCG = \\frac{1.0}{\\log_2(0 + 2)} + \\frac{0.6309}{\\log_2(1 + 2)} + \\frac{0.5}{\\log_2(2 + 2)} + 0 + 0 \\\\\n",
    "= 1.0 + 0.3979 + 0.25 = \\mathbf{1.6479}\n",
    "$$\n",
    "\n",
    "**nDCG@5:**\n",
    "\n",
    "$$\n",
    "nDCG@5 = \\frac{1.6479}{1.6479} = \\mathbf{1.0}\n",
    "$$\n",
    "\n",
    "\n",
    "#### **Interpretation**\n",
    "\n",
    "- When relevant keywords appear early in the predicted list, the score increases due to less discounting.\n",
    "- When relevant keywords are ranked lower, the score decreases due to higher discounting.\n",
    "- **nDCG@k rewards both correct predictions and their correct ranking**, making it suitable for evaluating keyword extractors that produce ranked lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b56b5008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_kw(kw):\n",
    "    \"\"\"\n",
    "    Normalize a keyword string by:\n",
    "    - Converting to lowercase\n",
    "    - Removing punctuation and non-alphanumeric characters (except spaces)\n",
    "    - Stripping leading and trailing whitespace\n",
    "\n",
    "    Args:\n",
    "        kw (str): The keyword string to normalize.\n",
    "\n",
    "    Returns:\n",
    "        str: The normalized keyword.\n",
    "    \"\"\"\n",
    "    kw = kw.lower()\n",
    "    kw = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", kw)  # Keep only alphanumeric characters and whitespace\n",
    "    return kw.strip()\n",
    "\n",
    "\n",
    "def is_approx_match(kw, gt_keywords):\n",
    "    \"\"\"\n",
    "    Check if a predicted keyword approximately matches any ground truth keyword.\n",
    "\n",
    "    A match is considered approximate if:\n",
    "    - The predicted keyword is exactly equal to a ground truth keyword\n",
    "    - OR the predicted keyword is a substring of a ground truth keyword\n",
    "    - OR a ground truth keyword is a substring of the predicted one\n",
    "\n",
    "    Args:\n",
    "        kw (str): The normalized predicted keyword.\n",
    "        gt_keywords (List[str]): A list of normalized ground truth keywords.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if an approximate match is found, False otherwise.\n",
    "    \"\"\"\n",
    "    for gt in gt_keywords:\n",
    "        if kw == gt or kw in gt or gt in kw:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def score_gt_keywords_from_rank(gt_keywords):\n",
    "    return [\n",
    "        (kw, 1 / math.log2(i + 2)) for i, kw in enumerate(gt_keywords)\n",
    "    ]\n",
    "\n",
    "def evaluate_keywords_weighted(all_predicted_kw_score, all_gt_keywords):\n",
    "    \"\"\"\n",
    "    Evaluate global weighted precision, recall, and F1-score across multiple reviews.\n",
    "    Matching is performed using approximate matching. Each predicted keyword contributes\n",
    "    to the precision proportionally to its confidence score. Each ground truth keyword contributes\n",
    "    to recall proportionally to its rank-based score.\n",
    "\n",
    "    Args:\n",
    "        all_predicted_kw_score (List[List[Tuple[str, float]]]): \n",
    "            A list of predicted keyword-score pairs per review.\n",
    "        all_gt_keywords (List[List[str]]): \n",
    "            A list of ground truth keyword lists per review.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float]: Weighted precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "    total_pred_score = 0.0  # Sum of all predicted keyword scores\n",
    "    matched_pred_score = 0.0  # Sum of scores of correctly predicted keywords\n",
    "    total_gt_score = 0.0  # Sum of all ground truth scores\n",
    "    matched_gt_score = 0.0  # Sum of scores of matched ground truth keywords\n",
    "\n",
    "    for pred_kw_score, gt_kw in zip(all_predicted_kw_score, all_gt_keywords):\n",
    "        # Normalize and score ground truth keywords\n",
    "        gt_kw_scored = score_gt_keywords_from_rank([normalize_kw(k) for k in gt_kw])\n",
    "        pred_kw_score = [\n",
    "            (normalize_kw(kw), score) for kw, score in pred_kw_score if isinstance(kw, str)\n",
    "        ]\n",
    "\n",
    "        total_pred_score += sum(score for _, score in pred_kw_score)\n",
    "        total_gt_score += sum(score for _, score in gt_kw_scored)\n",
    "\n",
    "        matched_gts = set()\n",
    "\n",
    "        for kw, score in pred_kw_score:\n",
    "            for gt_kw, gt_score in gt_kw_scored:\n",
    "                if gt_kw not in matched_gts and is_approx_match(kw, [gt_kw]):\n",
    "                    matched_pred_score += score\n",
    "                    matched_gt_score += gt_score\n",
    "                    matched_gts.add(gt_kw)\n",
    "                    break\n",
    "\n",
    "    precision = matched_pred_score / total_pred_score if total_pred_score > 0 else 0\n",
    "    recall = matched_gt_score / total_gt_score if total_gt_score > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "def compute_global_ndcg(all_predicted_kw_score, all_gt_keywords, k=5):\n",
    "    \"\"\"\n",
    "    Compute global average nDCG@k (Normalized Discounted Cumulative Gain) over multiple reviews.\n",
    "\n",
    "    The relevance of each predicted keyword is based on the position of its best matching\n",
    "    ground truth keyword. Matching is done via approximate matching. The ideal DCG assumes\n",
    "    the best possible ranking of ground truth keywords.\n",
    "\n",
    "    Args:\n",
    "        all_predicted_kw_score (List[List[Tuple[str, float]]]): \n",
    "            A list of predicted keyword-score pairs per review (ranked list).\n",
    "        all_gt_keywords (List[List[str]]): \n",
    "            A list of ground truth keyword lists per review.\n",
    "        k (int): The number of top predicted keywords to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        float: The average nDCG@k across all reviews.\n",
    "    \"\"\"\n",
    "    total_ndcg = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for pred_kw_score, gt_kw in zip(all_predicted_kw_score, all_gt_keywords):\n",
    "        # Normalize predicted and ground truth keywords\n",
    "        gt_keywords_norm = [normalize_kw(k) for k in gt_kw]\n",
    "        pred_keywords_norm = [normalize_kw(kw) for kw, _ in pred_kw_score[:k]]\n",
    "\n",
    "        relevance = []  # Relevance scores assigned to predicted keywords\n",
    "\n",
    "        for pk in pred_keywords_norm:\n",
    "            # Find the best (earliest) match position in the GT list\n",
    "            match_ranks = [\n",
    "                i for i, gk in enumerate(gt_keywords_norm) if is_approx_match(pk, [gk])\n",
    "            ]\n",
    "            if match_ranks:\n",
    "                best_rank = min(match_ranks)\n",
    "                rel = 1 / math.log2(best_rank + 2)  # Graded relevance\n",
    "            else:\n",
    "                rel = 0\n",
    "            relevance.append(rel)\n",
    "\n",
    "        # Compute DCG for predicted keywords\n",
    "        dcg = sum(rel / math.log2(i + 2) for i, rel in enumerate(relevance))\n",
    "\n",
    "        # Compute IDCG based on ideal ordering of GT keywords\n",
    "        ideal_relevance = [1 / math.log2(i + 2) for i in range(min(k, len(gt_keywords_norm)))]\n",
    "        idcg = sum(ideal_relevance)\n",
    "\n",
    "        if idcg > 0:\n",
    "            total_ndcg += dcg / idcg\n",
    "            count += 1\n",
    "\n",
    "    return total_ndcg / count if count > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52ddf38",
   "metadata": {},
   "source": [
    "### Evaluate and Compare Models on Keyword Extraction (Weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c80dd7",
   "metadata": {},
   "source": [
    "In this section, we evaluate the overall performance of each model using **score-aware metrics** computed **globally across all reviews**:\n",
    "\n",
    "- **Weighted Precision, Recall, and F1-score**: These metrics incorporate the **confidence scores** assigned to each predicted keyword, reflecting how much of the model’s confidence is placed on correct predictions.\n",
    "- **nDCG@5 (Normalized Discounted Cumulative Gain)**: Assesses the overall **ranking quality** of the top-5 predicted keywords, rewarding correct keywords that are ranked higher.\n",
    "\n",
    "This global evaluation provides a holistic view of each model’s effectiveness in ranking and selecting relevant keywords across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "909cc3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4c0be\">\n",
       "  <caption>Global Score-Aware Evaluation Summary</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4c0be_level0_col0\" class=\"col_heading level0 col0\" >Weighted Precision</th>\n",
       "      <th id=\"T_4c0be_level0_col1\" class=\"col_heading level0 col1\" >Weighted Recall</th>\n",
       "      <th id=\"T_4c0be_level0_col2\" class=\"col_heading level0 col2\" >Weighted F1-score</th>\n",
       "      <th id=\"T_4c0be_level0_col3\" class=\"col_heading level0 col3\" >nDCG@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row0\" class=\"row_heading level0 row0\" >base</th>\n",
       "      <td id=\"T_4c0be_row0_col0\" class=\"data row0 col0\" >0.9155</td>\n",
       "      <td id=\"T_4c0be_row0_col1\" class=\"data row0 col1\" >0.4677</td>\n",
       "      <td id=\"T_4c0be_row0_col2\" class=\"data row0 col2\" >0.6191</td>\n",
       "      <td id=\"T_4c0be_row0_col3\" class=\"data row0 col3\" >0.6973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row1\" class=\"row_heading level0 row1\" >metadata</th>\n",
       "      <td id=\"T_4c0be_row1_col0\" class=\"data row1 col0\" >0.9181</td>\n",
       "      <td id=\"T_4c0be_row1_col1\" class=\"data row1 col1\" >0.4778</td>\n",
       "      <td id=\"T_4c0be_row1_col2\" class=\"data row1 col2\" >0.6285</td>\n",
       "      <td id=\"T_4c0be_row1_col3\" class=\"data row1 col3\" >0.7169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x363b90d60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Models to evaluate\n",
    "models_to_evaluate = [\"base\", \"metadata\"]\n",
    "\n",
    "# Ground truth keywords (same for all reviews in the selected film)\n",
    "ground_truth_keywords = kw_ground_truth[\"Keyword\"].tolist()\n",
    "\n",
    "# Prepare data structures to hold predictions for each model\n",
    "all_predicted_kw_score = {model: [] for model in models_to_evaluate}\n",
    "\n",
    "# Collect predictions and GT for each review\n",
    "for _, row in selected_film.iterrows():\n",
    "    for model in models_to_evaluate:\n",
    "        pred_col = f\"keywords_{model}\"\n",
    "\n",
    "        # Skip if no prediction or wrong format\n",
    "        if pred_col in row and isinstance(row[pred_col], list):\n",
    "            predicted_kw_score = [(kw, score) for kw, score in row[pred_col] if isinstance(kw, str)]\n",
    "            # Remove duplicates per review\n",
    "            seen = set()\n",
    "            unique_pred = [(kw, score) for kw, score in predicted_kw_score if kw not in seen and not seen.add(kw)]\n",
    "            all_predicted_kw_score[model].append(unique_pred)\n",
    "\n",
    "\n",
    "# Dictionary to store global evaluation results\n",
    "weighted_summary = {}\n",
    "\n",
    "# Evaluate each model globally\n",
    "for model in models_to_evaluate:\n",
    "    preds = all_predicted_kw_score[model]\n",
    "\n",
    "    # Global weighted metrics\n",
    "    w_precision, w_recall, w_f1 = evaluate_keywords_weighted(preds, ground_truth_keywords)\n",
    "\n",
    "    # Global nDCG@5\n",
    "    ndcg = compute_global_ndcg(preds, ground_truth_keywords, k=5)\n",
    "\n",
    "    # Store results\n",
    "    weighted_summary[model] = {\n",
    "        \"weighted_precision\": round(w_precision, 4),\n",
    "        \"weighted_recall\": round(w_recall, 4),\n",
    "        \"weighted_f1\": round(w_f1, 4),\n",
    "        \"ndcg@5\": round(ndcg, 4)\n",
    "    }\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame(weighted_summary).T  # Models as rows\n",
    "\n",
    "# Rename columns\n",
    "summary_df.columns = [\n",
    "    \"Weighted Precision\",\n",
    "    \"Weighted Recall\",\n",
    "    \"Weighted F1-score\",\n",
    "    \"nDCG@5\"\n",
    "]\n",
    "\n",
    "# Display final table\n",
    "summary_df.style.format(precision=4).set_caption(\"Global Score-Aware Evaluation Summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabef0de",
   "metadata": {},
   "source": [
    "## Semantic Evaluation (Base vs Metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d16c67f",
   "metadata": {},
   "source": [
    "In this section, we evaluate and compare the **Base** and **Metadata-enhanced** keyword extraction models using a **semantic similarity approach** based on contextual embeddings.\n",
    "\n",
    "Traditional evaluation metrics rely on exact or approximate string matching between predicted and ground truth keywords. However, this approach may miss semantically related terms that differ lexically but convey the same meaning — such as *\"scam\"* and *\"fraud\"*.\n",
    "\n",
    "To address this limitation, we adopt a **global semantic evaluation**, where all predicted and ground truth keywords across the dataset are compared using **dense sentence embeddings** generated by a pre-trained transformer (e.g., Sentence-BERT).\n",
    "\n",
    "#### **Semantic Evaluation Procedure**\n",
    "\n",
    "1. **Embedding Keywords Globally**  \n",
    "   All predicted and ground truth keywords across all reviews are embedded into high-dimensional vectors using the same transformer model. Ground truth keywords are embedded **once**, and all vectors are normalized to allow cosine similarity comparisons.\n",
    "\n",
    "2. **Computing Similarity Matrix**  \n",
    "   For each model, we compute a cosine similarity matrix between **all predicted keywords** and **all ground truth keywords**.\n",
    "\n",
    "3. **Matching Threshold**  \n",
    "   A predicted keyword is considered a **semantic match** if its cosine similarity with at least one ground truth keyword exceeds a fixed threshold (e.g., **0.65**). This allows for flexible yet meaningful semantic alignment.\n",
    "\n",
    "4. **Global Semantic Precision**  \n",
    "   The proportion of predicted keywords that have at least one semantic match in the ground truth. This reflects how many of the model's predictions are semantically relevant.\n",
    "\n",
    "5. **Global Semantic Recall**  \n",
    "   The proportion of ground truth keywords that are captured by semantically similar predictions. This indicates how well the model covers the key concepts.\n",
    "\n",
    "6. **Global Semantic F1-score**  \n",
    "   The harmonic mean of semantic precision and recall, summarizing both relevance and coverage into a single score.\n",
    "\n",
    "This evaluation:\n",
    "\n",
    "- Is **more robust** than string-based metrics.\n",
    "- **Captures meaning**, not just surface forms.\n",
    "- Helps evaluate models that paraphrase or generalize beyond exact matches.\n",
    "\n",
    "This evaluation complements previous metrics and provides a more **realistic estimate** of how well the models capture the essence of user-annotated keywords in a global and context-aware manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f779851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sentence embedding model from the SentenceTransformers family\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load tokenizer and model to generate contextual embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "encoder = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "# Simple normalization function for keywords:\n",
    "# - Converts to lowercase\n",
    "# - Removes punctuation\n",
    "# - Strips leading/trailing spaces\n",
    "def normalize_kw(kw):\n",
    "    kw = kw.lower()\n",
    "    kw = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", kw)  # Keep only alphanumerics and whitespace\n",
    "    return kw.strip()\n",
    "\n",
    "def embed_keywords(keywords, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Compute sentence embeddings for a list of keyword strings.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    keywords : List[str]\n",
    "        A list of keyword strings to encode.\n",
    "    device : str\n",
    "        Device to run the model on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Normalized embeddings tensor of shape (num_keywords, embedding_dim).\n",
    "    \"\"\"\n",
    "    # Return empty tensor if input list is empty\n",
    "    if not keywords:\n",
    "        return torch.empty(0, encoder.config.hidden_size).to(device)\n",
    "\n",
    "    # Tokenize and prepare inputs for the model\n",
    "    inputs = tokenizer(keywords, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass through the encoder to get hidden states\n",
    "        outputs = encoder(**inputs)\n",
    "\n",
    "        # Use mean pooling on the last hidden state to get fixed-size embeddings\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "        # Normalize embeddings to unit length for cosine similarity computations\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def evaluate_semantic_keywords_global(all_pred_keywords, gt_keywords, threshold=0.65, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Compute global semantic precision, recall, and F1 score between all predicted keywords\n",
    "    and ground truth keywords using cosine similarity over embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    all_pred_keywords : List[List[str]]\n",
    "        List of predicted keywords for each review.\n",
    "    gt_keywords : List[str]\n",
    "        Global list of ground truth keywords for the movie.\n",
    "    threshold : float\n",
    "        Cosine similarity threshold for considering a match.\n",
    "    device : str\n",
    "        Device to run the model on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    precision : float\n",
    "    recall : float\n",
    "    f1 : float\n",
    "    \"\"\"\n",
    "    # Early return if either set is empty\n",
    "    if len(all_pred_keywords) == 0 or len(gt_keywords) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    # Compute embeddings\n",
    "    pred_emb = embed_keywords(all_pred_keywords, device=device)\n",
    "    gt_emb = embed_keywords(gt_keywords, device=device)\n",
    "\n",
    "    # Compute similarity matrix\n",
    "    sims = torch.matmul(pred_emb, gt_emb.T)\n",
    "\n",
    "    # Match counting based on threshold\n",
    "    pred_matches = (sims > threshold).any(dim=1).float().sum().item()\n",
    "    gt_matches = (sims > threshold).any(dim=0).float().sum().item()\n",
    "\n",
    "    precision = pred_matches / len(all_pred_keywords)\n",
    "    recall = gt_matches / len(gt_keywords)\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n",
    "\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce9bda",
   "metadata": {},
   "source": [
    "### Semantic Evaluation of Base and Metadata Models Using Sentence Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa566c",
   "metadata": {},
   "source": [
    "In this step, we evaluate the **semantic similarity** between the predicted keywords of two models — **Base** and **Metadata-enhanced** — and the ground truth keywords using **sentence embeddings**.\n",
    "\n",
    "Unlike exact or approximate string matching, this method leverages **contextual embeddings** from a pre-trained transformer to assess how semantically close the predicted keywords are to the reference keywords.\n",
    "\n",
    "The evaluation procedure is as follows:\n",
    "\n",
    "- We extract only the **text** of the predicted keywords for each model, discarding their confidence scores.\n",
    "- We embed all **predicted** and **ground truth** keywords using the same sentence transformer model.\n",
    "- Embeddings are **normalized** to ensure cosine similarity is a valid similarity measure.\n",
    "- For each predicted keyword, we compute the **cosine similarity** with all ground truth keywords.\n",
    "- A predicted keyword is considered a **semantic match** if its similarity with any ground truth keyword exceeds a fixed threshold (e.g., **0.65**).\n",
    "\n",
    "Once all matches are determined across all reviews of the selected movie, we compute:\n",
    "\n",
    "- **Semantic Precision**: Fraction of all predicted keywords (global) that have a semantic match.\n",
    "- **Semantic Recall**: Fraction of all ground truth keywords that are matched by at least one semantically similar predicted keyword.\n",
    "- **Semantic F1-score**: Harmonic mean of semantic precision and recall.\n",
    "\n",
    "This global semantic evaluation better reflects the models’ ability to capture **meaningful and relevant keywords**, even when the wording differs from the ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbbd11b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_44cff\">\n",
       "  <caption>Global Semantic-Aware Evaluation Summary</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_44cff_level0_col0\" class=\"col_heading level0 col0\" >Semantic_Precision</th>\n",
       "      <th id=\"T_44cff_level0_col1\" class=\"col_heading level0 col1\" >Semantic_Recall</th>\n",
       "      <th id=\"T_44cff_level0_col2\" class=\"col_heading level0 col2\" >Semantic_F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_44cff_level0_row0\" class=\"row_heading level0 row0\" >base</th>\n",
       "      <td id=\"T_44cff_row0_col0\" class=\"data row0 col0\" >0.9296</td>\n",
       "      <td id=\"T_44cff_row0_col1\" class=\"data row0 col1\" >0.7500</td>\n",
       "      <td id=\"T_44cff_row0_col2\" class=\"data row0 col2\" >0.8302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44cff_level0_row1\" class=\"row_heading level0 row1\" >metadata</th>\n",
       "      <td id=\"T_44cff_row1_col0\" class=\"data row1 col0\" >0.9274</td>\n",
       "      <td id=\"T_44cff_row1_col1\" class=\"data row1 col1\" >0.7610</td>\n",
       "      <td id=\"T_44cff_row1_col2\" class=\"data row1 col2\" >0.8360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1078cbd90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precompute embeddings for the ground truth keywords once per selected movie\n",
    "gt_keywords = kw_ground_truth[\"Keyword\"].tolist()\n",
    "\n",
    "# Define the models to evaluate\n",
    "models_to_evaluate = [\"base\", \"metadata\"]\n",
    "\n",
    "# Dictionary to collect all predicted keywords per model (without duplicates)\n",
    "all_predictions = {model: set() for model in models_to_evaluate}\n",
    "\n",
    "# Collect predicted keywords across all reviews (as a set for uniqueness)\n",
    "for _, row in selected_film.iterrows():\n",
    "    for model in models_to_evaluate:\n",
    "        pred_col = f\"keywords_{model}\"\n",
    "\n",
    "        if pred_col in row and isinstance(row[pred_col], list):\n",
    "            # Extract keyword strings and normalize\n",
    "            pred_kw = [normalize_kw(kw) for kw, _ in row[pred_col] if isinstance(kw, str)]\n",
    "            all_predictions[model].update(pred_kw)  # Add to set (no duplicates)\n",
    "\n",
    "# Compute semantic evaluation globally for each model\n",
    "semantic_scores = []\n",
    "for model in models_to_evaluate:\n",
    "    pred_kw = list(all_predictions[model])  # Convert back to list\n",
    "    precision, recall, f1 = evaluate_semantic_keywords_global(pred_kw, gt_keywords, device=device)\n",
    "\n",
    "    semantic_scores.append({\n",
    "        \"Model\": model,\n",
    "        \"Semantic_Precision\": round(precision, 4),\n",
    "        \"Semantic_Recall\": round(recall, 4),\n",
    "        \"Semantic_F1\": round(f1, 4)\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and format\n",
    "summary_df = pd.DataFrame(semantic_scores).set_index(\"Model\")\n",
    "summary_df.style.format(precision=4).set_caption(\"Global Semantic-Aware Evaluation Summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c28df9",
   "metadata": {},
   "source": [
    "## Evaluation Across All Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc187183",
   "metadata": {},
   "source": [
    "This section automatically processes all `.pkl` files in the `Extracted_Keywords` directory, where each file corresponds to a single movie and contains predicted keywords generated by different models.\n",
    "\n",
    "For each movie:\n",
    "- The corresponding **ground truth keywords** are loaded.\n",
    "- Predicted keywords from both models — **Base** and **Metadata-enhanced** — are evaluated.\n",
    "- The evaluation is performed globally across all reviews in the movie, without computing metrics per review.\n",
    "\n",
    "For each model, the following **global metrics** are computed:\n",
    "\n",
    "- **Unweighted Metrics**:  \n",
    "  Precision, Recall, and F1-score using approximate string matching.\n",
    "\n",
    "- **Score-aware Metrics**:  \n",
    "  - **Weighted Precision**: proportion of total confidence assigned to correct predictions.  \n",
    "  - **Weighted Recall**: coverage of ground truth weighted by prediction confidence.  \n",
    "  - **Weighted F1-score**: harmonic mean of weighted precision and recall.  \n",
    "  - **nDCG@5**: evaluates the quality of keyword ranking using graded relevance and position-based discounting.\n",
    "\n",
    "- **Semantic Metrics**:  \n",
    "  Semantic Precision, Recall, and F1-score using **cosine similarity** between **sentence embeddings** of predicted and ground truth keywords.\n",
    "\n",
    "All metrics are computed globally for each movie and then compiled into a summary table to compare the overall performance of the two models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4faf7251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1f3d2\">\n",
       "  <caption>Global Evaluation Summary per Movie and Model</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1f3d2_level0_col0\" class=\"col_heading level0 col0\" >Movie</th>\n",
       "      <th id=\"T_1f3d2_level0_col1\" class=\"col_heading level0 col1\" >Model</th>\n",
       "      <th id=\"T_1f3d2_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_1f3d2_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_1f3d2_level0_col4\" class=\"col_heading level0 col4\" >F1-score</th>\n",
       "      <th id=\"T_1f3d2_level0_col5\" class=\"col_heading level0 col5\" >Weighted Precision</th>\n",
       "      <th id=\"T_1f3d2_level0_col6\" class=\"col_heading level0 col6\" >Weighted Recall</th>\n",
       "      <th id=\"T_1f3d2_level0_col7\" class=\"col_heading level0 col7\" >Weighted F1-score</th>\n",
       "      <th id=\"T_1f3d2_level0_col8\" class=\"col_heading level0 col8\" >nDCG@5</th>\n",
       "      <th id=\"T_1f3d2_level0_col9\" class=\"col_heading level0 col9\" >Semantic Precision</th>\n",
       "      <th id=\"T_1f3d2_level0_col10\" class=\"col_heading level0 col10\" >Semantic Recall</th>\n",
       "      <th id=\"T_1f3d2_level0_col11\" class=\"col_heading level0 col11\" >Semantic F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1f3d2_row0_col0\" class=\"data row0 col0\" >GoodBadUgly</td>\n",
       "      <td id=\"T_1f3d2_row0_col1\" class=\"data row0 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row0_col2\" class=\"data row0 col2\" >0.9341</td>\n",
       "      <td id=\"T_1f3d2_row0_col3\" class=\"data row0 col3\" >0.3612</td>\n",
       "      <td id=\"T_1f3d2_row0_col4\" class=\"data row0 col4\" >0.5210</td>\n",
       "      <td id=\"T_1f3d2_row0_col5\" class=\"data row0 col5\" >0.9352</td>\n",
       "      <td id=\"T_1f3d2_row0_col6\" class=\"data row0 col6\" >0.4857</td>\n",
       "      <td id=\"T_1f3d2_row0_col7\" class=\"data row0 col7\" >0.6394</td>\n",
       "      <td id=\"T_1f3d2_row0_col8\" class=\"data row0 col8\" >0.7323</td>\n",
       "      <td id=\"T_1f3d2_row0_col9\" class=\"data row0 col9\" >0.8691</td>\n",
       "      <td id=\"T_1f3d2_row0_col10\" class=\"data row0 col10\" >0.7888</td>\n",
       "      <td id=\"T_1f3d2_row0_col11\" class=\"data row0 col11\" >0.8270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1f3d2_row1_col0\" class=\"data row1 col0\" >GoodBadUgly</td>\n",
       "      <td id=\"T_1f3d2_row1_col1\" class=\"data row1 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row1_col2\" class=\"data row1 col2\" >0.9378</td>\n",
       "      <td id=\"T_1f3d2_row1_col3\" class=\"data row1 col3\" >0.3627</td>\n",
       "      <td id=\"T_1f3d2_row1_col4\" class=\"data row1 col4\" >0.5231</td>\n",
       "      <td id=\"T_1f3d2_row1_col5\" class=\"data row1 col5\" >0.9363</td>\n",
       "      <td id=\"T_1f3d2_row1_col6\" class=\"data row1 col6\" >0.4876</td>\n",
       "      <td id=\"T_1f3d2_row1_col7\" class=\"data row1 col7\" >0.6413</td>\n",
       "      <td id=\"T_1f3d2_row1_col8\" class=\"data row1 col8\" >0.7391</td>\n",
       "      <td id=\"T_1f3d2_row1_col9\" class=\"data row1 col9\" >0.8539</td>\n",
       "      <td id=\"T_1f3d2_row1_col10\" class=\"data row1 col10\" >0.7981</td>\n",
       "      <td id=\"T_1f3d2_row1_col11\" class=\"data row1 col11\" >0.8251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1f3d2_row2_col0\" class=\"data row2 col0\" >HarryPotter</td>\n",
       "      <td id=\"T_1f3d2_row2_col1\" class=\"data row2 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row2_col2\" class=\"data row2 col2\" >0.9194</td>\n",
       "      <td id=\"T_1f3d2_row2_col3\" class=\"data row2 col3\" >0.3394</td>\n",
       "      <td id=\"T_1f3d2_row2_col4\" class=\"data row2 col4\" >0.4957</td>\n",
       "      <td id=\"T_1f3d2_row2_col5\" class=\"data row2 col5\" >0.9202</td>\n",
       "      <td id=\"T_1f3d2_row2_col6\" class=\"data row2 col6\" >0.4552</td>\n",
       "      <td id=\"T_1f3d2_row2_col7\" class=\"data row2 col7\" >0.6091</td>\n",
       "      <td id=\"T_1f3d2_row2_col8\" class=\"data row2 col8\" >0.7148</td>\n",
       "      <td id=\"T_1f3d2_row2_col9\" class=\"data row2 col9\" >0.9016</td>\n",
       "      <td id=\"T_1f3d2_row2_col10\" class=\"data row2 col10\" >0.8820</td>\n",
       "      <td id=\"T_1f3d2_row2_col11\" class=\"data row2 col11\" >0.8917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1f3d2_row3_col0\" class=\"data row3 col0\" >HarryPotter</td>\n",
       "      <td id=\"T_1f3d2_row3_col1\" class=\"data row3 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row3_col2\" class=\"data row3 col2\" >0.9274</td>\n",
       "      <td id=\"T_1f3d2_row3_col3\" class=\"data row3 col3\" >0.3423</td>\n",
       "      <td id=\"T_1f3d2_row3_col4\" class=\"data row3 col4\" >0.5001</td>\n",
       "      <td id=\"T_1f3d2_row3_col5\" class=\"data row3 col5\" >0.9262</td>\n",
       "      <td id=\"T_1f3d2_row3_col6\" class=\"data row3 col6\" >0.4649</td>\n",
       "      <td id=\"T_1f3d2_row3_col7\" class=\"data row3 col7\" >0.6191</td>\n",
       "      <td id=\"T_1f3d2_row3_col8\" class=\"data row3 col8\" >0.7277</td>\n",
       "      <td id=\"T_1f3d2_row3_col9\" class=\"data row3 col9\" >0.9771</td>\n",
       "      <td id=\"T_1f3d2_row3_col10\" class=\"data row3 col10\" >0.8886</td>\n",
       "      <td id=\"T_1f3d2_row3_col11\" class=\"data row3 col11\" >0.9308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1f3d2_row4_col0\" class=\"data row4 col0\" >IndianaJones</td>\n",
       "      <td id=\"T_1f3d2_row4_col1\" class=\"data row4 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row4_col2\" class=\"data row4 col2\" >0.9125</td>\n",
       "      <td id=\"T_1f3d2_row4_col3\" class=\"data row4 col3\" >0.3678</td>\n",
       "      <td id=\"T_1f3d2_row4_col4\" class=\"data row4 col4\" >0.5243</td>\n",
       "      <td id=\"T_1f3d2_row4_col5\" class=\"data row4 col5\" >0.9176</td>\n",
       "      <td id=\"T_1f3d2_row4_col6\" class=\"data row4 col6\" >0.4902</td>\n",
       "      <td id=\"T_1f3d2_row4_col7\" class=\"data row4 col7\" >0.6390</td>\n",
       "      <td id=\"T_1f3d2_row4_col8\" class=\"data row4 col8\" >0.7459</td>\n",
       "      <td id=\"T_1f3d2_row4_col9\" class=\"data row4 col9\" >0.9628</td>\n",
       "      <td id=\"T_1f3d2_row4_col10\" class=\"data row4 col10\" >0.7978</td>\n",
       "      <td id=\"T_1f3d2_row4_col11\" class=\"data row4 col11\" >0.8726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_1f3d2_row5_col0\" class=\"data row5 col0\" >IndianaJones</td>\n",
       "      <td id=\"T_1f3d2_row5_col1\" class=\"data row5 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row5_col2\" class=\"data row5 col2\" >0.9125</td>\n",
       "      <td id=\"T_1f3d2_row5_col3\" class=\"data row5 col3\" >0.3678</td>\n",
       "      <td id=\"T_1f3d2_row5_col4\" class=\"data row5 col4\" >0.5243</td>\n",
       "      <td id=\"T_1f3d2_row5_col5\" class=\"data row5 col5\" >0.9190</td>\n",
       "      <td id=\"T_1f3d2_row5_col6\" class=\"data row5 col6\" >0.4937</td>\n",
       "      <td id=\"T_1f3d2_row5_col7\" class=\"data row5 col7\" >0.6423</td>\n",
       "      <td id=\"T_1f3d2_row5_col8\" class=\"data row5 col8\" >0.7477</td>\n",
       "      <td id=\"T_1f3d2_row5_col9\" class=\"data row5 col9\" >0.9586</td>\n",
       "      <td id=\"T_1f3d2_row5_col10\" class=\"data row5 col10\" >0.7904</td>\n",
       "      <td id=\"T_1f3d2_row5_col11\" class=\"data row5 col11\" >0.8664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_1f3d2_row6_col0\" class=\"data row6 col0\" >LaLaLand</td>\n",
       "      <td id=\"T_1f3d2_row6_col1\" class=\"data row6 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row6_col2\" class=\"data row6 col2\" >0.8917</td>\n",
       "      <td id=\"T_1f3d2_row6_col3\" class=\"data row6 col3\" >0.3193</td>\n",
       "      <td id=\"T_1f3d2_row6_col4\" class=\"data row6 col4\" >0.4702</td>\n",
       "      <td id=\"T_1f3d2_row6_col5\" class=\"data row6 col5\" >0.9063</td>\n",
       "      <td id=\"T_1f3d2_row6_col6\" class=\"data row6 col6\" >0.4422</td>\n",
       "      <td id=\"T_1f3d2_row6_col7\" class=\"data row6 col7\" >0.5943</td>\n",
       "      <td id=\"T_1f3d2_row6_col8\" class=\"data row6 col8\" >0.7152</td>\n",
       "      <td id=\"T_1f3d2_row6_col9\" class=\"data row6 col9\" >0.8537</td>\n",
       "      <td id=\"T_1f3d2_row6_col10\" class=\"data row6 col10\" >0.7759</td>\n",
       "      <td id=\"T_1f3d2_row6_col11\" class=\"data row6 col11\" >0.8129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_1f3d2_row7_col0\" class=\"data row7 col0\" >LaLaLand</td>\n",
       "      <td id=\"T_1f3d2_row7_col1\" class=\"data row7 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row7_col2\" class=\"data row7 col2\" >0.9131</td>\n",
       "      <td id=\"T_1f3d2_row7_col3\" class=\"data row7 col3\" >0.3269</td>\n",
       "      <td id=\"T_1f3d2_row7_col4\" class=\"data row7 col4\" >0.4815</td>\n",
       "      <td id=\"T_1f3d2_row7_col5\" class=\"data row7 col5\" >0.9234</td>\n",
       "      <td id=\"T_1f3d2_row7_col6\" class=\"data row7 col6\" >0.4575</td>\n",
       "      <td id=\"T_1f3d2_row7_col7\" class=\"data row7 col7\" >0.6119</td>\n",
       "      <td id=\"T_1f3d2_row7_col8\" class=\"data row7 col8\" >0.7330</td>\n",
       "      <td id=\"T_1f3d2_row7_col9\" class=\"data row7 col9\" >0.8345</td>\n",
       "      <td id=\"T_1f3d2_row7_col10\" class=\"data row7 col10\" >0.7793</td>\n",
       "      <td id=\"T_1f3d2_row7_col11\" class=\"data row7 col11\" >0.8059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_1f3d2_row8_col0\" class=\"data row8 col0\" >Oppenheimer</td>\n",
       "      <td id=\"T_1f3d2_row8_col1\" class=\"data row8 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row8_col2\" class=\"data row8 col2\" >0.9384</td>\n",
       "      <td id=\"T_1f3d2_row8_col3\" class=\"data row8 col3\" >0.3207</td>\n",
       "      <td id=\"T_1f3d2_row8_col4\" class=\"data row8 col4\" >0.4781</td>\n",
       "      <td id=\"T_1f3d2_row8_col5\" class=\"data row8 col5\" >0.9470</td>\n",
       "      <td id=\"T_1f3d2_row8_col6\" class=\"data row8 col6\" >0.4611</td>\n",
       "      <td id=\"T_1f3d2_row8_col7\" class=\"data row8 col7\" >0.6202</td>\n",
       "      <td id=\"T_1f3d2_row8_col8\" class=\"data row8 col8\" >0.7611</td>\n",
       "      <td id=\"T_1f3d2_row8_col9\" class=\"data row8 col9\" >0.9905</td>\n",
       "      <td id=\"T_1f3d2_row8_col10\" class=\"data row8 col10\" >0.8556</td>\n",
       "      <td id=\"T_1f3d2_row8_col11\" class=\"data row8 col11\" >0.9181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_1f3d2_row9_col0\" class=\"data row9 col0\" >Oppenheimer</td>\n",
       "      <td id=\"T_1f3d2_row9_col1\" class=\"data row9 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row9_col2\" class=\"data row9 col2\" >0.9444</td>\n",
       "      <td id=\"T_1f3d2_row9_col3\" class=\"data row9 col3\" >0.3228</td>\n",
       "      <td id=\"T_1f3d2_row9_col4\" class=\"data row9 col4\" >0.4811</td>\n",
       "      <td id=\"T_1f3d2_row9_col5\" class=\"data row9 col5\" >0.9505</td>\n",
       "      <td id=\"T_1f3d2_row9_col6\" class=\"data row9 col6\" >0.4651</td>\n",
       "      <td id=\"T_1f3d2_row9_col7\" class=\"data row9 col7\" >0.6246</td>\n",
       "      <td id=\"T_1f3d2_row9_col8\" class=\"data row9 col8\" >0.7689</td>\n",
       "      <td id=\"T_1f3d2_row9_col9\" class=\"data row9 col9\" >0.9888</td>\n",
       "      <td id=\"T_1f3d2_row9_col10\" class=\"data row9 col10\" >0.8583</td>\n",
       "      <td id=\"T_1f3d2_row9_col11\" class=\"data row9 col11\" >0.9189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_1f3d2_row10_col0\" class=\"data row10 col0\" >Parasite</td>\n",
       "      <td id=\"T_1f3d2_row10_col1\" class=\"data row10 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row10_col2\" class=\"data row10 col2\" >0.9003</td>\n",
       "      <td id=\"T_1f3d2_row10_col3\" class=\"data row10 col3\" >0.3598</td>\n",
       "      <td id=\"T_1f3d2_row10_col4\" class=\"data row10 col4\" >0.5142</td>\n",
       "      <td id=\"T_1f3d2_row10_col5\" class=\"data row10 col5\" >0.9071</td>\n",
       "      <td id=\"T_1f3d2_row10_col6\" class=\"data row10 col6\" >0.4748</td>\n",
       "      <td id=\"T_1f3d2_row10_col7\" class=\"data row10 col7\" >0.6234</td>\n",
       "      <td id=\"T_1f3d2_row10_col8\" class=\"data row10 col8\" >0.7275</td>\n",
       "      <td id=\"T_1f3d2_row10_col9\" class=\"data row10 col9\" >0.9527</td>\n",
       "      <td id=\"T_1f3d2_row10_col10\" class=\"data row10 col10\" >0.9086</td>\n",
       "      <td id=\"T_1f3d2_row10_col11\" class=\"data row10 col11\" >0.9301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_1f3d2_row11_col0\" class=\"data row11 col0\" >Parasite</td>\n",
       "      <td id=\"T_1f3d2_row11_col1\" class=\"data row11 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row11_col2\" class=\"data row11 col2\" >0.9053</td>\n",
       "      <td id=\"T_1f3d2_row11_col3\" class=\"data row11 col3\" >0.3618</td>\n",
       "      <td id=\"T_1f3d2_row11_col4\" class=\"data row11 col4\" >0.5170</td>\n",
       "      <td id=\"T_1f3d2_row11_col5\" class=\"data row11 col5\" >0.9099</td>\n",
       "      <td id=\"T_1f3d2_row11_col6\" class=\"data row11 col6\" >0.4826</td>\n",
       "      <td id=\"T_1f3d2_row11_col7\" class=\"data row11 col7\" >0.6307</td>\n",
       "      <td id=\"T_1f3d2_row11_col8\" class=\"data row11 col8\" >0.7408</td>\n",
       "      <td id=\"T_1f3d2_row11_col9\" class=\"data row11 col9\" >0.9486</td>\n",
       "      <td id=\"T_1f3d2_row11_col10\" class=\"data row11 col10\" >0.9197</td>\n",
       "      <td id=\"T_1f3d2_row11_col11\" class=\"data row11 col11\" >0.9339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_1f3d2_row12_col0\" class=\"data row12 col0\" >SW_Episode1</td>\n",
       "      <td id=\"T_1f3d2_row12_col1\" class=\"data row12 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row12_col2\" class=\"data row12 col2\" >0.9005</td>\n",
       "      <td id=\"T_1f3d2_row12_col3\" class=\"data row12 col3\" >0.3608</td>\n",
       "      <td id=\"T_1f3d2_row12_col4\" class=\"data row12 col4\" >0.5152</td>\n",
       "      <td id=\"T_1f3d2_row12_col5\" class=\"data row12 col5\" >0.9050</td>\n",
       "      <td id=\"T_1f3d2_row12_col6\" class=\"data row12 col6\" >0.4816</td>\n",
       "      <td id=\"T_1f3d2_row12_col7\" class=\"data row12 col7\" >0.6287</td>\n",
       "      <td id=\"T_1f3d2_row12_col8\" class=\"data row12 col8\" >0.7058</td>\n",
       "      <td id=\"T_1f3d2_row12_col9\" class=\"data row12 col9\" >0.8969</td>\n",
       "      <td id=\"T_1f3d2_row12_col10\" class=\"data row12 col10\" >0.8293</td>\n",
       "      <td id=\"T_1f3d2_row12_col11\" class=\"data row12 col11\" >0.8618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_1f3d2_row13_col0\" class=\"data row13 col0\" >SW_Episode1</td>\n",
       "      <td id=\"T_1f3d2_row13_col1\" class=\"data row13 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row13_col2\" class=\"data row13 col2\" >0.9078</td>\n",
       "      <td id=\"T_1f3d2_row13_col3\" class=\"data row13 col3\" >0.3638</td>\n",
       "      <td id=\"T_1f3d2_row13_col4\" class=\"data row13 col4\" >0.5194</td>\n",
       "      <td id=\"T_1f3d2_row13_col5\" class=\"data row13 col5\" >0.9140</td>\n",
       "      <td id=\"T_1f3d2_row13_col6\" class=\"data row13 col6\" >0.4888</td>\n",
       "      <td id=\"T_1f3d2_row13_col7\" class=\"data row13 col7\" >0.6370</td>\n",
       "      <td id=\"T_1f3d2_row13_col8\" class=\"data row13 col8\" >0.7188</td>\n",
       "      <td id=\"T_1f3d2_row13_col9\" class=\"data row13 col9\" >0.8840</td>\n",
       "      <td id=\"T_1f3d2_row13_col10\" class=\"data row13 col10\" >0.8561</td>\n",
       "      <td id=\"T_1f3d2_row13_col11\" class=\"data row13 col11\" >0.8698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_1f3d2_row14_col0\" class=\"data row14 col0\" >SW_Episode2</td>\n",
       "      <td id=\"T_1f3d2_row14_col1\" class=\"data row14 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row14_col2\" class=\"data row14 col2\" >0.9166</td>\n",
       "      <td id=\"T_1f3d2_row14_col3\" class=\"data row14 col3\" >0.3450</td>\n",
       "      <td id=\"T_1f3d2_row14_col4\" class=\"data row14 col4\" >0.5013</td>\n",
       "      <td id=\"T_1f3d2_row14_col5\" class=\"data row14 col5\" >0.9295</td>\n",
       "      <td id=\"T_1f3d2_row14_col6\" class=\"data row14 col6\" >0.4709</td>\n",
       "      <td id=\"T_1f3d2_row14_col7\" class=\"data row14 col7\" >0.6251</td>\n",
       "      <td id=\"T_1f3d2_row14_col8\" class=\"data row14 col8\" >0.7218</td>\n",
       "      <td id=\"T_1f3d2_row14_col9\" class=\"data row14 col9\" >0.8875</td>\n",
       "      <td id=\"T_1f3d2_row14_col10\" class=\"data row14 col10\" >0.8342</td>\n",
       "      <td id=\"T_1f3d2_row14_col11\" class=\"data row14 col11\" >0.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_1f3d2_row15_col0\" class=\"data row15 col0\" >SW_Episode2</td>\n",
       "      <td id=\"T_1f3d2_row15_col1\" class=\"data row15 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row15_col2\" class=\"data row15 col2\" >0.9306</td>\n",
       "      <td id=\"T_1f3d2_row15_col3\" class=\"data row15 col3\" >0.3503</td>\n",
       "      <td id=\"T_1f3d2_row15_col4\" class=\"data row15 col4\" >0.5090</td>\n",
       "      <td id=\"T_1f3d2_row15_col5\" class=\"data row15 col5\" >0.9311</td>\n",
       "      <td id=\"T_1f3d2_row15_col6\" class=\"data row15 col6\" >0.4759</td>\n",
       "      <td id=\"T_1f3d2_row15_col7\" class=\"data row15 col7\" >0.6299</td>\n",
       "      <td id=\"T_1f3d2_row15_col8\" class=\"data row15 col8\" >0.7356</td>\n",
       "      <td id=\"T_1f3d2_row15_col9\" class=\"data row15 col9\" >0.8753</td>\n",
       "      <td id=\"T_1f3d2_row15_col10\" class=\"data row15 col10\" >0.8497</td>\n",
       "      <td id=\"T_1f3d2_row15_col11\" class=\"data row15 col11\" >0.8623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_1f3d2_row16_col0\" class=\"data row16 col0\" >SW_Episode3</td>\n",
       "      <td id=\"T_1f3d2_row16_col1\" class=\"data row16 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row16_col2\" class=\"data row16 col2\" >0.9185</td>\n",
       "      <td id=\"T_1f3d2_row16_col3\" class=\"data row16 col3\" >0.3386</td>\n",
       "      <td id=\"T_1f3d2_row16_col4\" class=\"data row16 col4\" >0.4948</td>\n",
       "      <td id=\"T_1f3d2_row16_col5\" class=\"data row16 col5\" >0.9327</td>\n",
       "      <td id=\"T_1f3d2_row16_col6\" class=\"data row16 col6\" >0.4634</td>\n",
       "      <td id=\"T_1f3d2_row16_col7\" class=\"data row16 col7\" >0.6192</td>\n",
       "      <td id=\"T_1f3d2_row16_col8\" class=\"data row16 col8\" >0.7096</td>\n",
       "      <td id=\"T_1f3d2_row16_col9\" class=\"data row16 col9\" >0.9489</td>\n",
       "      <td id=\"T_1f3d2_row16_col10\" class=\"data row16 col10\" >0.8547</td>\n",
       "      <td id=\"T_1f3d2_row16_col11\" class=\"data row16 col11\" >0.8993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_1f3d2_row17_col0\" class=\"data row17 col0\" >SW_Episode3</td>\n",
       "      <td id=\"T_1f3d2_row17_col1\" class=\"data row17 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row17_col2\" class=\"data row17 col2\" >0.9289</td>\n",
       "      <td id=\"T_1f3d2_row17_col3\" class=\"data row17 col3\" >0.3425</td>\n",
       "      <td id=\"T_1f3d2_row17_col4\" class=\"data row17 col4\" >0.5004</td>\n",
       "      <td id=\"T_1f3d2_row17_col5\" class=\"data row17 col5\" >0.9350</td>\n",
       "      <td id=\"T_1f3d2_row17_col6\" class=\"data row17 col6\" >0.4687</td>\n",
       "      <td id=\"T_1f3d2_row17_col7\" class=\"data row17 col7\" >0.6244</td>\n",
       "      <td id=\"T_1f3d2_row17_col8\" class=\"data row17 col8\" >0.7220</td>\n",
       "      <td id=\"T_1f3d2_row17_col9\" class=\"data row17 col9\" >0.9852</td>\n",
       "      <td id=\"T_1f3d2_row17_col10\" class=\"data row17 col10\" >0.7820</td>\n",
       "      <td id=\"T_1f3d2_row17_col11\" class=\"data row17 col11\" >0.8719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_1f3d2_row18_col0\" class=\"data row18 col0\" >SW_Episode4</td>\n",
       "      <td id=\"T_1f3d2_row18_col1\" class=\"data row18 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row18_col2\" class=\"data row18 col2\" >0.9030</td>\n",
       "      <td id=\"T_1f3d2_row18_col3\" class=\"data row18 col3\" >0.3709</td>\n",
       "      <td id=\"T_1f3d2_row18_col4\" class=\"data row18 col4\" >0.5259</td>\n",
       "      <td id=\"T_1f3d2_row18_col5\" class=\"data row18 col5\" >0.9205</td>\n",
       "      <td id=\"T_1f3d2_row18_col6\" class=\"data row18 col6\" >0.4966</td>\n",
       "      <td id=\"T_1f3d2_row18_col7\" class=\"data row18 col7\" >0.6452</td>\n",
       "      <td id=\"T_1f3d2_row18_col8\" class=\"data row18 col8\" >0.7376</td>\n",
       "      <td id=\"T_1f3d2_row18_col9\" class=\"data row18 col9\" >0.8414</td>\n",
       "      <td id=\"T_1f3d2_row18_col10\" class=\"data row18 col10\" >0.8198</td>\n",
       "      <td id=\"T_1f3d2_row18_col11\" class=\"data row18 col11\" >0.8304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_1f3d2_row19_col0\" class=\"data row19 col0\" >SW_Episode4</td>\n",
       "      <td id=\"T_1f3d2_row19_col1\" class=\"data row19 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row19_col2\" class=\"data row19 col2\" >0.9117</td>\n",
       "      <td id=\"T_1f3d2_row19_col3\" class=\"data row19 col3\" >0.3745</td>\n",
       "      <td id=\"T_1f3d2_row19_col4\" class=\"data row19 col4\" >0.5309</td>\n",
       "      <td id=\"T_1f3d2_row19_col5\" class=\"data row19 col5\" >0.9299</td>\n",
       "      <td id=\"T_1f3d2_row19_col6\" class=\"data row19 col6\" >0.5079</td>\n",
       "      <td id=\"T_1f3d2_row19_col7\" class=\"data row19 col7\" >0.6570</td>\n",
       "      <td id=\"T_1f3d2_row19_col8\" class=\"data row19 col8\" >0.7416</td>\n",
       "      <td id=\"T_1f3d2_row19_col9\" class=\"data row19 col9\" >0.8303</td>\n",
       "      <td id=\"T_1f3d2_row19_col10\" class=\"data row19 col10\" >0.8376</td>\n",
       "      <td id=\"T_1f3d2_row19_col11\" class=\"data row19 col11\" >0.8339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_1f3d2_row20_col0\" class=\"data row20 col0\" >SW_Episode5</td>\n",
       "      <td id=\"T_1f3d2_row20_col1\" class=\"data row20 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row20_col2\" class=\"data row20 col2\" >0.9072</td>\n",
       "      <td id=\"T_1f3d2_row20_col3\" class=\"data row20 col3\" >0.3721</td>\n",
       "      <td id=\"T_1f3d2_row20_col4\" class=\"data row20 col4\" >0.5277</td>\n",
       "      <td id=\"T_1f3d2_row20_col5\" class=\"data row20 col5\" >0.9203</td>\n",
       "      <td id=\"T_1f3d2_row20_col6\" class=\"data row20 col6\" >0.4873</td>\n",
       "      <td id=\"T_1f3d2_row20_col7\" class=\"data row20 col7\" >0.6372</td>\n",
       "      <td id=\"T_1f3d2_row20_col8\" class=\"data row20 col8\" >0.7158</td>\n",
       "      <td id=\"T_1f3d2_row20_col9\" class=\"data row20 col9\" >0.9032</td>\n",
       "      <td id=\"T_1f3d2_row20_col10\" class=\"data row20 col10\" >0.8145</td>\n",
       "      <td id=\"T_1f3d2_row20_col11\" class=\"data row20 col11\" >0.8566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_1f3d2_row21_col0\" class=\"data row21 col0\" >SW_Episode5</td>\n",
       "      <td id=\"T_1f3d2_row21_col1\" class=\"data row21 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row21_col2\" class=\"data row21 col2\" >0.9165</td>\n",
       "      <td id=\"T_1f3d2_row21_col3\" class=\"data row21 col3\" >0.3759</td>\n",
       "      <td id=\"T_1f3d2_row21_col4\" class=\"data row21 col4\" >0.5331</td>\n",
       "      <td id=\"T_1f3d2_row21_col5\" class=\"data row21 col5\" >0.9249</td>\n",
       "      <td id=\"T_1f3d2_row21_col6\" class=\"data row21 col6\" >0.4988</td>\n",
       "      <td id=\"T_1f3d2_row21_col7\" class=\"data row21 col7\" >0.6480</td>\n",
       "      <td id=\"T_1f3d2_row21_col8\" class=\"data row21 col8\" >0.7357</td>\n",
       "      <td id=\"T_1f3d2_row21_col9\" class=\"data row21 col9\" >0.9001</td>\n",
       "      <td id=\"T_1f3d2_row21_col10\" class=\"data row21 col10\" >0.8232</td>\n",
       "      <td id=\"T_1f3d2_row21_col11\" class=\"data row21 col11\" >0.8599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_1f3d2_row22_col0\" class=\"data row22 col0\" >SW_Episode6</td>\n",
       "      <td id=\"T_1f3d2_row22_col1\" class=\"data row22 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row22_col2\" class=\"data row22 col2\" >0.9199</td>\n",
       "      <td id=\"T_1f3d2_row22_col3\" class=\"data row22 col3\" >0.3577</td>\n",
       "      <td id=\"T_1f3d2_row22_col4\" class=\"data row22 col4\" >0.5151</td>\n",
       "      <td id=\"T_1f3d2_row22_col5\" class=\"data row22 col5\" >0.9155</td>\n",
       "      <td id=\"T_1f3d2_row22_col6\" class=\"data row22 col6\" >0.4677</td>\n",
       "      <td id=\"T_1f3d2_row22_col7\" class=\"data row22 col7\" >0.6191</td>\n",
       "      <td id=\"T_1f3d2_row22_col8\" class=\"data row22 col8\" >0.6973</td>\n",
       "      <td id=\"T_1f3d2_row22_col9\" class=\"data row22 col9\" >0.9296</td>\n",
       "      <td id=\"T_1f3d2_row22_col10\" class=\"data row22 col10\" >0.7500</td>\n",
       "      <td id=\"T_1f3d2_row22_col11\" class=\"data row22 col11\" >0.8302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_1f3d2_row23_col0\" class=\"data row23 col0\" >SW_Episode6</td>\n",
       "      <td id=\"T_1f3d2_row23_col1\" class=\"data row23 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row23_col2\" class=\"data row23 col2\" >0.9206</td>\n",
       "      <td id=\"T_1f3d2_row23_col3\" class=\"data row23 col3\" >0.3580</td>\n",
       "      <td id=\"T_1f3d2_row23_col4\" class=\"data row23 col4\" >0.5155</td>\n",
       "      <td id=\"T_1f3d2_row23_col5\" class=\"data row23 col5\" >0.9181</td>\n",
       "      <td id=\"T_1f3d2_row23_col6\" class=\"data row23 col6\" >0.4778</td>\n",
       "      <td id=\"T_1f3d2_row23_col7\" class=\"data row23 col7\" >0.6285</td>\n",
       "      <td id=\"T_1f3d2_row23_col8\" class=\"data row23 col8\" >0.7169</td>\n",
       "      <td id=\"T_1f3d2_row23_col9\" class=\"data row23 col9\" >0.9274</td>\n",
       "      <td id=\"T_1f3d2_row23_col10\" class=\"data row23 col10\" >0.7610</td>\n",
       "      <td id=\"T_1f3d2_row23_col11\" class=\"data row23 col11\" >0.8360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_1f3d2_row24_col0\" class=\"data row24 col0\" >SW_Episode7</td>\n",
       "      <td id=\"T_1f3d2_row24_col1\" class=\"data row24 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row24_col2\" class=\"data row24 col2\" >0.8964</td>\n",
       "      <td id=\"T_1f3d2_row24_col3\" class=\"data row24 col3\" >0.3609</td>\n",
       "      <td id=\"T_1f3d2_row24_col4\" class=\"data row24 col4\" >0.5147</td>\n",
       "      <td id=\"T_1f3d2_row24_col5\" class=\"data row24 col5\" >0.9146</td>\n",
       "      <td id=\"T_1f3d2_row24_col6\" class=\"data row24 col6\" >0.4898</td>\n",
       "      <td id=\"T_1f3d2_row24_col7\" class=\"data row24 col7\" >0.6379</td>\n",
       "      <td id=\"T_1f3d2_row24_col8\" class=\"data row24 col8\" >0.7296</td>\n",
       "      <td id=\"T_1f3d2_row24_col9\" class=\"data row24 col9\" >0.9514</td>\n",
       "      <td id=\"T_1f3d2_row24_col10\" class=\"data row24 col10\" >0.8754</td>\n",
       "      <td id=\"T_1f3d2_row24_col11\" class=\"data row24 col11\" >0.9118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_1f3d2_row25_col0\" class=\"data row25 col0\" >SW_Episode7</td>\n",
       "      <td id=\"T_1f3d2_row25_col1\" class=\"data row25 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row25_col2\" class=\"data row25 col2\" >0.9100</td>\n",
       "      <td id=\"T_1f3d2_row25_col3\" class=\"data row25 col3\" >0.3664</td>\n",
       "      <td id=\"T_1f3d2_row25_col4\" class=\"data row25 col4\" >0.5224</td>\n",
       "      <td id=\"T_1f3d2_row25_col5\" class=\"data row25 col5\" >0.9190</td>\n",
       "      <td id=\"T_1f3d2_row25_col6\" class=\"data row25 col6\" >0.4961</td>\n",
       "      <td id=\"T_1f3d2_row25_col7\" class=\"data row25 col7\" >0.6443</td>\n",
       "      <td id=\"T_1f3d2_row25_col8\" class=\"data row25 col8\" >0.7478</td>\n",
       "      <td id=\"T_1f3d2_row25_col9\" class=\"data row25 col9\" >0.9442</td>\n",
       "      <td id=\"T_1f3d2_row25_col10\" class=\"data row25 col10\" >0.9181</td>\n",
       "      <td id=\"T_1f3d2_row25_col11\" class=\"data row25 col11\" >0.9310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_1f3d2_row26_col0\" class=\"data row26 col0\" >SW_Episode8</td>\n",
       "      <td id=\"T_1f3d2_row26_col1\" class=\"data row26 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row26_col2\" class=\"data row26 col2\" >0.8951</td>\n",
       "      <td id=\"T_1f3d2_row26_col3\" class=\"data row26 col3\" >0.3662</td>\n",
       "      <td id=\"T_1f3d2_row26_col4\" class=\"data row26 col4\" >0.5198</td>\n",
       "      <td id=\"T_1f3d2_row26_col5\" class=\"data row26 col5\" >0.9087</td>\n",
       "      <td id=\"T_1f3d2_row26_col6\" class=\"data row26 col6\" >0.4863</td>\n",
       "      <td id=\"T_1f3d2_row26_col7\" class=\"data row26 col7\" >0.6336</td>\n",
       "      <td id=\"T_1f3d2_row26_col8\" class=\"data row26 col8\" >0.7153</td>\n",
       "      <td id=\"T_1f3d2_row26_col9\" class=\"data row26 col9\" >0.9767</td>\n",
       "      <td id=\"T_1f3d2_row26_col10\" class=\"data row26 col10\" >0.8659</td>\n",
       "      <td id=\"T_1f3d2_row26_col11\" class=\"data row26 col11\" >0.9179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_1f3d2_row27_col0\" class=\"data row27 col0\" >SW_Episode8</td>\n",
       "      <td id=\"T_1f3d2_row27_col1\" class=\"data row27 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row27_col2\" class=\"data row27 col2\" >0.9063</td>\n",
       "      <td id=\"T_1f3d2_row27_col3\" class=\"data row27 col3\" >0.3708</td>\n",
       "      <td id=\"T_1f3d2_row27_col4\" class=\"data row27 col4\" >0.5263</td>\n",
       "      <td id=\"T_1f3d2_row27_col5\" class=\"data row27 col5\" >0.9165</td>\n",
       "      <td id=\"T_1f3d2_row27_col6\" class=\"data row27 col6\" >0.4962</td>\n",
       "      <td id=\"T_1f3d2_row27_col7\" class=\"data row27 col7\" >0.6438</td>\n",
       "      <td id=\"T_1f3d2_row27_col8\" class=\"data row27 col8\" >0.7294</td>\n",
       "      <td id=\"T_1f3d2_row27_col9\" class=\"data row27 col9\" >0.9749</td>\n",
       "      <td id=\"T_1f3d2_row27_col10\" class=\"data row27 col10\" >0.8761</td>\n",
       "      <td id=\"T_1f3d2_row27_col11\" class=\"data row27 col11\" >0.9228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_1f3d2_row28_col0\" class=\"data row28 col0\" >SW_Episode9</td>\n",
       "      <td id=\"T_1f3d2_row28_col1\" class=\"data row28 col1\" >base</td>\n",
       "      <td id=\"T_1f3d2_row28_col2\" class=\"data row28 col2\" >0.9167</td>\n",
       "      <td id=\"T_1f3d2_row28_col3\" class=\"data row28 col3\" >0.3629</td>\n",
       "      <td id=\"T_1f3d2_row28_col4\" class=\"data row28 col4\" >0.5200</td>\n",
       "      <td id=\"T_1f3d2_row28_col5\" class=\"data row28 col5\" >0.9192</td>\n",
       "      <td id=\"T_1f3d2_row28_col6\" class=\"data row28 col6\" >0.4781</td>\n",
       "      <td id=\"T_1f3d2_row28_col7\" class=\"data row28 col7\" >0.6291</td>\n",
       "      <td id=\"T_1f3d2_row28_col8\" class=\"data row28 col8\" >0.7199</td>\n",
       "      <td id=\"T_1f3d2_row28_col9\" class=\"data row28 col9\" >0.9791</td>\n",
       "      <td id=\"T_1f3d2_row28_col10\" class=\"data row28 col10\" >0.8786</td>\n",
       "      <td id=\"T_1f3d2_row28_col11\" class=\"data row28 col11\" >0.9262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f3d2_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_1f3d2_row29_col0\" class=\"data row29 col0\" >SW_Episode9</td>\n",
       "      <td id=\"T_1f3d2_row29_col1\" class=\"data row29 col1\" >metadata</td>\n",
       "      <td id=\"T_1f3d2_row29_col2\" class=\"data row29 col2\" >0.9235</td>\n",
       "      <td id=\"T_1f3d2_row29_col3\" class=\"data row29 col3\" >0.3656</td>\n",
       "      <td id=\"T_1f3d2_row29_col4\" class=\"data row29 col4\" >0.5238</td>\n",
       "      <td id=\"T_1f3d2_row29_col5\" class=\"data row29 col5\" >0.9273</td>\n",
       "      <td id=\"T_1f3d2_row29_col6\" class=\"data row29 col6\" >0.4861</td>\n",
       "      <td id=\"T_1f3d2_row29_col7\" class=\"data row29 col7\" >0.6378</td>\n",
       "      <td id=\"T_1f3d2_row29_col8\" class=\"data row29 col8\" >0.7301</td>\n",
       "      <td id=\"T_1f3d2_row29_col9\" class=\"data row29 col9\" >0.9780</td>\n",
       "      <td id=\"T_1f3d2_row29_col10\" class=\"data row29 col10\" >0.8817</td>\n",
       "      <td id=\"T_1f3d2_row29_col11\" class=\"data row29 col11\" >0.9274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x178729df0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings\n",
    "keywords_dir = \"../Dataset/Extracted_Keywords/\"\n",
    "ground_truth_path = \"../Dataset/keywords_ground_truth.pkl\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "models_to_evaluate = [\"base\", \"metadata\"]\n",
    "\n",
    "# Load ground truth\n",
    "keywords_ground_truth = pd.read_pickle(ground_truth_path)\n",
    "\n",
    "# Store all results\n",
    "all_results = []\n",
    "\n",
    "# Iterate over movie keyword predictions\n",
    "for file in os.listdir(keywords_dir):\n",
    "    if file.endswith(\".pkl\") and file.startswith(\"kw_\"):\n",
    "        movie_name = file.replace(\"kw_\", \"\").replace(\".pkl\", \"\")\n",
    "        file_path = os.path.join(keywords_dir, file)\n",
    "\n",
    "        try:\n",
    "            selected_film = pd.read_pickle(file_path)\n",
    "            selected_film_id = selected_film[\"Movie_ID\"].iloc[0]\n",
    "\n",
    "            # Ground truth per quel film\n",
    "            kw_ground_truth = keywords_ground_truth[keywords_ground_truth[\"Movie_ID\"] == selected_film_id]\n",
    "            gt_keywords = kw_ground_truth[\"Keyword\"].tolist()\n",
    "\n",
    "            # Init: predicted keyword lists (per review, no duplicates)\n",
    "            all_predicted_kw_score = {model: [] for model in models_to_evaluate}\n",
    "\n",
    "            for _, row in selected_film.iterrows():\n",
    "                for model in models_to_evaluate:\n",
    "                    pred_col = f\"keywords_{model}\"\n",
    "                    if pred_col in row and isinstance(row[pred_col], list):\n",
    "                        predicted_kw_score = [(normalize_kw(kw), score) for kw, score in row[pred_col] if isinstance(kw, str)]\n",
    "                        seen = set()\n",
    "                        unique_pred = [(kw, score) for kw, score in predicted_kw_score if kw not in seen and not seen.add(kw)]\n",
    "                        all_predicted_kw_score[model].append(unique_pred)\n",
    "\n",
    "            for model in models_to_evaluate:\n",
    "                # Flatten keywords (global unique list)\n",
    "                flat_kw = [kw for review in all_predicted_kw_score[model] for kw, _ in review]\n",
    "                unique_pred_keywords = list(set(flat_kw))\n",
    "\n",
    "                # Max score for each keyword\n",
    "                kw_score_max = {}\n",
    "                for review in all_predicted_kw_score[model]:\n",
    "                    for kw, score in review:\n",
    "                        if kw not in kw_score_max or score > kw_score_max[kw]:\n",
    "                            kw_score_max[kw] = score\n",
    "                sorted_kw_score = sorted(kw_score_max.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                # Score-aware format\n",
    "                pred_kw_score_list = all_predicted_kw_score[model]\n",
    "                keyword_only_list = [[kw for kw, _ in review] for review in pred_kw_score_list]\n",
    "\n",
    "                # Compute all metrics\n",
    "                p, r, f1 = evaluate_keywords(keyword_only_list, gt_keywords)\n",
    "                wp, wr, wf = evaluate_keywords_weighted(pred_kw_score_list, gt_keywords)\n",
    "                ndcg = compute_global_ndcg(pred_kw_score_list, gt_keywords, k=5)\n",
    "                sp, sr, sf1 = evaluate_semantic_keywords_global(unique_pred_keywords, gt_keywords, device=device)\n",
    "\n",
    "                all_results.append({\n",
    "                    \"Movie\": movie_name,\n",
    "                    \"Model\": model,\n",
    "                    \"Precision\": round(p, 4),\n",
    "                    \"Recall\": round(r, 4),\n",
    "                    \"F1-score\": round(f1, 4),\n",
    "                    \"Weighted Precision\": round(wp, 4),\n",
    "                    \"Weighted Recall\": round(wr, 4),\n",
    "                    \"Weighted F1-score\": round(wf, 4),\n",
    "                    \"nDCG@5\": round(ndcg, 4),\n",
    "                    \"Semantic Precision\": round(sp, 4),\n",
    "                    \"Semantic Recall\": round(sr, 4),\n",
    "                    \"Semantic F1-score\": round(sf1, 4),\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# Final summary\n",
    "final_df = pd.DataFrame(all_results)\n",
    "final_df_sorted = final_df.sort_values(by=[\"Movie\", \"Model\"]).reset_index(drop=True)\n",
    "final_df_sorted.style.format(precision=4).set_caption(\"Global Evaluation Summary per Movie and Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c31870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df \n",
    "final_df.to_csv(\"base_vs_metadata_evaluation.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
