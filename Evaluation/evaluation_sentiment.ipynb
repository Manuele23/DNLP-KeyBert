{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da421a1a",
   "metadata": {},
   "source": [
    "# Evaluation of KeyBERTSentimentAware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804715a2",
   "metadata": {},
   "source": [
    "This notebook evaluates and compares different keyword extraction models applied to movie reviews, with a specific focus on assessing how well each model captures not only **semantic relevance** but also **sentiment alignment** with the content of the reviews.\n",
    "\n",
    "We assess the performance of two models:\n",
    "\n",
    "- **Base** KeyBERT model  \n",
    "- **Sentiment-aware** extension (KeyBERTSentimentAware), which integrates a custom sentiment classifier to adjust keyword relevance scores based on predicted sentiment\n",
    "\n",
    "This notebook adopts a **global evaluation approach**: all predicted and ground truth keywords across the entire dataset are aggregated **before** computing each metric. This provides a **holistic view** of each model's performance, unaffected by review-level variance.\n",
    "\n",
    "We use a set of annotated ground truth keywords per movie (from IMDb), and the top-5 predicted keywords (with scores) per review for both models.\n",
    "\n",
    "#### **Evaluation Layers**\n",
    "\n",
    "#### 1. **Basic (Unweighted) Metrics**\n",
    "\n",
    "- **Precision**, **Recall**, and **F1-score** computed globally via approximate binary matching.\n",
    "- A predicted keyword is correct if it approximately matches any of the movie’s ground truth keywords.\n",
    "- All keywords from all reviews are flattened and compared in aggregate.\n",
    "\n",
    "#### 2. **Score-Aware Metrics**\n",
    "\n",
    "- **Weighted Precision**, **Recall**, and **F1-score**:\n",
    "  - Each predicted keyword is weighted by its score.\n",
    "  - Correct predictions contribute proportionally to their confidence.\n",
    "- **nDCG@5 (Normalized Discounted Cumulative Gain)**:\n",
    "  - Evaluates whether correct keywords are ranked near the top globally.\n",
    "  - Relevance is discounted by position, rewarding better keyword orderings.\n",
    "\n",
    "#### 3. **Semantic Evaluation (Embedding-Based)**\n",
    "\n",
    "- All predicted and ground truth keywords are embedded using a **sentence-transformer** model.\n",
    "- **Cosine similarity** is used to detect approximate **semantic matches**.\n",
    "- A predicted keyword is correct if its similarity with any ground truth keyword exceeds a given threshold (e.g., **0.75**).\n",
    "- **Semantic Precision**, **Recall**, and **F1-score** are computed globally based on these soft matches.\n",
    "\n",
    "#### 4. **Sentiment Appropriateness Score (SAS)**\n",
    "\n",
    "This novel metric evaluates **how well the sentiment of predicted keywords aligns with the sentiment of the review**.\n",
    "\n",
    "Two global variants are computed:\n",
    "\n",
    "- **SAS_from_keywords**:  \n",
    "  - Computes the average sentiment of predicted keywords (via VADER or custom classifier).  \n",
    "  - Compares it to the average sentiment of the ground truth keywords for the movie.\n",
    "\n",
    "- **SAS_from_text**:  \n",
    "  - Compares the average sentiment of the predicted keywords to the sentiment of the **full review text**.\n",
    "\n",
    "SAS values are normalized in [0, 1], where values closer to 1 indicate higher emotional coherence.\n",
    "\n",
    "#### **Why Sentiment-Aware Evaluation Matters**\n",
    "\n",
    "The **base** KeyBERT model selects keywords based only on semantic relevance, while the **sentiment-aware** version ranks keywords based on a combination of **semantic and emotional cues**.\n",
    "\n",
    "Traditional evaluations may overlook whether the extracted keywords convey the **emotional tone** of the review.  \n",
    "By introducing **Sentiment Appropriateness Scores**, we quantify this alignment explicitly and verify whether integrating sentiment enhances both **relevance** and **emotional fidelity**.\n",
    "\n",
    "This global, multi-dimensional evaluation provides a robust framework for comparing keyword extraction systems beyond surface-level matching.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7526626c",
   "metadata": {},
   "source": [
    "## Setup: Installing and Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0baee66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy is already installed.\n",
      "pandas is already installed.\n",
      "torch is already installed.\n",
      "transformers is already installed.\n",
      "tqdm is already installed.\n",
      "vaderSentiment is already installed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of required packages\n",
    "required_packages = {\n",
    "    \"pandas\", \"numpy\", \"tqdm\", \"transformers\", \"torch\", \"vaderSentiment\"\n",
    "}\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip if it's not already installed.\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"{package} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Check and install missing packages\n",
    "for package in required_packages:\n",
    "    install_package(package)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "973bef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import os      # File system operations (e.g., listing files)\n",
    "import re      # Regular expressions for text processing\n",
    "import math    # Mathematical functions (e.g., log2)\n",
    "\n",
    "# Third-Party Libraries\n",
    "import pandas as pd                  # Data manipulation with DataFrames\n",
    "import numpy as np                   # Numerical computations and array operations\n",
    "from tqdm import tqdm                # Progress bars for loops\n",
    "\n",
    "# Transformers and PyTorch for embeddings and models\n",
    "from transformers import AutoTokenizer, AutoModel # type:ignore\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Sentiment Analysis\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b9ee47",
   "metadata": {},
   "source": [
    "## Load Available Movies from Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189c179",
   "metadata": {},
   "source": [
    "This section lists all the available movies stored as `.pkl` files inside the review dataset directory.\n",
    "\n",
    "- It defines the root path (`../Dataset/Reviews_By_Movie`) where all review files are saved.\n",
    "- It automatically detects and lists all movie filenames (removing the `.pkl` extension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55796a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available movies: ['GoodBadUgly', 'HarryPotter', 'IndianaJones', 'LaLaLand', 'Oppenheimer', 'Parasite', 'SW_Episode1', 'SW_Episode2', 'SW_Episode3', 'SW_Episode4', 'SW_Episode5', 'SW_Episode6', 'SW_Episode7', 'SW_Episode8', 'SW_Episode9']\n"
     ]
    }
   ],
   "source": [
    "# Define root directory\n",
    "root_dir = \"../Dataset/Reviews_By_Movie\"\n",
    "\n",
    "# List all available movies\n",
    "available_movies = sorted([f[:-4] for f in os.listdir(root_dir) if f.endswith(\".pkl\")])\n",
    "print(\"Available movies:\", available_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3edbda1",
   "metadata": {},
   "source": [
    "## Select a Movie and Load its Ground Truth Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42602be9",
   "metadata": {},
   "source": [
    "In this step, we load the keyword extraction results for a specific movie and retrieve the corresponding ground truth keywords. The goal is to use these annotated keywords for evaluation and comparison with automatically extracted ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71a8e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the movie to be evaluated\n",
    "movie_name = \"IndianaJones\"\n",
    "\n",
    "# Load the extracted keywords for the selected movie from a pickle file\n",
    "# The file path is dynamically built using the movie name\n",
    "selected_film = pd.read_pickle(f\"../Dataset/Extracted_Keywords/kw_{movie_name}.pkl\")\n",
    "\n",
    "# Retrieve the Movie_ID of the selected film\n",
    "# Assumes that the file contains a DataFrame with at least one row\n",
    "selected_film_id = selected_film[\"Movie_ID\"].iloc[0]\n",
    "\n",
    "# Load the full dataset containing the ground truth keywords\n",
    "# for all movies in the evaluation set\n",
    "keywords = pd.read_pickle(\"../Dataset/keywords_ground_truth.pkl\")\n",
    "\n",
    "# Filter the ground truth dataset to extract only the keywords for the selected movie\n",
    "kw_ground_truth = keywords[keywords[\"Movie_ID\"] == selected_film_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5fd95b",
   "metadata": {},
   "source": [
    "## Keyword Matching and Evaluation Functions (Basic – Unweighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c9a94a",
   "metadata": {},
   "source": [
    "This block defines the core utility functions used to evaluate predicted keywords against the ground truth. These functions perform a **binary, unweighted evaluation**, ignoring confidence scores and ranking information.\n",
    "\n",
    "The evaluation pipeline includes the following steps:\n",
    "\n",
    "- **Normalization**: all keywords are lowercased, stripped of punctuation, and cleaned of extra whitespace to ensure consistent text matching.\n",
    "\n",
    "- **Approximate Matching**: a relaxed rule considers two keywords as a match if:\n",
    "  - They are exactly equal (after normalization), or\n",
    "  - One is a substring of the other (e.g., *\"social satire\"* is considered a match with *\"satire\"*).\n",
    "\n",
    "- **Global Evaluation**: for each model, all keywords predicted across the reviews of a given movie are aggregated, and then compared to the global set of ground truth keywords for that movie.\n",
    "\n",
    "- **Metrics**: we compute **Precision**, **Recall**, and **F1-score** based on the number of approximate matches between the predicted and ground truth keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f79c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_kw(kw):\n",
    "    \"\"\"\n",
    "    Normalize a keyword string by:\n",
    "    - Converting to lowercase\n",
    "    - Removing punctuation and non-alphanumeric characters (except spaces)\n",
    "    - Stripping leading and trailing whitespace\n",
    "\n",
    "    Args:\n",
    "        kw (str): The keyword string to normalize.\n",
    "\n",
    "    Returns:\n",
    "        str: The normalized keyword.\n",
    "    \"\"\"\n",
    "    kw = kw.lower()\n",
    "    kw = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", kw)  # Keep only alphanumeric characters and whitespace\n",
    "    return kw.strip()\n",
    "\n",
    "\n",
    "def is_approx_match(kw, gt_keywords):\n",
    "    \"\"\"\n",
    "    Check if a predicted keyword approximately matches any ground truth keyword.\n",
    "\n",
    "    A match is considered approximate if:\n",
    "    - The predicted keyword is exactly equal to a ground truth keyword\n",
    "    - OR the predicted keyword is a substring of a ground truth keyword\n",
    "    - OR a ground truth keyword is a substring of the predicted one\n",
    "\n",
    "    Args:\n",
    "        kw (str): The normalized predicted keyword.\n",
    "        gt_keywords (List[str]): A list of normalized ground truth keywords.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if an approximate match is found, False otherwise.\n",
    "    \"\"\"\n",
    "    for gt in gt_keywords:\n",
    "        if kw == gt or kw in gt or gt in kw:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def evaluate_keywords(all_pred_keywords, all_gt_keywords):\n",
    "    \"\"\"\n",
    "    Evaluate global precision, recall, and F1-score across a dataset using approximate matching.\n",
    "\n",
    "    This function compares predicted keywords to ground truth keywords for each review.\n",
    "    Matching is performed using approximate string comparison, and each ground truth keyword\n",
    "    can be matched only once to ensure fairness. The metrics are aggregated globally,\n",
    "    not per-review.\n",
    "\n",
    "    Args:\n",
    "        all_pred_keywords (List[List[str]]): \n",
    "            A list where each element is a list of predicted keywords for a single review.\n",
    "        all_gt_keywords (List[List[str]]): \n",
    "            A list where each element is a list of ground truth keywords for the corresponding review.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float]: Global precision, recall, and F1-score based on approximate matching.\n",
    "    \"\"\"\n",
    "    global_match_count = 0     # Total number of matched keywords across all reviews\n",
    "    global_pred_count = 0      # Total number of predicted keywords\n",
    "    global_gt_count = 0        # Total number of ground truth keywords\n",
    "\n",
    "    # Iterate through each review's predictions and ground truths\n",
    "    for pred_keywords, gt_keywords in zip(all_pred_keywords, all_gt_keywords):\n",
    "        # Normalize and sort keywords to ensure consistent behavior\n",
    "        pred_keywords = sorted([normalize_kw(k) for k in pred_keywords])\n",
    "        gt_keywords = sorted([normalize_kw(k) for k in gt_keywords])\n",
    "\n",
    "        global_pred_count += len(pred_keywords)\n",
    "        global_gt_count += len(gt_keywords)\n",
    "\n",
    "        matched_gts = set()  # Track which ground truth keywords have already been matched\n",
    "\n",
    "        for pred in pred_keywords:\n",
    "            for gt in gt_keywords:\n",
    "                if gt not in matched_gts and is_approx_match(pred, [gt]):\n",
    "                    global_match_count += 1\n",
    "                    matched_gts.add(gt)  # Avoid matching the same GT keyword multiple times\n",
    "                    break\n",
    "\n",
    "    # Compute global metrics\n",
    "    precision = global_match_count / global_pred_count if global_pred_count else 0\n",
    "    recall = global_match_count / global_gt_count if global_gt_count else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0cda19",
   "metadata": {},
   "source": [
    "### Evaluate and Compare Models on Keyword Extraction (Basic – Unweighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd0199",
   "metadata": {},
   "source": [
    "This section evaluates two keyword extraction models — **base** and **sentiment-enhanced** — against the ground truth annotations.\n",
    "\n",
    "For each model, we collect all predicted keywords across all reviews in the selected movie and compare them to the ground truth keywords using **binary approximate matching**.\n",
    "\n",
    "The evaluation computes **global precision, recall, and F1-score**, considering the entire set of predictions and ground truth keywords as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d333544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1016f\">\n",
       "  <caption>Global Evaluation Summary</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1016f_level0_col0\" class=\"col_heading level0 col0\" >Precision</th>\n",
       "      <th id=\"T_1016f_level0_col1\" class=\"col_heading level0 col1\" >Recall</th>\n",
       "      <th id=\"T_1016f_level0_col2\" class=\"col_heading level0 col2\" >F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1016f_level0_row0\" class=\"row_heading level0 row0\" >base</th>\n",
       "      <td id=\"T_1016f_row0_col0\" class=\"data row0 col0\" >0.9125</td>\n",
       "      <td id=\"T_1016f_row0_col1\" class=\"data row0 col1\" >0.3685</td>\n",
       "      <td id=\"T_1016f_row0_col2\" class=\"data row0 col2\" >0.5250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1016f_level0_row1\" class=\"row_heading level0 row1\" >sentiment</th>\n",
       "      <td id=\"T_1016f_row1_col0\" class=\"data row1 col0\" >0.8805</td>\n",
       "      <td id=\"T_1016f_row1_col1\" class=\"data row1 col1\" >0.3391</td>\n",
       "      <td id=\"T_1016f_row1_col2\" class=\"data row1 col2\" >0.4896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x178c25850>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the models to be evaluated\n",
    "models_to_evaluate = [\"base\", \"sentiment\"]\n",
    "\n",
    "# Extract the list of ground truth keywords for the selected movie\n",
    "ground_truth_keywords = [normalize_kw(kw) for kw in kw_ground_truth[\"Keyword\"].tolist()]\n",
    "\n",
    "# Dictionary to store all predicted keywords per model (across all reviews)\n",
    "all_predictions = {model: [] for model in models_to_evaluate}\n",
    "\n",
    "# Iterate over each review in the selected film's predictions\n",
    "for _, row in selected_film.iterrows():\n",
    "    for model in models_to_evaluate:\n",
    "        pred_col = f\"keywords_{model}\"\n",
    "\n",
    "        if pred_col in row and isinstance(row[pred_col], list):\n",
    "            predicted_keywords = [\n",
    "                normalize_kw(kw) for kw, _ in row[pred_col] if isinstance(kw, str)\n",
    "            ]\n",
    "            \n",
    "            # Remove duplicates per review\n",
    "            seen = set()\n",
    "            unique_kw = [kw for kw in predicted_keywords if kw not in seen and not seen.add(kw)]\n",
    "\n",
    "            all_predictions[model].append(unique_kw)\n",
    "\n",
    "# Evaluate each model globally\n",
    "summary = {}\n",
    "for model in models_to_evaluate:\n",
    "    precision, recall, f1 = evaluate_keywords(\n",
    "        all_predictions[model],  # List of lists\n",
    "        ground_truth_keywords\n",
    "    )\n",
    "\n",
    "    summary[model] = {\n",
    "        \"Precision\": round(precision, 4),\n",
    "        \"Recall\": round(recall, 4),\n",
    "        \"F1-score\": round(f1, 4)\n",
    "    }\n",
    "\n",
    "# Convert and display\n",
    "summary_df = pd.DataFrame(summary).T\n",
    "summary_df.columns = [\"Precision\", \"Recall\", \"F1-score\"]\n",
    "summary_df.style.format(precision=4).set_caption(\"Global Evaluation Summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc68d6",
   "metadata": {},
   "source": [
    "## Score-Aware Evaluation: Weighted Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0055848",
   "metadata": {},
   "source": [
    "This extended evaluation considers the **confidence scores** assigned by the model to each predicted keyword, allowing us to measure not only whether the predictions are correct but also how confidently and effectively they are ranked.\n",
    "\n",
    "#### Score-Aware Metrics\n",
    "\n",
    "- **Weighted Precision**: Reflects the proportion of the model’s total confidence assigned to correct keywords. High confidence in incorrect predictions lowers this score.\n",
    "\n",
    "- **Weighted Recall**: Measures how much of the ground truth is recovered, weighted by the confidence of correct predictions.\n",
    "\n",
    "- **Weighted F1-score**: The harmonic mean of weighted precision and recall, balancing accuracy with coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b56b5008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_kw(kw):\n",
    "    \"\"\"\n",
    "    Normalize a keyword string by:\n",
    "    - Converting to lowercase\n",
    "    - Removing punctuation and non-alphanumeric characters (except spaces)\n",
    "    - Stripping leading and trailing whitespace\n",
    "\n",
    "    Args:\n",
    "        kw (str): The keyword string to normalize.\n",
    "\n",
    "    Returns:\n",
    "        str: The normalized keyword.\n",
    "    \"\"\"\n",
    "    kw = kw.lower()\n",
    "    kw = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", kw)  # Keep only alphanumeric characters and whitespace\n",
    "    return kw.strip()\n",
    "\n",
    "\n",
    "def is_approx_match(kw, gt_keywords):\n",
    "    \"\"\"\n",
    "    Check if a predicted keyword approximately matches any ground truth keyword.\n",
    "\n",
    "    A match is considered approximate if:\n",
    "    - The predicted keyword is exactly equal to a ground truth keyword\n",
    "    - OR the predicted keyword is a substring of a ground truth keyword\n",
    "    - OR a ground truth keyword is a substring of the predicted one\n",
    "\n",
    "    Args:\n",
    "        kw (str): The normalized predicted keyword.\n",
    "        gt_keywords (List[str]): A list of normalized ground truth keywords.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if an approximate match is found, False otherwise.\n",
    "    \"\"\"\n",
    "    for gt in gt_keywords:\n",
    "        if kw == gt or kw in gt or gt in kw:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def score_gt_keywords_from_rank(gt_keywords):\n",
    "    return [\n",
    "        (kw, 1 / math.log2(i + 2)) for i, kw in enumerate(gt_keywords)\n",
    "    ]\n",
    "\n",
    "def evaluate_keywords_weighted(all_predicted_kw_score, all_gt_keywords):\n",
    "    \"\"\"\n",
    "    Evaluate global weighted precision, recall, and F1-score across multiple reviews.\n",
    "    Matching is performed using approximate matching. Each predicted keyword contributes\n",
    "    to the precision proportionally to its confidence score. Each ground truth keyword contributes\n",
    "    to recall proportionally to its rank-based score.\n",
    "\n",
    "    Args:\n",
    "        all_predicted_kw_score (List[List[Tuple[str, float]]]): \n",
    "            A list of predicted keyword-score pairs per review.\n",
    "        all_gt_keywords (List[List[str]]): \n",
    "            A list of ground truth keyword lists per review.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float]: Weighted precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "    total_pred_score = 0.0  # Sum of all predicted keyword scores\n",
    "    matched_pred_score = 0.0  # Sum of scores of correctly predicted keywords\n",
    "    total_gt_score = 0.0  # Sum of all ground truth scores\n",
    "    matched_gt_score = 0.0  # Sum of scores of matched ground truth keywords\n",
    "\n",
    "    for pred_kw_score, gt_kw in zip(all_predicted_kw_score, all_gt_keywords):\n",
    "        # Normalize and score ground truth keywords\n",
    "        gt_kw_scored = score_gt_keywords_from_rank([normalize_kw(k) for k in gt_kw])\n",
    "        pred_kw_score = [\n",
    "            (normalize_kw(kw), score) for kw, score in pred_kw_score if isinstance(kw, str)\n",
    "        ]\n",
    "\n",
    "        total_pred_score += sum(score for _, score in pred_kw_score)\n",
    "        total_gt_score += sum(score for _, score in gt_kw_scored)\n",
    "\n",
    "        matched_gts = set()\n",
    "\n",
    "        for kw, score in pred_kw_score:\n",
    "            for gt_kw, gt_score in gt_kw_scored:\n",
    "                if gt_kw not in matched_gts and is_approx_match(kw, [gt_kw]):\n",
    "                    matched_pred_score += score\n",
    "                    matched_gt_score += gt_score\n",
    "                    matched_gts.add(gt_kw)\n",
    "                    break\n",
    "\n",
    "    precision = matched_pred_score / total_pred_score if total_pred_score > 0 else 0\n",
    "    recall = matched_gt_score / total_gt_score if total_gt_score > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52ddf38",
   "metadata": {},
   "source": [
    "### Evaluate and Compare Models on Keyword Extraction (Weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c80dd7",
   "metadata": {},
   "source": [
    "In this section, we evaluate the overall performance of each model using **score-aware metrics** computed **globally across all reviews**:\n",
    "\n",
    "- **Weighted Precision, Recall, and F1-score**: These metrics incorporate the **confidence scores** assigned to each predicted keyword, reflecting how much of the model’s confidence is placed on correct predictions.\n",
    "\n",
    "This global evaluation provides a holistic view of each model’s effectiveness in ranking and selecting relevant keywords across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "909cc3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_50041\">\n",
       "  <caption>Global Score-Aware Evaluation Summary</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_50041_level0_col0\" class=\"col_heading level0 col0\" >Weighted Precision</th>\n",
       "      <th id=\"T_50041_level0_col1\" class=\"col_heading level0 col1\" >Weighted Recall</th>\n",
       "      <th id=\"T_50041_level0_col2\" class=\"col_heading level0 col2\" >Weighted F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_50041_level0_row0\" class=\"row_heading level0 row0\" >base</th>\n",
       "      <td id=\"T_50041_row0_col0\" class=\"data row0 col0\" >0.9176</td>\n",
       "      <td id=\"T_50041_row0_col1\" class=\"data row0 col1\" >0.4902</td>\n",
       "      <td id=\"T_50041_row0_col2\" class=\"data row0 col2\" >0.6390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_50041_level0_row1\" class=\"row_heading level0 row1\" >sentiment</th>\n",
       "      <td id=\"T_50041_row1_col0\" class=\"data row1 col0\" >0.8955</td>\n",
       "      <td id=\"T_50041_row1_col1\" class=\"data row1 col1\" >0.4489</td>\n",
       "      <td id=\"T_50041_row1_col2\" class=\"data row1 col2\" >0.5981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x35b00e160>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Models to evaluate\n",
    "models_to_evaluate = [\"base\", \"sentiment\"]\n",
    "\n",
    "# Ground truth keywords (same for all reviews in the selected film)\n",
    "ground_truth_keywords = kw_ground_truth[\"Keyword\"].tolist()\n",
    "\n",
    "# Prepare data structures to hold predictions for each model\n",
    "all_predicted_kw_score = {model: [] for model in models_to_evaluate}\n",
    "\n",
    "# Collect predictions and GT for each review\n",
    "for _, row in selected_film.iterrows():\n",
    "    for model in models_to_evaluate:\n",
    "        pred_col = f\"keywords_{model}\"\n",
    "\n",
    "        # Skip if no prediction or wrong format\n",
    "        if pred_col in row and isinstance(row[pred_col], list):\n",
    "            predicted_kw_score = [(kw, score) for kw, score in row[pred_col] if isinstance(kw, str)]\n",
    "            \n",
    "            # Remove duplicates per review\n",
    "            seen = set()\n",
    "            unique_pred = [(kw, score) for kw, score in predicted_kw_score if kw not in seen and not seen.add(kw)]\n",
    "            all_predicted_kw_score[model].append(unique_pred)\n",
    "\n",
    "# Dictionary to store global evaluation results\n",
    "weighted_summary = {}\n",
    "\n",
    "# Evaluate each model globally\n",
    "for model in models_to_evaluate:\n",
    "    preds = all_predicted_kw_score[model]\n",
    "\n",
    "    # Global weighted metrics\n",
    "    w_precision, w_recall, w_f1 = evaluate_keywords_weighted(preds, ground_truth_keywords)\n",
    "\n",
    "    # Store results\n",
    "    weighted_summary[model] = {\n",
    "        \"weighted_precision\": round(w_precision, 4),\n",
    "        \"weighted_recall\": round(w_recall, 4),\n",
    "        \"weighted_f1\": round(w_f1, 4),\n",
    "    }\n",
    "\n",
    "# Convert summary to DataFrame\n",
    "summary_df = pd.DataFrame(weighted_summary).T  # Models as rows\n",
    "\n",
    "# Rename columns\n",
    "summary_df.columns = [\n",
    "    \"Weighted Precision\",\n",
    "    \"Weighted Recall\",\n",
    "    \"Weighted F1-score\",\n",
    "]\n",
    "\n",
    "# Display final table\n",
    "summary_df.style.format(precision=4).set_caption(\"Global Score-Aware Evaluation Summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabef0de",
   "metadata": {},
   "source": [
    "## Semantic Evaluation (Base vs Sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d16c67f",
   "metadata": {},
   "source": [
    "In this section, we evaluate and compare the **Base** and **Sentiment-enhanced** keyword extraction models using a **semantic similarity approach** based on contextual embeddings.\n",
    "\n",
    "Traditional evaluation metrics rely on exact or approximate string matching between predicted and ground truth keywords. However, this approach may miss semantically related terms that differ lexically but convey the same meaning — such as *\"scam\"* and *\"fraud\"*.\n",
    "\n",
    "To address this limitation, we adopt a **global semantic evaluation**, where all predicted and ground truth keywords across the dataset are compared using **dense sentence embeddings** generated by a pre-trained transformer (e.g., Sentence-BERT).\n",
    "\n",
    "#### **Semantic Evaluation Procedure**\n",
    "\n",
    "1. **Embedding Keywords Globally**  \n",
    "   All predicted and ground truth keywords across all reviews are embedded into high-dimensional vectors using the same transformer model. Ground truth keywords are embedded **once**, and all vectors are normalized to allow cosine similarity comparisons.\n",
    "\n",
    "2. **Computing Similarity Matrix**  \n",
    "   For each model, we compute a cosine similarity matrix between **all predicted keywords** and **all ground truth keywords**.\n",
    "\n",
    "3. **Matching Threshold**  \n",
    "   A predicted keyword is considered a **semantic match** if its cosine similarity with at least one ground truth keyword exceeds a fixed threshold (e.g., **0.65**). This allows for flexible yet meaningful semantic alignment.\n",
    "\n",
    "4. **Global Semantic Precision**  \n",
    "   The proportion of predicted keywords that have at least one semantic match in the ground truth. This reflects how many of the model's predictions are semantically relevant.\n",
    "\n",
    "5. **Global Semantic Recall**  \n",
    "   The proportion of ground truth keywords that are captured by semantically similar predictions. This indicates how well the model covers the key concepts.\n",
    "\n",
    "6. **Global Semantic F1-score**  \n",
    "   The harmonic mean of semantic precision and recall, summarizing both relevance and coverage into a single score.\n",
    "\n",
    "This evaluation:\n",
    "\n",
    "- Is **more robust** than string-based metrics.\n",
    "- **Captures meaning**, not just surface forms.\n",
    "- Helps evaluate models that paraphrase or generalize beyond exact matches.\n",
    "\n",
    "This evaluation complements previous metrics and provides a more **realistic estimate** of how well the models capture the essence of user-annotated keywords in a global and context-aware manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f779851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sentence embedding model from the SentenceTransformers family\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load tokenizer and model to generate contextual embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "encoder = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "# Simple normalization function for keywords:\n",
    "# - Converts to lowercase\n",
    "# - Removes punctuation\n",
    "# - Strips leading/trailing spaces\n",
    "def normalize_kw(kw):\n",
    "    kw = kw.lower()\n",
    "    kw = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", kw)  # Keep only alphanumerics and whitespace\n",
    "    return kw.strip()\n",
    "\n",
    "def embed_keywords(keywords, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Compute sentence embeddings for a list of keyword strings.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    keywords : List[str]\n",
    "        A list of keyword strings to encode.\n",
    "    device : str\n",
    "        Device to run the model on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Normalized embeddings tensor of shape (num_keywords, embedding_dim).\n",
    "    \"\"\"\n",
    "    # Return empty tensor if input list is empty\n",
    "    if not keywords:\n",
    "        return torch.empty(0, encoder.config.hidden_size).to(device)\n",
    "\n",
    "    # Tokenize and prepare inputs for the model\n",
    "    inputs = tokenizer(keywords, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass through the encoder to get hidden states\n",
    "        outputs = encoder(**inputs)\n",
    "\n",
    "        # Use mean pooling on the last hidden state to get fixed-size embeddings\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "        # Normalize embeddings to unit length for cosine similarity computations\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def evaluate_semantic_keywords(all_pred_keywords, gt_keywords, threshold=0.65, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Compute global semantic precision, recall, and F1 score between all predicted keywords\n",
    "    and ground truth keywords using cosine similarity over embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    all_pred_keywords : List[List[str]]\n",
    "        List of predicted keywords for each review.\n",
    "    gt_keywords : List[str]\n",
    "        Global list of ground truth keywords for the movie.\n",
    "    threshold : float\n",
    "        Cosine similarity threshold for considering a match.\n",
    "    device : str\n",
    "        Device to run the model on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    precision : float\n",
    "    recall : float\n",
    "    f1 : float\n",
    "    \"\"\"\n",
    "    # Early return if either set is empty\n",
    "    if len(all_pred_keywords) == 0 or len(gt_keywords) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    # Compute embeddings\n",
    "    pred_emb = embed_keywords(all_pred_keywords, device=device)\n",
    "    gt_emb = embed_keywords(gt_keywords, device=device)\n",
    "\n",
    "    # Compute similarity matrix\n",
    "    sims = torch.matmul(pred_emb, gt_emb.T)\n",
    "\n",
    "    # Match counting based on threshold\n",
    "    pred_matches = (sims > threshold).any(dim=1).float().sum().item()\n",
    "    gt_matches = (sims > threshold).any(dim=0).float().sum().item()\n",
    "\n",
    "    precision = pred_matches / len(all_pred_keywords)\n",
    "    recall = gt_matches / len(gt_keywords)\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce9bda",
   "metadata": {},
   "source": [
    "### Semantic Evaluation of Base and Sentiment Models Using Sentence Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa566c",
   "metadata": {},
   "source": [
    "In this step, we evaluate the **semantic similarity** between the predicted keywords of two models — **Base** and **Sentiment-enhanced** — and the ground truth keywords using **sentence embeddings**.\n",
    "\n",
    "Unlike exact or approximate string matching, this method leverages **contextual embeddings** from a pre-trained transformer to assess how semantically close the predicted keywords are to the reference keywords.\n",
    "\n",
    "The evaluation procedure is as follows:\n",
    "\n",
    "- We extract only the **text** of the predicted keywords for each model, discarding their confidence scores.\n",
    "- We embed all **predicted** and **ground truth** keywords using the same sentence transformer model.\n",
    "- Embeddings are **normalized** to ensure cosine similarity is a valid similarity measure.\n",
    "- For each predicted keyword, we compute the **cosine similarity** with all ground truth keywords.\n",
    "- A predicted keyword is considered a **semantic match** if its similarity with any ground truth keyword exceeds a fixed threshold (e.g., **0.75**).\n",
    "\n",
    "Once all matches are determined across all reviews of the selected movie, we compute:\n",
    "\n",
    "- **Semantic Precision**: Fraction of all predicted keywords (global) that have a semantic match.\n",
    "- **Semantic Recall**: Fraction of all ground truth keywords that are matched by at least one semantically similar predicted keyword.\n",
    "- **Semantic F1-score**: Harmonic mean of semantic precision and recall.\n",
    "\n",
    "This global semantic evaluation better reflects the models’ ability to capture **meaningful and relevant keywords**, even when the wording differs from the ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbbd11b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0d7ce\">\n",
       "  <caption>Global Semantic-Aware Evaluation Summary</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0d7ce_level0_col0\" class=\"col_heading level0 col0\" >Semantic_Precision</th>\n",
       "      <th id=\"T_0d7ce_level0_col1\" class=\"col_heading level0 col1\" >Semantic_Recall</th>\n",
       "      <th id=\"T_0d7ce_level0_col2\" class=\"col_heading level0 col2\" >Semantic_F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0d7ce_level0_row0\" class=\"row_heading level0 row0\" >base</th>\n",
       "      <td id=\"T_0d7ce_row0_col0\" class=\"data row0 col0\" >0.9628</td>\n",
       "      <td id=\"T_0d7ce_row0_col1\" class=\"data row0 col1\" >0.7978</td>\n",
       "      <td id=\"T_0d7ce_row0_col2\" class=\"data row0 col2\" >0.8726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d7ce_level0_row1\" class=\"row_heading level0 row1\" >sentiment</th>\n",
       "      <td id=\"T_0d7ce_row1_col0\" class=\"data row1 col0\" >0.9616</td>\n",
       "      <td id=\"T_0d7ce_row1_col1\" class=\"data row1 col1\" >0.8162</td>\n",
       "      <td id=\"T_0d7ce_row1_col2\" class=\"data row1 col2\" >0.8830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x177931280>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precompute embeddings for the ground truth keywords once per selected movie\n",
    "gt_keywords = kw_ground_truth[\"Keyword\"].tolist()\n",
    "\n",
    "# Define the models to evaluate\n",
    "models_to_evaluate = [\"base\", \"sentiment\"]\n",
    "\n",
    "# Dictionary to collect all predicted keywords per model (without duplicates)\n",
    "all_predictions = {model: set() for model in models_to_evaluate}\n",
    "\n",
    "# Collect predicted keywords across all reviews (as a set for uniqueness)\n",
    "for _, row in selected_film.iterrows():\n",
    "    for model in models_to_evaluate:\n",
    "        pred_col = f\"keywords_{model}\"\n",
    "\n",
    "        if pred_col in row and isinstance(row[pred_col], list):\n",
    "            # Extract keyword strings and normalize\n",
    "            pred_kw = [normalize_kw(kw) for kw, _ in row[pred_col] if isinstance(kw, str)]\n",
    "            all_predictions[model].update(pred_kw)  # Add to set (no duplicates)\n",
    "\n",
    "# Compute semantic evaluation globally for each model\n",
    "semantic_scores = []\n",
    "for model in models_to_evaluate:\n",
    "    pred_kw = list(all_predictions[model])  # Convert back to list\n",
    "    precision, recall, f1 = evaluate_semantic_keywords(pred_kw, gt_keywords, device=device, threshold=0.65)\n",
    "\n",
    "    semantic_scores.append({\n",
    "        \"Model\": model,\n",
    "        \"Semantic_Precision\": round(precision, 4),\n",
    "        \"Semantic_Recall\": round(recall, 4),\n",
    "        \"Semantic_F1\": round(f1, 4)\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and format\n",
    "summary_df = pd.DataFrame(semantic_scores).set_index(\"Model\")\n",
    "summary_df.style.format(precision=4).set_caption(\"Global Semantic-Aware Evaluation Summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997bd7af",
   "metadata": {},
   "source": [
    "## Sentiment Appropriateness Score (SAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b08c7",
   "metadata": {},
   "source": [
    "To further evaluate the quality of predicted keywords from a sentiment-aware perspective, we introduce the **Sentiment Appropriateness Score (SAS)**. This metric assesses how well the **overall sentiment of the predicted keywords** aligns with the **sentiment of the ground truth keywords** or the **sentiment of the full review text**, providing a complementary dimension to traditional keyword evaluation.\n",
    "\n",
    "Unlike standard metrics like **Precision**, **Recall**, or **F1**, which measure lexical or semantic correctness, SAS explicitly measures **emotional alignment**.\n",
    "\n",
    "#### **Two Global Evaluation Schemes**\n",
    "\n",
    "1. **SAS from Ground Truth Keywords**\n",
    "\n",
    "   - The sentiment of the reference is approximated using all ground truth keywords for the movie.\n",
    "   - Each ground truth keyword is analyzed using **VADER** sentiment analyzer.\n",
    "   - The sentiment score is calculated as a weighted combination:\n",
    "     - `pos` → 1.0\n",
    "     - `neu` → 0.5\n",
    "     - `neg` → 0.0\n",
    "   - The average sentiment across all ground truth keywords forms the **reference sentiment**.\n",
    "   - This is compared to the **global average sentiment** of all predicted keywords (across reviews).\n",
    "\n",
    "2. **SAS from Review Text**\n",
    "\n",
    "   - The sentiment of the review set is approximated by aggregating the sentiments of the full review texts.\n",
    "   - Each review is processed with VADER using the same weighted scoring.\n",
    "   - The resulting average sentiment is compared to the sentiment of all predicted keywords.\n",
    "\n",
    "#### **Formula**\n",
    "\n",
    "$$\n",
    "\\text{SAS} = 1 - \\left| \\text{Sentiment}_{\\text{predicted}} - \\text{Sentiment}_{\\text{reference}} \\right|\n",
    "$$\n",
    "\n",
    "SAS is a value in **\\[0, 1\\]**, where values closer to **1** indicate stronger emotional coherence between the predicted keywords and the reference source (either ground truth keywords or full review text).\n",
    "\n",
    "#### **Why VADER?**\n",
    "\n",
    "We choose **VADER (Valence Aware Dictionary and sEntiment Reasoner)** for its suitability in this context:\n",
    "\n",
    "- It is optimized for **short, informal text** like tags and keywords.\n",
    "- It works well on **single words and short phrases**, which represent our prediction outputs.\n",
    "- It provides interpretable and **probabilistic sentiment scores** (`pos`, `neu`, `neg`).\n",
    "- It is lightweight, efficient, and scalable for large-scale global evaluations.\n",
    "\n",
    "Although transformer-based sentiment models may offer more nuanced analysis on long text, VADER provides the best **balance of performance, interpretability, and scalability** for evaluating the emotional tone of predicted keywords in our keyword extraction task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "75a839c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sas_from_keywords(all_predicted_keywords, ground_truth_keywords=None, analyzer=None, sentiment_gt=None):\n",
    "    \"\"\"\n",
    "    Computes global SAS by comparing the average sentiment of all predicted keywords (across reviews)\n",
    "    to the sentiment of the ground truth keywords (either computed or pre-given).\n",
    "\n",
    "    Args:\n",
    "        all_predicted_keywords (list of list of dict): list of predicted keyword dicts per review (each dict has 'sentiment_score' ∈ [0,1])\n",
    "        ground_truth_keywords (list of str): optional, used if sentiment_gt is not given\n",
    "        analyzer (SentimentIntensityAnalyzer): optional, used if sentiment_gt is not given\n",
    "        sentiment_gt (float): optional precomputed global ground truth sentiment ∈ [0,1]\n",
    "\n",
    "    Returns:\n",
    "        float: SAS ∈ [0,1] — higher means better emotional alignment with ground truth\n",
    "    \"\"\"\n",
    "    # Compute GT sentiment if not precomputed\n",
    "    if sentiment_gt is None:\n",
    "        if not ground_truth_keywords or analyzer is None:\n",
    "            return None\n",
    "        gt_scores = [\n",
    "            analyzer.polarity_scores(kw)\n",
    "            for kw in ground_truth_keywords\n",
    "        ]\n",
    "        sentiments_gt = [\n",
    "            1.0 * s[\"pos\"] + 0.5 * s[\"neu\"] + 0.0 * s[\"neg\"]\n",
    "            for s in gt_scores\n",
    "        ]\n",
    "        sentiment_gt = sum(sentiments_gt) / len(sentiments_gt) if sentiments_gt else 0.0\n",
    "\n",
    "    # Collect all predicted sentiments across reviews\n",
    "    all_sentiments_pred = []\n",
    "    for review_preds in all_predicted_keywords:\n",
    "        all_sentiments_pred.extend(\n",
    "            [kw['sentiment_score'] for kw in review_preds]\n",
    "        )\n",
    "\n",
    "    # Compute global average of predicted sentiment\n",
    "    if not all_sentiments_pred:\n",
    "        return None\n",
    "    sentiment_pred = sum(all_sentiments_pred) / len(all_sentiments_pred)\n",
    "\n",
    "    # Global SAS\n",
    "    return 1 - abs(sentiment_pred - sentiment_gt)\n",
    "\n",
    "\n",
    "def compute_sas_from_text(all_predicted_keywords, review_texts=None, analyzer=None, sentiment_text=None):\n",
    "    \"\"\"\n",
    "    Computes global SAS by comparing the average sentiment of all predicted keywords\n",
    "    to the sentiment of the full movie text corpus (or average of review texts).\n",
    "\n",
    "    Args:\n",
    "        all_predicted_keywords (list of list of dict): list of predicted keyword dicts per review (each dict has 'sentiment_score' ∈ [0,1])\n",
    "        review_texts (list of str): optional, used if sentiment_text is not given\n",
    "        analyzer (SentimentIntensityAnalyzer): optional, used if sentiment_text is not given\n",
    "        sentiment_text (float): optional precomputed global sentiment of review text ∈ [0,1]\n",
    "\n",
    "    Returns:\n",
    "        float: SAS ∈ [0,1] — higher means better emotional alignment with full review sentiment\n",
    "    \"\"\"\n",
    "    # Compute sentiment from full text if not precomputed\n",
    "    if sentiment_text is None:\n",
    "        if not review_texts or analyzer is None:\n",
    "            return None\n",
    "        text_scores = [\n",
    "            analyzer.polarity_scores(text)\n",
    "            for text in review_texts if isinstance(text, str)\n",
    "        ]\n",
    "        sentiments_text = [\n",
    "            1.0 * s[\"pos\"] + 0.5 * s[\"neu\"] + 0.0 * s[\"neg\"]\n",
    "            for s in text_scores\n",
    "        ]\n",
    "        sentiment_text = sum(sentiments_text) / len(sentiments_text) if sentiments_text else 0.0\n",
    "\n",
    "    # Collect all predicted keyword sentiments across reviews\n",
    "    all_sentiments_pred = []\n",
    "    for review_preds in all_predicted_keywords:\n",
    "        all_sentiments_pred.extend(\n",
    "            [kw['sentiment_score'] for kw in review_preds]\n",
    "        )\n",
    "\n",
    "    if not all_sentiments_pred:\n",
    "        return None\n",
    "    sentiment_pred = sum(all_sentiments_pred) / len(all_sentiments_pred)\n",
    "\n",
    "    # Global SAS\n",
    "    return 1 - abs(sentiment_pred - sentiment_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c53932",
   "metadata": {},
   "source": [
    "### Sentiment Appropriateness Evaluation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f47dae1",
   "metadata": {},
   "source": [
    "In this section, we evaluate the sentiment alignment of predicted keywords for each model using the **Sentiment Appropriateness Score (SAS)**.\n",
    "\n",
    "Unlike traditional metrics, SAS assesses how well the **overall sentiment of the predicted keywords** reflects the sentiment of the movie’s content, based on two global references:\n",
    "\n",
    "- **SAS from Ground Truth Keywords**  \n",
    "  Compares the average sentiment of all predicted keywords to that of the ground truth keywords using **VADER**.\n",
    "\n",
    "- **SAS from Review Texts**  \n",
    "  Compares the predicted sentiment to the overall sentiment of all preprocessed reviews.\n",
    "\n",
    "Both reference sentiments are computed **globally per movie**, and each model's predictions are evaluated accordingly.  \n",
    "SAS is defined as:\n",
    "\n",
    "$$\n",
    "\\text{SAS} = 1 - \\left| \\text{sentiment}_{\\text{pred}} - \\text{sentiment}_{\\text{ref}} \\right|\n",
    "$$\n",
    "\n",
    "Higher scores indicate better emotional alignment between the predicted keywords and the movie's actual sentiment.\n",
    "\n",
    "The results are summarized in a table for **global comparison across models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b0c92f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_fcedb\">\n",
       "  <caption>Sentiment Appropriateness Score (SAS) - Global Evaluation</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fcedb_level0_col0\" class=\"col_heading level0 col0\" >SAS from keywords</th>\n",
       "      <th id=\"T_fcedb_level0_col1\" class=\"col_heading level0 col1\" >SAS from text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fcedb_level0_row0\" class=\"row_heading level0 row0\" >base</th>\n",
       "      <td id=\"T_fcedb_row0_col0\" class=\"data row0 col0\" >0.9675</td>\n",
       "      <td id=\"T_fcedb_row0_col1\" class=\"data row0 col1\" >0.9206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcedb_level0_row1\" class=\"row_heading level0 row1\" >sentiment</th>\n",
       "      <td id=\"T_fcedb_row1_col0\" class=\"data row1 col0\" >0.9015</td>\n",
       "      <td id=\"T_fcedb_row1_col1\" class=\"data row1 col1\" >0.8545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x32d6b7af0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define models to evaluate\n",
    "models_to_evaluate = [\"base\", \"sentiment\"]\n",
    "\n",
    "# Precompute global ground truth sentiment (from all keywords in the movie)\n",
    "gt_keywords = kw_ground_truth[\"Keyword\"].tolist()\n",
    "sentiments_gt = []\n",
    "for kw in gt_keywords:\n",
    "    scores = analyzer.polarity_scores(kw)\n",
    "    sentiment = 1.0 * scores[\"pos\"] + 0.5 * scores[\"neu\"] + 0.0 * scores[\"neg\"]\n",
    "    sentiments_gt.append(sentiment)\n",
    "sentiment_gt = sum(sentiments_gt) / len(sentiments_gt) if sentiments_gt else None\n",
    "\n",
    "# Precompute global review sentiment (from all review texts)\n",
    "all_review_texts = selected_film[\"Preprocessed_Review\"].dropna().tolist()\n",
    "sentiments_text = []\n",
    "for text in all_review_texts:\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    sentiment = 1.0 * scores[\"pos\"] + 0.5 * scores[\"neu\"] + 0.0 * scores[\"neg\"]\n",
    "    sentiments_text.append(sentiment)\n",
    "sentiment_text = sum(sentiments_text) / len(sentiments_text) if sentiments_text else None\n",
    "\n",
    "# Collect SAS results\n",
    "sas_scores = []\n",
    "\n",
    "for model in models_to_evaluate:\n",
    "    all_predicted_keywords = []\n",
    "\n",
    "    for _, row in selected_film.iterrows():\n",
    "        pred_col = f\"keywords_{model}\"\n",
    "\n",
    "        if pred_col in row and isinstance(row[pred_col], list):\n",
    "            for kw, score in row[pred_col]:\n",
    "                if isinstance(kw, str) and isinstance(score, (float, int)):\n",
    "                    all_predicted_keywords.append({\n",
    "                        \"keyword\": kw,\n",
    "                        \"sentiment_score\": float(score)\n",
    "                    })\n",
    "\n",
    "    if not all_predicted_keywords:\n",
    "        continue\n",
    "\n",
    "    # Compute SAS from GT keywords\n",
    "    sas_kw = compute_sas_from_keywords([all_predicted_keywords], sentiment_gt=sentiment_gt)\n",
    "\n",
    "    # Compute SAS from full review text\n",
    "    sas_text = compute_sas_from_text([all_predicted_keywords], sentiment_text=sentiment_text)\n",
    "\n",
    "    result = {\"Model\": model}\n",
    "    if sas_kw is not None:\n",
    "        result[\"SAS from keywords\"] = round(sas_kw, 4)\n",
    "    if sas_text is not None:\n",
    "        result[\"SAS from text\"] = round(sas_text, 4)\n",
    "\n",
    "    sas_scores.append(result)\n",
    "\n",
    "# Create and display summary DataFrame\n",
    "sas_df = pd.DataFrame(sas_scores).set_index(\"Model\")\n",
    "sas_df.style.format(precision=4).set_caption(\"Sentiment Appropriateness Score (SAS) - Global Evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c28df9",
   "metadata": {},
   "source": [
    "## Evaluation Across All Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc187183",
   "metadata": {},
   "source": [
    "This section automatically processes all `.pkl` files in the `Extracted_Keywords` directory, where each file corresponds to a single movie and contains predicted keywords generated by different models.\n",
    "\n",
    "For **each movie**:\n",
    "\n",
    "- The corresponding **ground truth keywords** are loaded.\n",
    "- Predicted keywords from both models — **Base** and **Sentiment-aware** — are aggregated across all reviews.\n",
    "- The following **global evaluation metrics** are computed:\n",
    "\n",
    "#### Unweighted Metrics\n",
    "- **Precision**, **Recall**, and **F1-score**  \n",
    "  Based on approximate string matching between predicted and ground truth keywords, without considering prediction scores.\n",
    "\n",
    "#### Score-aware Metrics\n",
    "- **Weighted Precision**, **Weighted Recall**, **Weighted F1-score**  \n",
    "  Evaluate prediction correctness while incorporating confidence scores.\n",
    "  \n",
    "- **nDCG@5**  \n",
    "  Measures the ranking quality of the top 5 predicted keywords, rewarding correct keywords ranked higher.\n",
    "\n",
    "#### Semantic Metrics\n",
    "- **Semantic Precision**, **Semantic Recall**, **Semantic F1-score**  \n",
    "  Computed using cosine similarity between **sentence embeddings** of predicted and reference keywords.\n",
    "\n",
    "#### Sentiment Alignment Metrics\n",
    "- **SAS_from_keywords**:  \n",
    "  Measures how well the average sentiment of predicted keywords aligns with the sentiment of the ground truth keywords (via VADER).\n",
    "  \n",
    "- **SAS_from_text**:  \n",
    "  Measures alignment with the sentiment of the full review texts.\n",
    "\n",
    "All metrics are computed **globally per movie**, not per review, and the results are compiled into a **comprehensive summary table** for comparison across models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e56b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b2490\">\n",
       "  <caption>Global Evaluation Summary per Movie and Model</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b2490_level0_col0\" class=\"col_heading level0 col0\" >Movie</th>\n",
       "      <th id=\"T_b2490_level0_col1\" class=\"col_heading level0 col1\" >Model</th>\n",
       "      <th id=\"T_b2490_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_b2490_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_b2490_level0_col4\" class=\"col_heading level0 col4\" >F1-score</th>\n",
       "      <th id=\"T_b2490_level0_col5\" class=\"col_heading level0 col5\" >Weighted Precision</th>\n",
       "      <th id=\"T_b2490_level0_col6\" class=\"col_heading level0 col6\" >Weighted Recall</th>\n",
       "      <th id=\"T_b2490_level0_col7\" class=\"col_heading level0 col7\" >Weighted F1-score</th>\n",
       "      <th id=\"T_b2490_level0_col8\" class=\"col_heading level0 col8\" >Semantic Precision</th>\n",
       "      <th id=\"T_b2490_level0_col9\" class=\"col_heading level0 col9\" >Semantic Recall</th>\n",
       "      <th id=\"T_b2490_level0_col10\" class=\"col_heading level0 col10\" >Semantic F1-score</th>\n",
       "      <th id=\"T_b2490_level0_col11\" class=\"col_heading level0 col11\" >SAS from Keywords</th>\n",
       "      <th id=\"T_b2490_level0_col12\" class=\"col_heading level0 col12\" >SAS from text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b2490_row0_col0\" class=\"data row0 col0\" >GoodBadUgly</td>\n",
       "      <td id=\"T_b2490_row0_col1\" class=\"data row0 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row0_col2\" class=\"data row0 col2\" >0.9341</td>\n",
       "      <td id=\"T_b2490_row0_col3\" class=\"data row0 col3\" >0.3612</td>\n",
       "      <td id=\"T_b2490_row0_col4\" class=\"data row0 col4\" >0.5210</td>\n",
       "      <td id=\"T_b2490_row0_col5\" class=\"data row0 col5\" >0.9352</td>\n",
       "      <td id=\"T_b2490_row0_col6\" class=\"data row0 col6\" >0.4857</td>\n",
       "      <td id=\"T_b2490_row0_col7\" class=\"data row0 col7\" >0.6394</td>\n",
       "      <td id=\"T_b2490_row0_col8\" class=\"data row0 col8\" >0.8691</td>\n",
       "      <td id=\"T_b2490_row0_col9\" class=\"data row0 col9\" >0.7888</td>\n",
       "      <td id=\"T_b2490_row0_col10\" class=\"data row0 col10\" >0.8270</td>\n",
       "      <td id=\"T_b2490_row0_col11\" class=\"data row0 col11\" >0.9868</td>\n",
       "      <td id=\"T_b2490_row0_col12\" class=\"data row0 col12\" >0.9245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b2490_row1_col0\" class=\"data row1 col0\" >GoodBadUgly</td>\n",
       "      <td id=\"T_b2490_row1_col1\" class=\"data row1 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row1_col2\" class=\"data row1 col2\" >0.9074</td>\n",
       "      <td id=\"T_b2490_row1_col3\" class=\"data row1 col3\" >0.3391</td>\n",
       "      <td id=\"T_b2490_row1_col4\" class=\"data row1 col4\" >0.4937</td>\n",
       "      <td id=\"T_b2490_row1_col5\" class=\"data row1 col5\" >0.9104</td>\n",
       "      <td id=\"T_b2490_row1_col6\" class=\"data row1 col6\" >0.4481</td>\n",
       "      <td id=\"T_b2490_row1_col7\" class=\"data row1 col7\" >0.6006</td>\n",
       "      <td id=\"T_b2490_row1_col8\" class=\"data row1 col8\" >0.7477</td>\n",
       "      <td id=\"T_b2490_row1_col9\" class=\"data row1 col9\" >0.8043</td>\n",
       "      <td id=\"T_b2490_row1_col10\" class=\"data row1 col10\" >0.7750</td>\n",
       "      <td id=\"T_b2490_row1_col11\" class=\"data row1 col11\" >0.9773</td>\n",
       "      <td id=\"T_b2490_row1_col12\" class=\"data row1 col12\" >0.8886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b2490_row2_col0\" class=\"data row2 col0\" >HarryPotter</td>\n",
       "      <td id=\"T_b2490_row2_col1\" class=\"data row2 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row2_col2\" class=\"data row2 col2\" >0.9194</td>\n",
       "      <td id=\"T_b2490_row2_col3\" class=\"data row2 col3\" >0.3394</td>\n",
       "      <td id=\"T_b2490_row2_col4\" class=\"data row2 col4\" >0.4957</td>\n",
       "      <td id=\"T_b2490_row2_col5\" class=\"data row2 col5\" >0.9202</td>\n",
       "      <td id=\"T_b2490_row2_col6\" class=\"data row2 col6\" >0.4552</td>\n",
       "      <td id=\"T_b2490_row2_col7\" class=\"data row2 col7\" >0.6091</td>\n",
       "      <td id=\"T_b2490_row2_col8\" class=\"data row2 col8\" >0.9016</td>\n",
       "      <td id=\"T_b2490_row2_col9\" class=\"data row2 col9\" >0.8820</td>\n",
       "      <td id=\"T_b2490_row2_col10\" class=\"data row2 col10\" >0.8917</td>\n",
       "      <td id=\"T_b2490_row2_col11\" class=\"data row2 col11\" >0.9738</td>\n",
       "      <td id=\"T_b2490_row2_col12\" class=\"data row2 col12\" >0.9087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b2490_row3_col0\" class=\"data row3 col0\" >HarryPotter</td>\n",
       "      <td id=\"T_b2490_row3_col1\" class=\"data row3 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row3_col2\" class=\"data row3 col2\" >0.9023</td>\n",
       "      <td id=\"T_b2490_row3_col3\" class=\"data row3 col3\" >0.3251</td>\n",
       "      <td id=\"T_b2490_row3_col4\" class=\"data row3 col4\" >0.4779</td>\n",
       "      <td id=\"T_b2490_row3_col5\" class=\"data row3 col5\" >0.9043</td>\n",
       "      <td id=\"T_b2490_row3_col6\" class=\"data row3 col6\" >0.4348</td>\n",
       "      <td id=\"T_b2490_row3_col7\" class=\"data row3 col7\" >0.5873</td>\n",
       "      <td id=\"T_b2490_row3_col8\" class=\"data row3 col8\" >0.8966</td>\n",
       "      <td id=\"T_b2490_row3_col9\" class=\"data row3 col9\" >0.8976</td>\n",
       "      <td id=\"T_b2490_row3_col10\" class=\"data row3 col10\" >0.8971</td>\n",
       "      <td id=\"T_b2490_row3_col11\" class=\"data row3 col11\" >0.9449</td>\n",
       "      <td id=\"T_b2490_row3_col12\" class=\"data row3 col12\" >0.8798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b2490_row4_col0\" class=\"data row4 col0\" >IndianaJones</td>\n",
       "      <td id=\"T_b2490_row4_col1\" class=\"data row4 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row4_col2\" class=\"data row4 col2\" >0.9125</td>\n",
       "      <td id=\"T_b2490_row4_col3\" class=\"data row4 col3\" >0.3678</td>\n",
       "      <td id=\"T_b2490_row4_col4\" class=\"data row4 col4\" >0.5243</td>\n",
       "      <td id=\"T_b2490_row4_col5\" class=\"data row4 col5\" >0.9176</td>\n",
       "      <td id=\"T_b2490_row4_col6\" class=\"data row4 col6\" >0.4902</td>\n",
       "      <td id=\"T_b2490_row4_col7\" class=\"data row4 col7\" >0.6390</td>\n",
       "      <td id=\"T_b2490_row4_col8\" class=\"data row4 col8\" >0.9628</td>\n",
       "      <td id=\"T_b2490_row4_col9\" class=\"data row4 col9\" >0.7978</td>\n",
       "      <td id=\"T_b2490_row4_col10\" class=\"data row4 col10\" >0.8726</td>\n",
       "      <td id=\"T_b2490_row4_col11\" class=\"data row4 col11\" >0.9675</td>\n",
       "      <td id=\"T_b2490_row4_col12\" class=\"data row4 col12\" >0.9206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b2490_row5_col0\" class=\"data row5 col0\" >IndianaJones</td>\n",
       "      <td id=\"T_b2490_row5_col1\" class=\"data row5 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row5_col2\" class=\"data row5 col2\" >0.8805</td>\n",
       "      <td id=\"T_b2490_row5_col3\" class=\"data row5 col3\" >0.3385</td>\n",
       "      <td id=\"T_b2490_row5_col4\" class=\"data row5 col4\" >0.4890</td>\n",
       "      <td id=\"T_b2490_row5_col5\" class=\"data row5 col5\" >0.8955</td>\n",
       "      <td id=\"T_b2490_row5_col6\" class=\"data row5 col6\" >0.4489</td>\n",
       "      <td id=\"T_b2490_row5_col7\" class=\"data row5 col7\" >0.5981</td>\n",
       "      <td id=\"T_b2490_row5_col8\" class=\"data row5 col8\" >0.9616</td>\n",
       "      <td id=\"T_b2490_row5_col9\" class=\"data row5 col9\" >0.8162</td>\n",
       "      <td id=\"T_b2490_row5_col10\" class=\"data row5 col10\" >0.8830</td>\n",
       "      <td id=\"T_b2490_row5_col11\" class=\"data row5 col11\" >0.9015</td>\n",
       "      <td id=\"T_b2490_row5_col12\" class=\"data row5 col12\" >0.8545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b2490_row6_col0\" class=\"data row6 col0\" >LaLaLand</td>\n",
       "      <td id=\"T_b2490_row6_col1\" class=\"data row6 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row6_col2\" class=\"data row6 col2\" >0.8917</td>\n",
       "      <td id=\"T_b2490_row6_col3\" class=\"data row6 col3\" >0.3193</td>\n",
       "      <td id=\"T_b2490_row6_col4\" class=\"data row6 col4\" >0.4702</td>\n",
       "      <td id=\"T_b2490_row6_col5\" class=\"data row6 col5\" >0.9063</td>\n",
       "      <td id=\"T_b2490_row6_col6\" class=\"data row6 col6\" >0.4422</td>\n",
       "      <td id=\"T_b2490_row6_col7\" class=\"data row6 col7\" >0.5943</td>\n",
       "      <td id=\"T_b2490_row6_col8\" class=\"data row6 col8\" >0.8537</td>\n",
       "      <td id=\"T_b2490_row6_col9\" class=\"data row6 col9\" >0.7759</td>\n",
       "      <td id=\"T_b2490_row6_col10\" class=\"data row6 col10\" >0.8129</td>\n",
       "      <td id=\"T_b2490_row6_col11\" class=\"data row6 col11\" >0.9438</td>\n",
       "      <td id=\"T_b2490_row6_col12\" class=\"data row6 col12\" >0.9046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b2490_row7_col0\" class=\"data row7 col0\" >LaLaLand</td>\n",
       "      <td id=\"T_b2490_row7_col1\" class=\"data row7 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row7_col2\" class=\"data row7 col2\" >0.8928</td>\n",
       "      <td id=\"T_b2490_row7_col3\" class=\"data row7 col3\" >0.3126</td>\n",
       "      <td id=\"T_b2490_row7_col4\" class=\"data row7 col4\" >0.4631</td>\n",
       "      <td id=\"T_b2490_row7_col5\" class=\"data row7 col5\" >0.8962</td>\n",
       "      <td id=\"T_b2490_row7_col6\" class=\"data row7 col6\" >0.4212</td>\n",
       "      <td id=\"T_b2490_row7_col7\" class=\"data row7 col7\" >0.5731</td>\n",
       "      <td id=\"T_b2490_row7_col8\" class=\"data row7 col8\" >0.7331</td>\n",
       "      <td id=\"T_b2490_row7_col9\" class=\"data row7 col9\" >0.7897</td>\n",
       "      <td id=\"T_b2490_row7_col10\" class=\"data row7 col10\" >0.7604</td>\n",
       "      <td id=\"T_b2490_row7_col11\" class=\"data row7 col11\" >0.9185</td>\n",
       "      <td id=\"T_b2490_row7_col12\" class=\"data row7 col12\" >0.8793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b2490_row8_col0\" class=\"data row8 col0\" >Oppenheimer</td>\n",
       "      <td id=\"T_b2490_row8_col1\" class=\"data row8 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row8_col2\" class=\"data row8 col2\" >0.9384</td>\n",
       "      <td id=\"T_b2490_row8_col3\" class=\"data row8 col3\" >0.3207</td>\n",
       "      <td id=\"T_b2490_row8_col4\" class=\"data row8 col4\" >0.4781</td>\n",
       "      <td id=\"T_b2490_row8_col5\" class=\"data row8 col5\" >0.9470</td>\n",
       "      <td id=\"T_b2490_row8_col6\" class=\"data row8 col6\" >0.4611</td>\n",
       "      <td id=\"T_b2490_row8_col7\" class=\"data row8 col7\" >0.6202</td>\n",
       "      <td id=\"T_b2490_row8_col8\" class=\"data row8 col8\" >0.9905</td>\n",
       "      <td id=\"T_b2490_row8_col9\" class=\"data row8 col9\" >0.8556</td>\n",
       "      <td id=\"T_b2490_row8_col10\" class=\"data row8 col10\" >0.9181</td>\n",
       "      <td id=\"T_b2490_row8_col11\" class=\"data row8 col11\" >0.9926</td>\n",
       "      <td id=\"T_b2490_row8_col12\" class=\"data row8 col12\" >0.9481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b2490_row9_col0\" class=\"data row9 col0\" >Oppenheimer</td>\n",
       "      <td id=\"T_b2490_row9_col1\" class=\"data row9 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row9_col2\" class=\"data row9 col2\" >0.9247</td>\n",
       "      <td id=\"T_b2490_row9_col3\" class=\"data row9 col3\" >0.3090</td>\n",
       "      <td id=\"T_b2490_row9_col4\" class=\"data row9 col4\" >0.4632</td>\n",
       "      <td id=\"T_b2490_row9_col5\" class=\"data row9 col5\" >0.9219</td>\n",
       "      <td id=\"T_b2490_row9_col6\" class=\"data row9 col6\" >0.4328</td>\n",
       "      <td id=\"T_b2490_row9_col7\" class=\"data row9 col7\" >0.5891</td>\n",
       "      <td id=\"T_b2490_row9_col8\" class=\"data row9 col8\" >0.8451</td>\n",
       "      <td id=\"T_b2490_row9_col9\" class=\"data row9 col9\" >0.9428</td>\n",
       "      <td id=\"T_b2490_row9_col10\" class=\"data row9 col10\" >0.8913</td>\n",
       "      <td id=\"T_b2490_row9_col11\" class=\"data row9 col11\" >0.9686</td>\n",
       "      <td id=\"T_b2490_row9_col12\" class=\"data row9 col12\" >0.9092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_b2490_row10_col0\" class=\"data row10 col0\" >Parasite</td>\n",
       "      <td id=\"T_b2490_row10_col1\" class=\"data row10 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row10_col2\" class=\"data row10 col2\" >0.9003</td>\n",
       "      <td id=\"T_b2490_row10_col3\" class=\"data row10 col3\" >0.3598</td>\n",
       "      <td id=\"T_b2490_row10_col4\" class=\"data row10 col4\" >0.5142</td>\n",
       "      <td id=\"T_b2490_row10_col5\" class=\"data row10 col5\" >0.9071</td>\n",
       "      <td id=\"T_b2490_row10_col6\" class=\"data row10 col6\" >0.4748</td>\n",
       "      <td id=\"T_b2490_row10_col7\" class=\"data row10 col7\" >0.6234</td>\n",
       "      <td id=\"T_b2490_row10_col8\" class=\"data row10 col8\" >0.9527</td>\n",
       "      <td id=\"T_b2490_row10_col9\" class=\"data row10 col9\" >0.9086</td>\n",
       "      <td id=\"T_b2490_row10_col10\" class=\"data row10 col10\" >0.9301</td>\n",
       "      <td id=\"T_b2490_row10_col11\" class=\"data row10 col11\" >0.9878</td>\n",
       "      <td id=\"T_b2490_row10_col12\" class=\"data row10 col12\" >0.9139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_b2490_row11_col0\" class=\"data row11 col0\" >Parasite</td>\n",
       "      <td id=\"T_b2490_row11_col1\" class=\"data row11 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row11_col2\" class=\"data row11 col2\" >0.8855</td>\n",
       "      <td id=\"T_b2490_row11_col3\" class=\"data row11 col3\" >0.3423</td>\n",
       "      <td id=\"T_b2490_row11_col4\" class=\"data row11 col4\" >0.4938</td>\n",
       "      <td id=\"T_b2490_row11_col5\" class=\"data row11 col5\" >0.8869</td>\n",
       "      <td id=\"T_b2490_row11_col6\" class=\"data row11 col6\" >0.4505</td>\n",
       "      <td id=\"T_b2490_row11_col7\" class=\"data row11 col7\" >0.5975</td>\n",
       "      <td id=\"T_b2490_row11_col8\" class=\"data row11 col8\" >0.9499</td>\n",
       "      <td id=\"T_b2490_row11_col9\" class=\"data row11 col9\" >0.9114</td>\n",
       "      <td id=\"T_b2490_row11_col10\" class=\"data row11 col10\" >0.9302</td>\n",
       "      <td id=\"T_b2490_row11_col11\" class=\"data row11 col11\" >0.9918</td>\n",
       "      <td id=\"T_b2490_row11_col12\" class=\"data row11 col12\" >0.9099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_b2490_row12_col0\" class=\"data row12 col0\" >SW_Episode1</td>\n",
       "      <td id=\"T_b2490_row12_col1\" class=\"data row12 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row12_col2\" class=\"data row12 col2\" >0.9005</td>\n",
       "      <td id=\"T_b2490_row12_col3\" class=\"data row12 col3\" >0.3608</td>\n",
       "      <td id=\"T_b2490_row12_col4\" class=\"data row12 col4\" >0.5152</td>\n",
       "      <td id=\"T_b2490_row12_col5\" class=\"data row12 col5\" >0.9050</td>\n",
       "      <td id=\"T_b2490_row12_col6\" class=\"data row12 col6\" >0.4816</td>\n",
       "      <td id=\"T_b2490_row12_col7\" class=\"data row12 col7\" >0.6287</td>\n",
       "      <td id=\"T_b2490_row12_col8\" class=\"data row12 col8\" >0.8968</td>\n",
       "      <td id=\"T_b2490_row12_col9\" class=\"data row12 col9\" >0.8293</td>\n",
       "      <td id=\"T_b2490_row12_col10\" class=\"data row12 col10\" >0.8617</td>\n",
       "      <td id=\"T_b2490_row12_col11\" class=\"data row12 col11\" >0.9977</td>\n",
       "      <td id=\"T_b2490_row12_col12\" class=\"data row12 col12\" >0.9420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_b2490_row13_col0\" class=\"data row13 col0\" >SW_Episode1</td>\n",
       "      <td id=\"T_b2490_row13_col1\" class=\"data row13 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row13_col2\" class=\"data row13 col2\" >0.8597</td>\n",
       "      <td id=\"T_b2490_row13_col3\" class=\"data row13 col3\" >0.3354</td>\n",
       "      <td id=\"T_b2490_row13_col4\" class=\"data row13 col4\" >0.4826</td>\n",
       "      <td id=\"T_b2490_row13_col5\" class=\"data row13 col5\" >0.8689</td>\n",
       "      <td id=\"T_b2490_row13_col6\" class=\"data row13 col6\" >0.4448</td>\n",
       "      <td id=\"T_b2490_row13_col7\" class=\"data row13 col7\" >0.5884</td>\n",
       "      <td id=\"T_b2490_row13_col8\" class=\"data row13 col8\" >0.9318</td>\n",
       "      <td id=\"T_b2490_row13_col9\" class=\"data row13 col9\" >0.8634</td>\n",
       "      <td id=\"T_b2490_row13_col10\" class=\"data row13 col10\" >0.8963</td>\n",
       "      <td id=\"T_b2490_row13_col11\" class=\"data row13 col11\" >0.9915</td>\n",
       "      <td id=\"T_b2490_row13_col12\" class=\"data row13 col12\" >0.9527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_b2490_row14_col0\" class=\"data row14 col0\" >SW_Episode2</td>\n",
       "      <td id=\"T_b2490_row14_col1\" class=\"data row14 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row14_col2\" class=\"data row14 col2\" >0.9166</td>\n",
       "      <td id=\"T_b2490_row14_col3\" class=\"data row14 col3\" >0.3450</td>\n",
       "      <td id=\"T_b2490_row14_col4\" class=\"data row14 col4\" >0.5013</td>\n",
       "      <td id=\"T_b2490_row14_col5\" class=\"data row14 col5\" >0.9295</td>\n",
       "      <td id=\"T_b2490_row14_col6\" class=\"data row14 col6\" >0.4709</td>\n",
       "      <td id=\"T_b2490_row14_col7\" class=\"data row14 col7\" >0.6251</td>\n",
       "      <td id=\"T_b2490_row14_col8\" class=\"data row14 col8\" >0.8875</td>\n",
       "      <td id=\"T_b2490_row14_col9\" class=\"data row14 col9\" >0.8342</td>\n",
       "      <td id=\"T_b2490_row14_col10\" class=\"data row14 col10\" >0.8600</td>\n",
       "      <td id=\"T_b2490_row14_col11\" class=\"data row14 col11\" >0.9939</td>\n",
       "      <td id=\"T_b2490_row14_col12\" class=\"data row14 col12\" >0.9372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_b2490_row15_col0\" class=\"data row15 col0\" >SW_Episode2</td>\n",
       "      <td id=\"T_b2490_row15_col1\" class=\"data row15 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row15_col2\" class=\"data row15 col2\" >0.8970</td>\n",
       "      <td id=\"T_b2490_row15_col3\" class=\"data row15 col3\" >0.3277</td>\n",
       "      <td id=\"T_b2490_row15_col4\" class=\"data row15 col4\" >0.4800</td>\n",
       "      <td id=\"T_b2490_row15_col5\" class=\"data row15 col5\" >0.9072</td>\n",
       "      <td id=\"T_b2490_row15_col6\" class=\"data row15 col6\" >0.4437</td>\n",
       "      <td id=\"T_b2490_row15_col7\" class=\"data row15 col7\" >0.5960</td>\n",
       "      <td id=\"T_b2490_row15_col8\" class=\"data row15 col8\" >0.8973</td>\n",
       "      <td id=\"T_b2490_row15_col9\" class=\"data row15 col9\" >0.8420</td>\n",
       "      <td id=\"T_b2490_row15_col10\" class=\"data row15 col10\" >0.8687</td>\n",
       "      <td id=\"T_b2490_row15_col11\" class=\"data row15 col11\" >0.9929</td>\n",
       "      <td id=\"T_b2490_row15_col12\" class=\"data row15 col12\" >0.9362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_b2490_row16_col0\" class=\"data row16 col0\" >SW_Episode3</td>\n",
       "      <td id=\"T_b2490_row16_col1\" class=\"data row16 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row16_col2\" class=\"data row16 col2\" >0.9185</td>\n",
       "      <td id=\"T_b2490_row16_col3\" class=\"data row16 col3\" >0.3386</td>\n",
       "      <td id=\"T_b2490_row16_col4\" class=\"data row16 col4\" >0.4948</td>\n",
       "      <td id=\"T_b2490_row16_col5\" class=\"data row16 col5\" >0.9327</td>\n",
       "      <td id=\"T_b2490_row16_col6\" class=\"data row16 col6\" >0.4634</td>\n",
       "      <td id=\"T_b2490_row16_col7\" class=\"data row16 col7\" >0.6192</td>\n",
       "      <td id=\"T_b2490_row16_col8\" class=\"data row16 col8\" >0.9489</td>\n",
       "      <td id=\"T_b2490_row16_col9\" class=\"data row16 col9\" >0.8547</td>\n",
       "      <td id=\"T_b2490_row16_col10\" class=\"data row16 col10\" >0.8993</td>\n",
       "      <td id=\"T_b2490_row16_col11\" class=\"data row16 col11\" >0.9700</td>\n",
       "      <td id=\"T_b2490_row16_col12\" class=\"data row16 col12\" >0.9575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_b2490_row17_col0\" class=\"data row17 col0\" >SW_Episode3</td>\n",
       "      <td id=\"T_b2490_row17_col1\" class=\"data row17 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row17_col2\" class=\"data row17 col2\" >0.8932</td>\n",
       "      <td id=\"T_b2490_row17_col3\" class=\"data row17 col3\" >0.3219</td>\n",
       "      <td id=\"T_b2490_row17_col4\" class=\"data row17 col4\" >0.4732</td>\n",
       "      <td id=\"T_b2490_row17_col5\" class=\"data row17 col5\" >0.9077</td>\n",
       "      <td id=\"T_b2490_row17_col6\" class=\"data row17 col6\" >0.4287</td>\n",
       "      <td id=\"T_b2490_row17_col7\" class=\"data row17 col7\" >0.5823</td>\n",
       "      <td id=\"T_b2490_row17_col8\" class=\"data row17 col8\" >0.9703</td>\n",
       "      <td id=\"T_b2490_row17_col9\" class=\"data row17 col9\" >0.8566</td>\n",
       "      <td id=\"T_b2490_row17_col10\" class=\"data row17 col10\" >0.9099</td>\n",
       "      <td id=\"T_b2490_row17_col11\" class=\"data row17 col11\" >0.9828</td>\n",
       "      <td id=\"T_b2490_row17_col12\" class=\"data row17 col12\" >0.9446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_b2490_row18_col0\" class=\"data row18 col0\" >SW_Episode4</td>\n",
       "      <td id=\"T_b2490_row18_col1\" class=\"data row18 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row18_col2\" class=\"data row18 col2\" >0.9030</td>\n",
       "      <td id=\"T_b2490_row18_col3\" class=\"data row18 col3\" >0.3709</td>\n",
       "      <td id=\"T_b2490_row18_col4\" class=\"data row18 col4\" >0.5259</td>\n",
       "      <td id=\"T_b2490_row18_col5\" class=\"data row18 col5\" >0.9205</td>\n",
       "      <td id=\"T_b2490_row18_col6\" class=\"data row18 col6\" >0.4966</td>\n",
       "      <td id=\"T_b2490_row18_col7\" class=\"data row18 col7\" >0.6452</td>\n",
       "      <td id=\"T_b2490_row18_col8\" class=\"data row18 col8\" >0.9679</td>\n",
       "      <td id=\"T_b2490_row18_col9\" class=\"data row18 col9\" >0.7234</td>\n",
       "      <td id=\"T_b2490_row18_col10\" class=\"data row18 col10\" >0.8279</td>\n",
       "      <td id=\"T_b2490_row18_col11\" class=\"data row18 col11\" >0.9931</td>\n",
       "      <td id=\"T_b2490_row18_col12\" class=\"data row18 col12\" >0.9315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_b2490_row19_col0\" class=\"data row19 col0\" >SW_Episode4</td>\n",
       "      <td id=\"T_b2490_row19_col1\" class=\"data row19 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row19_col2\" class=\"data row19 col2\" >0.8733</td>\n",
       "      <td id=\"T_b2490_row19_col3\" class=\"data row19 col3\" >0.3463</td>\n",
       "      <td id=\"T_b2490_row19_col4\" class=\"data row19 col4\" >0.4960</td>\n",
       "      <td id=\"T_b2490_row19_col5\" class=\"data row19 col5\" >0.8908</td>\n",
       "      <td id=\"T_b2490_row19_col6\" class=\"data row19 col6\" >0.4551</td>\n",
       "      <td id=\"T_b2490_row19_col7\" class=\"data row19 col7\" >0.6025</td>\n",
       "      <td id=\"T_b2490_row19_col8\" class=\"data row19 col8\" >0.9771</td>\n",
       "      <td id=\"T_b2490_row19_col9\" class=\"data row19 col9\" >0.7360</td>\n",
       "      <td id=\"T_b2490_row19_col10\" class=\"data row19 col10\" >0.8396</td>\n",
       "      <td id=\"T_b2490_row19_col11\" class=\"data row19 col11\" >0.9642</td>\n",
       "      <td id=\"T_b2490_row19_col12\" class=\"data row19 col12\" >0.8888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_b2490_row20_col0\" class=\"data row20 col0\" >SW_Episode5</td>\n",
       "      <td id=\"T_b2490_row20_col1\" class=\"data row20 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row20_col2\" class=\"data row20 col2\" >0.9072</td>\n",
       "      <td id=\"T_b2490_row20_col3\" class=\"data row20 col3\" >0.3721</td>\n",
       "      <td id=\"T_b2490_row20_col4\" class=\"data row20 col4\" >0.5277</td>\n",
       "      <td id=\"T_b2490_row20_col5\" class=\"data row20 col5\" >0.9203</td>\n",
       "      <td id=\"T_b2490_row20_col6\" class=\"data row20 col6\" >0.4873</td>\n",
       "      <td id=\"T_b2490_row20_col7\" class=\"data row20 col7\" >0.6372</td>\n",
       "      <td id=\"T_b2490_row20_col8\" class=\"data row20 col8\" >0.9032</td>\n",
       "      <td id=\"T_b2490_row20_col9\" class=\"data row20 col9\" >0.8145</td>\n",
       "      <td id=\"T_b2490_row20_col10\" class=\"data row20 col10\" >0.8566</td>\n",
       "      <td id=\"T_b2490_row20_col11\" class=\"data row20 col11\" >0.9968</td>\n",
       "      <td id=\"T_b2490_row20_col12\" class=\"data row20 col12\" >0.9490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_b2490_row21_col0\" class=\"data row21 col0\" >SW_Episode5</td>\n",
       "      <td id=\"T_b2490_row21_col1\" class=\"data row21 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row21_col2\" class=\"data row21 col2\" >0.8876</td>\n",
       "      <td id=\"T_b2490_row21_col3\" class=\"data row21 col3\" >0.3550</td>\n",
       "      <td id=\"T_b2490_row21_col4\" class=\"data row21 col4\" >0.5071</td>\n",
       "      <td id=\"T_b2490_row21_col5\" class=\"data row21 col5\" >0.9040</td>\n",
       "      <td id=\"T_b2490_row21_col6\" class=\"data row21 col6\" >0.4636</td>\n",
       "      <td id=\"T_b2490_row21_col7\" class=\"data row21 col7\" >0.6129</td>\n",
       "      <td id=\"T_b2490_row21_col8\" class=\"data row21 col8\" >0.8398</td>\n",
       "      <td id=\"T_b2490_row21_col9\" class=\"data row21 col9\" >0.8667</td>\n",
       "      <td id=\"T_b2490_row21_col10\" class=\"data row21 col10\" >0.8530</td>\n",
       "      <td id=\"T_b2490_row21_col11\" class=\"data row21 col11\" >0.9346</td>\n",
       "      <td id=\"T_b2490_row21_col12\" class=\"data row21 col12\" >0.8804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_b2490_row22_col0\" class=\"data row22 col0\" >SW_Episode6</td>\n",
       "      <td id=\"T_b2490_row22_col1\" class=\"data row22 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row22_col2\" class=\"data row22 col2\" >0.9199</td>\n",
       "      <td id=\"T_b2490_row22_col3\" class=\"data row22 col3\" >0.3577</td>\n",
       "      <td id=\"T_b2490_row22_col4\" class=\"data row22 col4\" >0.5151</td>\n",
       "      <td id=\"T_b2490_row22_col5\" class=\"data row22 col5\" >0.9155</td>\n",
       "      <td id=\"T_b2490_row22_col6\" class=\"data row22 col6\" >0.4677</td>\n",
       "      <td id=\"T_b2490_row22_col7\" class=\"data row22 col7\" >0.6191</td>\n",
       "      <td id=\"T_b2490_row22_col8\" class=\"data row22 col8\" >0.9296</td>\n",
       "      <td id=\"T_b2490_row22_col9\" class=\"data row22 col9\" >0.7500</td>\n",
       "      <td id=\"T_b2490_row22_col10\" class=\"data row22 col10\" >0.8302</td>\n",
       "      <td id=\"T_b2490_row22_col11\" class=\"data row22 col11\" >0.9835</td>\n",
       "      <td id=\"T_b2490_row22_col12\" class=\"data row22 col12\" >0.9690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_b2490_row23_col0\" class=\"data row23 col0\" >SW_Episode6</td>\n",
       "      <td id=\"T_b2490_row23_col1\" class=\"data row23 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row23_col2\" class=\"data row23 col2\" >0.8660</td>\n",
       "      <td id=\"T_b2490_row23_col3\" class=\"data row23 col3\" >0.3289</td>\n",
       "      <td id=\"T_b2490_row23_col4\" class=\"data row23 col4\" >0.4767</td>\n",
       "      <td id=\"T_b2490_row23_col5\" class=\"data row23 col5\" >0.8914</td>\n",
       "      <td id=\"T_b2490_row23_col6\" class=\"data row23 col6\" >0.4416</td>\n",
       "      <td id=\"T_b2490_row23_col7\" class=\"data row23 col7\" >0.5906</td>\n",
       "      <td id=\"T_b2490_row23_col8\" class=\"data row23 col8\" >0.8823</td>\n",
       "      <td id=\"T_b2490_row23_col9\" class=\"data row23 col9\" >0.7831</td>\n",
       "      <td id=\"T_b2490_row23_col10\" class=\"data row23 col10\" >0.8297</td>\n",
       "      <td id=\"T_b2490_row23_col11\" class=\"data row23 col11\" >0.9917</td>\n",
       "      <td id=\"T_b2490_row23_col12\" class=\"data row23 col12\" >0.9442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_b2490_row24_col0\" class=\"data row24 col0\" >SW_Episode7</td>\n",
       "      <td id=\"T_b2490_row24_col1\" class=\"data row24 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row24_col2\" class=\"data row24 col2\" >0.8964</td>\n",
       "      <td id=\"T_b2490_row24_col3\" class=\"data row24 col3\" >0.3609</td>\n",
       "      <td id=\"T_b2490_row24_col4\" class=\"data row24 col4\" >0.5147</td>\n",
       "      <td id=\"T_b2490_row24_col5\" class=\"data row24 col5\" >0.9146</td>\n",
       "      <td id=\"T_b2490_row24_col6\" class=\"data row24 col6\" >0.4898</td>\n",
       "      <td id=\"T_b2490_row24_col7\" class=\"data row24 col7\" >0.6379</td>\n",
       "      <td id=\"T_b2490_row24_col8\" class=\"data row24 col8\" >0.9915</td>\n",
       "      <td id=\"T_b2490_row24_col9\" class=\"data row24 col9\" >0.7651</td>\n",
       "      <td id=\"T_b2490_row24_col10\" class=\"data row24 col10\" >0.8637</td>\n",
       "      <td id=\"T_b2490_row24_col11\" class=\"data row24 col11\" >0.9954</td>\n",
       "      <td id=\"T_b2490_row24_col12\" class=\"data row24 col12\" >0.9446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_b2490_row25_col0\" class=\"data row25 col0\" >SW_Episode7</td>\n",
       "      <td id=\"T_b2490_row25_col1\" class=\"data row25 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row25_col2\" class=\"data row25 col2\" >0.8713</td>\n",
       "      <td id=\"T_b2490_row25_col3\" class=\"data row25 col3\" >0.3445</td>\n",
       "      <td id=\"T_b2490_row25_col4\" class=\"data row25 col4\" >0.4937</td>\n",
       "      <td id=\"T_b2490_row25_col5\" class=\"data row25 col5\" >0.8868</td>\n",
       "      <td id=\"T_b2490_row25_col6\" class=\"data row25 col6\" >0.4532</td>\n",
       "      <td id=\"T_b2490_row25_col7\" class=\"data row25 col7\" >0.5999</td>\n",
       "      <td id=\"T_b2490_row25_col8\" class=\"data row25 col8\" >0.9239</td>\n",
       "      <td id=\"T_b2490_row25_col9\" class=\"data row25 col9\" >0.9253</td>\n",
       "      <td id=\"T_b2490_row25_col10\" class=\"data row25 col10\" >0.9246</td>\n",
       "      <td id=\"T_b2490_row25_col11\" class=\"data row25 col11\" >0.9989</td>\n",
       "      <td id=\"T_b2490_row25_col12\" class=\"data row25 col12\" >0.9411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_b2490_row26_col0\" class=\"data row26 col0\" >SW_Episode8</td>\n",
       "      <td id=\"T_b2490_row26_col1\" class=\"data row26 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row26_col2\" class=\"data row26 col2\" >0.8951</td>\n",
       "      <td id=\"T_b2490_row26_col3\" class=\"data row26 col3\" >0.3662</td>\n",
       "      <td id=\"T_b2490_row26_col4\" class=\"data row26 col4\" >0.5198</td>\n",
       "      <td id=\"T_b2490_row26_col5\" class=\"data row26 col5\" >0.9087</td>\n",
       "      <td id=\"T_b2490_row26_col6\" class=\"data row26 col6\" >0.4863</td>\n",
       "      <td id=\"T_b2490_row26_col7\" class=\"data row26 col7\" >0.6336</td>\n",
       "      <td id=\"T_b2490_row26_col8\" class=\"data row26 col8\" >0.9767</td>\n",
       "      <td id=\"T_b2490_row26_col9\" class=\"data row26 col9\" >0.8659</td>\n",
       "      <td id=\"T_b2490_row26_col10\" class=\"data row26 col10\" >0.9179</td>\n",
       "      <td id=\"T_b2490_row26_col11\" class=\"data row26 col11\" >0.9912</td>\n",
       "      <td id=\"T_b2490_row26_col12\" class=\"data row26 col12\" >0.9725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_b2490_row27_col0\" class=\"data row27 col0\" >SW_Episode8</td>\n",
       "      <td id=\"T_b2490_row27_col1\" class=\"data row27 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row27_col2\" class=\"data row27 col2\" >0.8714</td>\n",
       "      <td id=\"T_b2490_row27_col3\" class=\"data row27 col3\" >0.3483</td>\n",
       "      <td id=\"T_b2490_row27_col4\" class=\"data row27 col4\" >0.4977</td>\n",
       "      <td id=\"T_b2490_row27_col5\" class=\"data row27 col5\" >0.8904</td>\n",
       "      <td id=\"T_b2490_row27_col6\" class=\"data row27 col6\" >0.4604</td>\n",
       "      <td id=\"T_b2490_row27_col7\" class=\"data row27 col7\" >0.6069</td>\n",
       "      <td id=\"T_b2490_row27_col8\" class=\"data row27 col8\" >0.9711</td>\n",
       "      <td id=\"T_b2490_row27_col9\" class=\"data row27 col9\" >0.9015</td>\n",
       "      <td id=\"T_b2490_row27_col10\" class=\"data row27 col10\" >0.9350</td>\n",
       "      <td id=\"T_b2490_row27_col11\" class=\"data row27 col11\" >0.9901</td>\n",
       "      <td id=\"T_b2490_row27_col12\" class=\"data row27 col12\" >0.9736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_b2490_row28_col0\" class=\"data row28 col0\" >SW_Episode9</td>\n",
       "      <td id=\"T_b2490_row28_col1\" class=\"data row28 col1\" >base</td>\n",
       "      <td id=\"T_b2490_row28_col2\" class=\"data row28 col2\" >0.9167</td>\n",
       "      <td id=\"T_b2490_row28_col3\" class=\"data row28 col3\" >0.3629</td>\n",
       "      <td id=\"T_b2490_row28_col4\" class=\"data row28 col4\" >0.5200</td>\n",
       "      <td id=\"T_b2490_row28_col5\" class=\"data row28 col5\" >0.9192</td>\n",
       "      <td id=\"T_b2490_row28_col6\" class=\"data row28 col6\" >0.4781</td>\n",
       "      <td id=\"T_b2490_row28_col7\" class=\"data row28 col7\" >0.6291</td>\n",
       "      <td id=\"T_b2490_row28_col8\" class=\"data row28 col8\" >0.9791</td>\n",
       "      <td id=\"T_b2490_row28_col9\" class=\"data row28 col9\" >0.8786</td>\n",
       "      <td id=\"T_b2490_row28_col10\" class=\"data row28 col10\" >0.9262</td>\n",
       "      <td id=\"T_b2490_row28_col11\" class=\"data row28 col11\" >0.9972</td>\n",
       "      <td id=\"T_b2490_row28_col12\" class=\"data row28 col12\" >0.9471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2490_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_b2490_row29_col0\" class=\"data row29 col0\" >SW_Episode9</td>\n",
       "      <td id=\"T_b2490_row29_col1\" class=\"data row29 col1\" >sentiment</td>\n",
       "      <td id=\"T_b2490_row29_col2\" class=\"data row29 col2\" >0.8897</td>\n",
       "      <td id=\"T_b2490_row29_col3\" class=\"data row29 col3\" >0.3453</td>\n",
       "      <td id=\"T_b2490_row29_col4\" class=\"data row29 col4\" >0.4975</td>\n",
       "      <td id=\"T_b2490_row29_col5\" class=\"data row29 col5\" >0.9005</td>\n",
       "      <td id=\"T_b2490_row29_col6\" class=\"data row29 col6\" >0.4524</td>\n",
       "      <td id=\"T_b2490_row29_col7\" class=\"data row29 col7\" >0.6023</td>\n",
       "      <td id=\"T_b2490_row29_col8\" class=\"data row29 col8\" >0.9812</td>\n",
       "      <td id=\"T_b2490_row29_col9\" class=\"data row29 col9\" >0.9017</td>\n",
       "      <td id=\"T_b2490_row29_col10\" class=\"data row29 col10\" >0.9398</td>\n",
       "      <td id=\"T_b2490_row29_col11\" class=\"data row29 col11\" >0.9919</td>\n",
       "      <td id=\"T_b2490_row29_col12\" class=\"data row29 col12\" >0.9580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x372d67f10>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths\n",
    "keywords_dir = \"../Dataset/Extracted_Keywords/\"\n",
    "ground_truth_path = \"../Dataset/keywords_ground_truth.pkl\"\n",
    "\n",
    "# Load ground truth keywords\n",
    "keywords_ground_truth = pd.read_pickle(ground_truth_path)\n",
    "\n",
    "# Models to evaluate\n",
    "models_to_evaluate = [\"base\", \"sentiment\"]\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Container to store results for all movies and models\n",
    "global_results = []\n",
    "\n",
    "# Iterate over all predicted keyword files (one file per movie)\n",
    "for file in os.listdir(keywords_dir):\n",
    "    if file.endswith(\".pkl\") and file.startswith(\"kw_\"):\n",
    "        movie_name = file.replace(\"kw_\", \"\").replace(\".pkl\", \"\")\n",
    "        file_path = os.path.join(keywords_dir, file)\n",
    "\n",
    "        try:\n",
    "            # Load predicted keywords DataFrame and movie ID\n",
    "            selected_film = pd.read_pickle(file_path)\n",
    "            selected_film_id = selected_film[\"Movie_ID\"].iloc[0]\n",
    "\n",
    "            # Get ground truth keywords for this movie\n",
    "            kw_ground_truth = keywords_ground_truth[\n",
    "                keywords_ground_truth[\"Movie_ID\"] == selected_film_id\n",
    "            ]\n",
    "            gt_keywords = kw_ground_truth[\"Keyword\"].tolist()\n",
    "\n",
    "            # Compute average sentiment of ground truth keywords\n",
    "            gt_sentiments = []\n",
    "            for kw in gt_keywords:\n",
    "                scores = analyzer.polarity_scores(kw)\n",
    "                sentiment = 1.0 * scores[\"pos\"] + 0.5 * scores[\"neu\"]\n",
    "                gt_sentiments.append(sentiment)\n",
    "            sentiment_gt = sum(gt_sentiments) / len(gt_sentiments) if gt_sentiments else None\n",
    "\n",
    "            # Compute average sentiment from all review texts\n",
    "            review_texts = selected_film[\"Preprocessed_Review\"].dropna().tolist()\n",
    "            review_sentiments = []\n",
    "            for text in review_texts:\n",
    "                scores = analyzer.polarity_scores(text)\n",
    "                sentiment = 1.0 * scores[\"pos\"] + 0.5 * scores[\"neu\"]\n",
    "                review_sentiments.append(sentiment)\n",
    "            sentiment_text = sum(review_sentiments) / len(review_sentiments) if review_sentiments else None\n",
    "\n",
    "            # Evaluate each model globally\n",
    "            for model in models_to_evaluate:\n",
    "                pred_col = f\"keywords_{model}\"\n",
    "\n",
    "                # Lists of lists for evaluation functions:\n",
    "                # - pred_kw_per_review: list of lists of keywords (strings) for evaluate_keywords()\n",
    "                # - pred_kwscore_per_review: list of lists of (keyword, score) tuples for evaluate_keywords_weighted()\n",
    "                pred_kw_per_review = []\n",
    "                pred_kwscore_per_review = []\n",
    "                \n",
    "                # Flat list of dicts for SAS functions\n",
    "                flat_keyword_list = []\n",
    "\n",
    "                # Iterate over reviews to build these lists\n",
    "                for _, row in selected_film.iterrows():\n",
    "                    if pred_col in row and isinstance(row[pred_col], list):\n",
    "\n",
    "                        # Extract keywords only for evaluate_keywords()\n",
    "                        pred_kw_only = [kw for kw, _ in row[pred_col] if isinstance(kw, str)]\n",
    "\n",
    "                        # Extract (keyword, score) tuples for evaluate_keywords_weighted()\n",
    "                        pred_kw_score = [\n",
    "                            (kw, score) for kw, score in row[pred_col]\n",
    "                            if isinstance(kw, str) and isinstance(score, (float, int))\n",
    "                        ]\n",
    "\n",
    "                        # Append per review keyword lists if not empty\n",
    "                        if pred_kw_only:\n",
    "                            pred_kw_per_review.append(pred_kw_only)\n",
    "                        if pred_kw_score:\n",
    "                            pred_kwscore_per_review.append(pred_kw_score)\n",
    "\n",
    "                        # Append flat dicts for SAS calculations\n",
    "                        for kw, score in pred_kw_score:\n",
    "                            flat_keyword_list.append({\n",
    "                                \"keyword\": kw,\n",
    "                                \"sentiment_score\": float(score)\n",
    "                            })\n",
    "\n",
    "                # Compute classic precision, recall, F1\n",
    "                precision, recall, f1 = evaluate_keywords(pred_kw_per_review, gt_keywords)\n",
    "\n",
    "                # Compute weighted precision, recall, F1\n",
    "                w_precision, w_recall, w_f1 = evaluate_keywords_weighted(pred_kwscore_per_review, gt_keywords)\n",
    "\n",
    "                # Compute semantic precision, recall, F1\n",
    "                flat_kw_list = [kw for review in pred_kw_per_review for kw in review]\n",
    "                flat_kw_list = list(set(flat_kw_list))\n",
    "\n",
    "                semantic_precision, semantic_recall, semantic_f1 = evaluate_semantic_keywords(\n",
    "                    flat_kw_list, gt_keywords, device=device, threshold=0.65\n",
    "                )\n",
    "\n",
    "                # Compute SAS (Sentiment Appropriateness Score)\n",
    "                sas_kw = compute_sas_from_keywords([flat_keyword_list], sentiment_gt=sentiment_gt)\n",
    "                sas_txt = compute_sas_from_text([flat_keyword_list], sentiment_text=sentiment_text)\n",
    "\n",
    "                # Store results for this movie-model pair\n",
    "                global_results.append({\n",
    "                    \"Movie\": movie_name,\n",
    "                    \"Model\": model,\n",
    "                    \"Precision\": precision,\n",
    "                    \"Recall\": recall,\n",
    "                    \"F1-score\": f1,\n",
    "                    \"Weighted Precision\": w_precision,\n",
    "                    \"Weighted Recall\": w_recall,\n",
    "                    \"Weighted F1-score\": w_f1,\n",
    "                    \"Semantic Precision\": semantic_precision,\n",
    "                    \"Semantic Recall\": semantic_recall,\n",
    "                    \"Semantic F1-score\": semantic_f1,\n",
    "                    \"SAS from Keywords\": sas_kw,\n",
    "                    \"SAS from text\": sas_txt\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# Create final DataFrame and sort results\n",
    "final_df = pd.DataFrame(global_results)\n",
    "final_df = final_df.sort_values(by=[\"Movie\", \"Model\"]).reset_index(drop=True)\n",
    "final_df.style.format(precision=4).set_caption(\"Global Evaluation Summary per Movie and Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15262642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df \n",
    "final_df.to_csv(\"base_vs_sentiment_evaluation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7b893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca69ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d848a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a8b5c9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3f1c3\">\n",
       "  <caption>Rank Correlation per Movie and Model</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3f1c3_level0_col0\" class=\"col_heading level0 col0\" >Movie</th>\n",
       "      <th id=\"T_3f1c3_level0_col1\" class=\"col_heading level0 col1\" >Model</th>\n",
       "      <th id=\"T_3f1c3_level0_col2\" class=\"col_heading level0 col2\" >Rank Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3f1c3_row0_col0\" class=\"data row0 col0\" >GoodBadUgly</td>\n",
       "      <td id=\"T_3f1c3_row0_col1\" class=\"data row0 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row0_col2\" class=\"data row0 col2\" >0.7354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3f1c3_row1_col0\" class=\"data row1 col0\" >GoodBadUgly</td>\n",
       "      <td id=\"T_3f1c3_row1_col1\" class=\"data row1 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row1_col2\" class=\"data row1 col2\" >0.8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3f1c3_row2_col0\" class=\"data row2 col0\" >HarryPotter</td>\n",
       "      <td id=\"T_3f1c3_row2_col1\" class=\"data row2 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row2_col2\" class=\"data row2 col2\" >0.8135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3f1c3_row3_col0\" class=\"data row3 col0\" >HarryPotter</td>\n",
       "      <td id=\"T_3f1c3_row3_col1\" class=\"data row3 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row3_col2\" class=\"data row3 col2\" >0.8556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3f1c3_row4_col0\" class=\"data row4 col0\" >IndianaJones</td>\n",
       "      <td id=\"T_3f1c3_row4_col1\" class=\"data row4 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row4_col2\" class=\"data row4 col2\" >0.6640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3f1c3_row5_col0\" class=\"data row5 col0\" >IndianaJones</td>\n",
       "      <td id=\"T_3f1c3_row5_col1\" class=\"data row5 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row5_col2\" class=\"data row5 col2\" >0.8842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3f1c3_row6_col0\" class=\"data row6 col0\" >LaLaLand</td>\n",
       "      <td id=\"T_3f1c3_row6_col1\" class=\"data row6 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row6_col2\" class=\"data row6 col2\" >0.7608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3f1c3_row7_col0\" class=\"data row7 col0\" >LaLaLand</td>\n",
       "      <td id=\"T_3f1c3_row7_col1\" class=\"data row7 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row7_col2\" class=\"data row7 col2\" >0.8363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3f1c3_row8_col0\" class=\"data row8 col0\" >Oppenheimer</td>\n",
       "      <td id=\"T_3f1c3_row8_col1\" class=\"data row8 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row8_col2\" class=\"data row8 col2\" >0.7989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3f1c3_row9_col0\" class=\"data row9 col0\" >Oppenheimer</td>\n",
       "      <td id=\"T_3f1c3_row9_col1\" class=\"data row9 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row9_col2\" class=\"data row9 col2\" >0.8526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_3f1c3_row10_col0\" class=\"data row10 col0\" >Parasite</td>\n",
       "      <td id=\"T_3f1c3_row10_col1\" class=\"data row10 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row10_col2\" class=\"data row10 col2\" >0.7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_3f1c3_row11_col0\" class=\"data row11 col0\" >Parasite</td>\n",
       "      <td id=\"T_3f1c3_row11_col1\" class=\"data row11 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row11_col2\" class=\"data row11 col2\" >0.8033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_3f1c3_row12_col0\" class=\"data row12 col0\" >SW_Episode1</td>\n",
       "      <td id=\"T_3f1c3_row12_col1\" class=\"data row12 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row12_col2\" class=\"data row12 col2\" >0.8082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_3f1c3_row13_col0\" class=\"data row13 col0\" >SW_Episode1</td>\n",
       "      <td id=\"T_3f1c3_row13_col1\" class=\"data row13 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row13_col2\" class=\"data row13 col2\" >0.8457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_3f1c3_row14_col0\" class=\"data row14 col0\" >SW_Episode2</td>\n",
       "      <td id=\"T_3f1c3_row14_col1\" class=\"data row14 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row14_col2\" class=\"data row14 col2\" >0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_3f1c3_row15_col0\" class=\"data row15 col0\" >SW_Episode2</td>\n",
       "      <td id=\"T_3f1c3_row15_col1\" class=\"data row15 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row15_col2\" class=\"data row15 col2\" >0.8592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_3f1c3_row16_col0\" class=\"data row16 col0\" >SW_Episode3</td>\n",
       "      <td id=\"T_3f1c3_row16_col1\" class=\"data row16 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row16_col2\" class=\"data row16 col2\" >0.8138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_3f1c3_row17_col0\" class=\"data row17 col0\" >SW_Episode3</td>\n",
       "      <td id=\"T_3f1c3_row17_col1\" class=\"data row17 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row17_col2\" class=\"data row17 col2\" >0.8668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_3f1c3_row18_col0\" class=\"data row18 col0\" >SW_Episode4</td>\n",
       "      <td id=\"T_3f1c3_row18_col1\" class=\"data row18 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row18_col2\" class=\"data row18 col2\" >0.7647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_3f1c3_row19_col0\" class=\"data row19 col0\" >SW_Episode4</td>\n",
       "      <td id=\"T_3f1c3_row19_col1\" class=\"data row19 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row19_col2\" class=\"data row19 col2\" >0.8732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_3f1c3_row20_col0\" class=\"data row20 col0\" >SW_Episode5</td>\n",
       "      <td id=\"T_3f1c3_row20_col1\" class=\"data row20 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row20_col2\" class=\"data row20 col2\" >0.7539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_3f1c3_row21_col0\" class=\"data row21 col0\" >SW_Episode5</td>\n",
       "      <td id=\"T_3f1c3_row21_col1\" class=\"data row21 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row21_col2\" class=\"data row21 col2\" >0.8736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_3f1c3_row22_col0\" class=\"data row22 col0\" >SW_Episode6</td>\n",
       "      <td id=\"T_3f1c3_row22_col1\" class=\"data row22 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row22_col2\" class=\"data row22 col2\" >0.7226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_3f1c3_row23_col0\" class=\"data row23 col0\" >SW_Episode6</td>\n",
       "      <td id=\"T_3f1c3_row23_col1\" class=\"data row23 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row23_col2\" class=\"data row23 col2\" >0.8643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_3f1c3_row24_col0\" class=\"data row24 col0\" >SW_Episode7</td>\n",
       "      <td id=\"T_3f1c3_row24_col1\" class=\"data row24 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row24_col2\" class=\"data row24 col2\" >0.8242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_3f1c3_row25_col0\" class=\"data row25 col0\" >SW_Episode7</td>\n",
       "      <td id=\"T_3f1c3_row25_col1\" class=\"data row25 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row25_col2\" class=\"data row25 col2\" >0.8650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_3f1c3_row26_col0\" class=\"data row26 col0\" >SW_Episode8</td>\n",
       "      <td id=\"T_3f1c3_row26_col1\" class=\"data row26 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row26_col2\" class=\"data row26 col2\" >0.8218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_3f1c3_row27_col0\" class=\"data row27 col0\" >SW_Episode8</td>\n",
       "      <td id=\"T_3f1c3_row27_col1\" class=\"data row27 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row27_col2\" class=\"data row27 col2\" >0.8325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_3f1c3_row28_col0\" class=\"data row28 col0\" >SW_Episode9</td>\n",
       "      <td id=\"T_3f1c3_row28_col1\" class=\"data row28 col1\" >base</td>\n",
       "      <td id=\"T_3f1c3_row28_col2\" class=\"data row28 col2\" >0.7915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f1c3_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_3f1c3_row29_col0\" class=\"data row29 col0\" >SW_Episode9</td>\n",
       "      <td id=\"T_3f1c3_row29_col1\" class=\"data row29 col1\" >sentiment</td>\n",
       "      <td id=\"T_3f1c3_row29_col2\" class=\"data row29 col2\" >0.8100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x32d668940>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from scipy.stats import spearmanr\n",
    "#import nltk\n",
    "#nltk.download('vader_lexicon')  # Esegui una volta sola fuori da questo script\n",
    "\n",
    "def compute_sentiment_rank_correlation(all_predicted_keywords):\n",
    "    correlations = []\n",
    "    for review in all_predicted_keywords:\n",
    "        if len(review) < 2:\n",
    "            continue\n",
    "        sentiment_intensity = [abs(kw['sentiment_score'] - 0.5) for kw in review]\n",
    "        rank = list(reversed(range(len(review))))  # 0 = top rank keyword\n",
    "        corr, _ = spearmanr(rank, sentiment_intensity)\n",
    "        if corr is not None:\n",
    "            correlations.append(abs(corr))  # valore assoluto per forza relazione\n",
    "    return np.mean(correlations) if correlations else None\n",
    "\n",
    "# Percorsi\n",
    "keywords_dir = \"../Dataset/Extracted_Keywords/\"\n",
    "ground_truth_path = \"../Dataset/keywords_ground_truth.pkl\"\n",
    "\n",
    "# Carica ground truth keywords\n",
    "keywords_ground_truth = pd.read_pickle(ground_truth_path)\n",
    "\n",
    "# Modelli da valutare\n",
    "models_to_evaluate = [\"base\", \"sentiment\"]\n",
    "\n",
    "# Inizializza il sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "global_results = []\n",
    "\n",
    "for file in os.listdir(keywords_dir):\n",
    "    if file.endswith(\".pkl\") and file.startswith(\"kw_\"):\n",
    "        movie_name = file.replace(\"kw_\", \"\").replace(\".pkl\", \"\")\n",
    "        file_path = os.path.join(keywords_dir, file)\n",
    "\n",
    "        try:\n",
    "            selected_film = pd.read_pickle(file_path)\n",
    "            selected_film_id = selected_film[\"Movie_ID\"].iloc[0]\n",
    "\n",
    "            # Ground truth keywords per il film\n",
    "            kw_ground_truth = keywords_ground_truth[\n",
    "                keywords_ground_truth[\"Movie_ID\"] == selected_film_id\n",
    "            ]\n",
    "            gt_keywords = kw_ground_truth[\"Keyword\"].tolist()\n",
    "\n",
    "            # Calcola sentiment medio keyword GT\n",
    "            gt_sentiments = []\n",
    "            for kw in gt_keywords:\n",
    "                scores = analyzer.polarity_scores(kw)\n",
    "                sentiment = 1.0 * scores[\"pos\"] + 0.5 * scores[\"neu\"]\n",
    "                gt_sentiments.append(sentiment)\n",
    "            sentiment_gt = sum(gt_sentiments) / len(gt_sentiments) if gt_sentiments else None\n",
    "\n",
    "            # Calcola sentiment medio da recensioni\n",
    "            review_texts = selected_film[\"Preprocessed_Review\"].dropna().tolist()\n",
    "            review_sentiments = []\n",
    "            for text in review_texts:\n",
    "                scores = analyzer.polarity_scores(text)\n",
    "                sentiment = 1.0 * scores[\"pos\"] + 0.5 * scores[\"neu\"]\n",
    "                review_sentiments.append(sentiment)\n",
    "            sentiment_text = sum(review_sentiments) / len(review_sentiments) if review_sentiments else None\n",
    "\n",
    "            for model in models_to_evaluate:\n",
    "                pred_col = f\"keywords_{model}\"\n",
    "\n",
    "                all_predicted_keywords_per_review = []\n",
    "\n",
    "                for _, row in selected_film.iterrows():\n",
    "                    if pred_col in row and isinstance(row[pred_col], list):\n",
    "                        review_kw = []\n",
    "                        for kw, score in row[pred_col]:\n",
    "                            if isinstance(kw, str) and isinstance(score, (float, int)):\n",
    "                                review_kw.append({\n",
    "                                    \"keyword\": kw,\n",
    "                                    \"sentiment_score\": float(score)\n",
    "                                })\n",
    "                        if review_kw:\n",
    "                            all_predicted_keywords_per_review.append(review_kw)\n",
    "\n",
    "                if not all_predicted_keywords_per_review:\n",
    "                    continue\n",
    "\n",
    "                rank_corr = compute_sentiment_rank_correlation(all_predicted_keywords_per_review)\n",
    "\n",
    "                global_results.append({\n",
    "                    \"Movie\": movie_name,\n",
    "                    \"Model\": model,\n",
    "                    \"Rank Correlation\": rank_corr\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "final_df = pd.DataFrame(global_results)\n",
    "final_df = final_df.sort_values(by=[\"Movie\", \"Model\"]).reset_index(drop=True)\n",
    "\n",
    "final_df.style.format(precision=4).set_caption(\"Rank Correlation per Movie and Model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
