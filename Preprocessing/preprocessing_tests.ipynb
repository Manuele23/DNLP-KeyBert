{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing Test Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to **test and demonstrate the behavior of a lightweight text preprocessing pipeline** implemented in the `Preprocessor` class. The preprocessing steps are tailored to prepare movie reviews for transformer-based keyword extraction using models like **KeyBERT** with **`all-MiniLM-L6-v2`** embeddings.\n",
    "\n",
    "The main preprocessing operations include:\n",
    "- **Punctuation-spacing normalization**, ensuring better readability and compatibility with tokenizer expectations  \n",
    "- **Typo correction** using `autocorrect`, with enhanced handling of repeated letters and proper nouns \n",
    "- **Nonsense/empty review filtering**, removing short or unintelligible entries that would reduce model quality  \n",
    "\n",
    "Each step is tested with controlled input examples to verify correctness and robustness before applying the pipeline to full datasets.\n",
    "\n",
    "> **Note**:  \n",
    "> - **Lemmatization is not performed**, as transformer models (like MiniLM) internally manage word variation through subword tokenization and contextual embeddings.  \n",
    "> - **Stop word removal is also skipped**, since this is handled during keyword selection by custom KeyBERT extensions.  \n",
    "> This ensures compatibility with downstream transformer models and preserves the contextual richness needed for accurate keyword extraction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Installing and Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas is already installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelemustari/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy is already installed.\n",
      "autocorrect is already installed.\n",
      "wordfreq is already installed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"pandas\",                         \n",
    "    \"spacy\",           \n",
    "    \"autocorrect\",\n",
    "    \"wordfreq\"\n",
    "]\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip if it's not already installed.\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"{package} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Check and install missing packages\n",
    "for package in required_packages:\n",
    "    install_package(package)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports for preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "# Text processing\n",
    "import re\n",
    "from autocorrect import Speller\n",
    "from wordfreq import zipf_frequency # type: ignore\n",
    "\n",
    "# spaCy for NLP tasks\n",
    "import spacy\n",
    "\n",
    "# Load the English language model in spaCy (download if not present)\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading 'en_core_web_sm' model...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Custom Preprocessor\n",
    "\n",
    "This cell imports the `Preprocessor` class from the custom `preprocessing.py` module.  \n",
    "The class encapsulates all the text cleaning operations required to prepare review texts before passing them to a Transformer-based model.  \n",
    "It provides methods for typo correction, punctuation normalization and filtering of nonsensical content, and will be applied to each review in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import Preprocessor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 ‚Äì Typo Correction\n",
    "\n",
    "This test evaluates the typo correction capabilities of the `Preprocessor` class.\n",
    "\n",
    "The input consists of sentences with common spelling errors such as:\n",
    "- `\"amazng\"` ‚Üí `\"amazing\"`  \n",
    "- `\"dirction\"` ‚Üí `\"direction\"`  \n",
    "- `\"absolutly\"` ‚Üí `\"absolutely\"`\n",
    "\n",
    "Typo correction is a key step in improving the quality of keyword extraction and semantic embeddings.  \n",
    "The logic implemented combines several techniques:\n",
    "\n",
    "- **Whitespace normalization**: collapses multiple consecutive spaces into a single space.\n",
    "\n",
    "- **Proper noun preservation**: capitalized words that are not at the beginning of a sentence are excluded from correction to avoid altering named entities.\n",
    "\n",
    "- **Character repetition handling**:\n",
    "   - If a word contains 3 or more repeated alphabetic characters (e.g., \"loooong\"), they are first reduced to 2 (‚Üí \"loong\"), then to 1 (‚Üí \"long\"), checking validity at each step.\n",
    "   - If reducing the repetition results in a valid word, that version is kept.\n",
    "\n",
    "- **Autocorrect fallback**: if no valid form is found through the above steps, the word is passed to `autocorrect` for correction.\n",
    "\n",
    "This combined approach prevents overcorrection (e.g., `\"baad\"` becoming `\"band\"`) and enhances the robustness of the text preprocessing pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Typo Correction Test ===\n",
      "\n",
      "Review 1:\n",
      "Original:  This movi was amazng\n",
      "Corrected: This move was amazing\n",
      "\n",
      "Review 2:\n",
      "Original:  The dirction of the film is goooood\n",
      "Corrected: The direction of the film is good\n",
      "\n",
      "Review 3:\n",
      "Original:  Charactrs were not believabl\n",
      "Corrected: Characters were not believable\n",
      "\n",
      "Review 4:\n",
      "Original:  Absolutly stunning      performnce by the lead actr\n",
      "Corrected: Absolutely stunning performance by the lead actor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the preprocessor\n",
    "pre = Preprocessor()\n",
    "\n",
    "# Sample reviews with typos\n",
    "typo_reviews = [\n",
    "    \"This movi was amazng\",\n",
    "    \"The dirction of the film is goooood\",\n",
    "    \"Charactrs were not believabl\",\n",
    "    \"Absolutly stunning      performnce by the lead actr\",\n",
    "]\n",
    "\n",
    "# Apply typo correction only\n",
    "print(\"=== Typo Correction Test ===\\n\")\n",
    "for i, review in enumerate(typo_reviews, 1):\n",
    "    corrected = pre.correct_typos(review)\n",
    "    print(f\"Review {i}:\\nOriginal:  {review}\\nCorrected: {corrected}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 ‚Äì Punctuation Spacing Normalization\n",
    "\n",
    "This test evaluates the punctuation spacing normalization step of the `Preprocessor` class.\n",
    "\n",
    "The objective is to ensure that a **space is inserted after punctuation marks** (such as `.`, `,`, `!`, `?`, `;`, `:`) **only when appropriate**.  \n",
    "Specifically, a space is added **only if** the punctuation is **directly followed by a letter or underscore**, and **not** by a digit or another punctuation mark.\n",
    "\n",
    "This normalization improves **readability** and prevents the **merging of adjacent words**, which could negatively affect downstream tasks like tokenization or embedding.  \n",
    "At the same time, it preserves numeric formats and punctuation sequences such as:\n",
    "- `\"Hello.This\"` ‚Üí `\"Hello. This\"` \n",
    "- `\"Wow!!!Great\"` ‚Üí `\"Wow!!! Great\"` \n",
    "- `\"Price is $200,000.00\"` ‚Üí remains unchanged\n",
    "\n",
    "By applying this rule selectively, the model maintains clean sentence structure without corrupting numerical data or stylistic emphasis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1: This movie is great!Amazing direction.\n",
      "Normalized 1: This movie is great! Amazing direction.\n",
      "\n",
      "Original 2: Wait...what?Really?\n",
      "Normalized 2: Wait... what? Really?\n",
      "\n",
      "Original 3: Incredible,unbelievable!Must watch.\n",
      "Normalized 3: Incredible, unbelievable! Must watch.\n",
      "\n",
      "Original 4: I loved it.The actors were amazing.\n",
      "Normalized 4: I loved it. The actors were amazing.\n",
      "\n",
      "Original 5: I paid 300,000$ this house!!!It was worth it.\n",
      "Normalized 5: I paid 300,000$ this house!!! It was worth it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Preprocessor\n",
    "pre = Preprocessor()\n",
    "\n",
    "# Sample reviews with punctuation issues\n",
    "sample_texts = [\n",
    "    \"This movie is great!Amazing direction.\",\n",
    "    \"Wait...what?Really?\",\n",
    "    \"Incredible,unbelievable!Must watch.\",\n",
    "    \"I loved it.The actors were amazing.\",\n",
    "    \"I paid 300,000$ this house!!!It was worth it.\",\n",
    "]\n",
    "\n",
    "# Apply only punctuation spacing normalization\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    normalized = pre.normalize_spacing(text)\n",
    "    print(f\"Original {i}: {text}\")\n",
    "    print(f\"Normalized {i}: {normalized}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3 ‚Äì Nonsense Detection\n",
    "\n",
    "This test evaluates the ability of the `Preprocessor` class to detect and flag **nonsensical or low-quality reviews**.\n",
    "\n",
    "The implemented logic marks a review as *nonsense* if it satisfies one of the following conditions:\n",
    "- The text is **too short** (e.g., fewer than 10 characters).\n",
    "- The **ratio of alphabetic characters** to total characters is very low (e.g., dominated by symbols or numbers).\n",
    "\n",
    "This filtering step is essential to discard meaningless entries that could negatively affect downstream tasks such as embedding generation or keyword extraction.\n",
    "\n",
    "We isolate and apply only the **nonsense detection** module in this test, checking how it handles various inputs including:\n",
    "- Empty strings  \n",
    "- Symbol-only content  \n",
    "- Short but meaningful phrases  \n",
    "- Number-dominated text  \n",
    "\n",
    "Each input is labeled as either `OK` (valid) or `NONSENSE` (to be discarded).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: '!!!...??' ‚Üí NONSENSE\n",
      "\n",
      "Sample 2: '1234567890' ‚Üí NONSENSE\n",
      "\n",
      "Sample 3: 'Ok' ‚Üí NONSENSE\n",
      "\n",
      "Sample 4: 'This is fine.' ‚Üí OK\n",
      "\n",
      "Sample 5: '....' ‚Üí NONSENSE\n",
      "\n",
      "Sample 6: '!!!!????....' ‚Üí NONSENSE\n",
      "\n",
      "Sample 7: 'The movie was good.' ‚Üí OK\n",
      "\n",
      "Sample 8: 'üëçüèªüëçüèªüëçüèª' ‚Üí NONSENSE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Preprocessor\n",
    "from preprocessing import Preprocessor\n",
    "pre = Preprocessor()\n",
    "\n",
    "# Test cases for nonsense detection\n",
    "samples = [\n",
    "    \"!!!...??\",               # Only punctuation\n",
    "    \"1234567890\",             # Only numbers\n",
    "    \"Ok\",                     # Too short\n",
    "    \"This is fine.\",          # Valid sentence\n",
    "    \"....\",                   # Dots only\n",
    "    \"!!!!????....\",           # Random punctuation\n",
    "    \"The movie was good.\",    # Proper review\n",
    "    \"üëçüèªüëçüèªüëçüèª\"                   # Emoticons only\n",
    "]\n",
    "\n",
    "# Apply nonsense detection logic\n",
    "for i, sample in enumerate(samples, 1):\n",
    "    result = pre.is_nonsense(sample)\n",
    "    status = \"NONSENSE\" if result else \"OK\"\n",
    "    print(f\"Sample {i}: '{sample}' ‚Üí {status}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4 ‚Äì Full Preprocessing Pipeline\n",
    "\n",
    "This test evaluates the **entire preprocessing pipeline** implemented in the `Preprocessor` class.  \n",
    "The pipeline includes all previously tested steps, executed in sequence:\n",
    "\n",
    "1. **Typo Correction** ‚Üí Fixes common spelling mistakes.\n",
    "2. **Punctuation Spacing Normalization** ‚Üí Ensures correct spacing after punctuation marks, but only when followed by a letter.\n",
    "3. **Nonsense Detection** ‚Üí Removes reviews that are too short or composed mostly of symbols and digits.\n",
    "\n",
    "We apply this pipeline to a variety of noisy reviews to verify its effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 1 ===\n",
      "Original:  This movie is absoltly      amazng!The charactrs were believabl(not all of theeeem).\n",
      "Processed: This movie is absolutely amazing! The characters were believable (not all of them).\n",
      "\n",
      "=== Sample 2 ===\n",
      "Original:  Whaat??Noo...thiiiiis is baad dirction!!!\n",
      "Processed: What?? No... this is bad direction!!!\n",
      "\n",
      "=== Sample 3 ===\n",
      "Original:  1234 .... ü§ñü§ñü§ñ ???\n",
      "REMOVED (nonsense)\n",
      "\n",
      "=== Sample 4 ===\n",
      "Original:  OMG thisss   moviiee wazzz sooo üò≠üò≠baaad...but kinda goood??!!(I thinkkk).LOVEDDDD ittttt üòÖ 4 realzz!!!!!!!\n",
      "Processed: OMG this movie jazz soo bad... but kinda good??!! (I think). LOVED it 4 really!!!!!!!\n",
      "\n",
      "=== Sample 5 ===\n",
      "Original:  LOOOOOVED the filmmmm!!!!!I see it on VHS and the end was...unexpected!\n",
      "Processed: LOVED the film!!!!! I see it on HS and the end was... unexpected!\n",
      "\n",
      "=== Sample 6 ===\n",
      "Original:  It is nots very          baaaaad,burt        not thatttt goad eithaer.\n",
      "Processed: It is not very bad, but not that good either.\n"
     ]
    }
   ],
   "source": [
    "# Define sample reviews for the full pipeline\n",
    "samples = [\n",
    "    \"This movie is absoltly      amazng!The charactrs were believabl(not all of theeeem).\",\n",
    "    \"Whaat??Noo...thiiiiis is baad dirction!!!\",\n",
    "    \"1234 .... ü§ñü§ñü§ñ ???\",  # nonsense\n",
    "    \"OMG thisss   moviiee wazzz sooo üò≠üò≠baaad...but kinda goood??!!(I thinkkk).LOVEDDDD ittttt üòÖ 4 realzz!!!!!!!\",\n",
    "    \"LOOOOOVED the filmmmm!!!!!I see it on VHS and the end was...unexpected!\",\n",
    "    \"It is nots very          baaaaad,burt        not thatttt goad eithaer.\"\n",
    "]\n",
    "\n",
    "# Apply full preprocessing pipeline\n",
    "for i, sample in enumerate(samples, 1):\n",
    "    result = pre.preprocess_review(sample)\n",
    "    status = \"REMOVED (nonsense)\" if result is None else f\"Processed: {result}\"\n",
    "    print(f\"\\n=== Sample {i} ===\\nOriginal:  {sample}\\n{status}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
