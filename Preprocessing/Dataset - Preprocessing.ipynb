{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas is already installed.\n",
      "spacy is already installed.\n",
      "nltk is already installed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"pandas\", \"spacy\", \"nltk\"\n",
    "]\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip if it's not already installed.\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"{package} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Check and install missing packages\n",
    "for package in required_packages:\n",
    "    install_package(package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Dataset: `other_reviews_df.pkl`\n",
    "\n",
    "In this section, we load and explore the `other_reviews_df.pkl` dataset.\n",
    "The goal is to understand the structure of the DataFrame, particularly identifying the column that contains the review text, in order to proceed with the preprocessing required for keyword extraction using KeyBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['Review_ID', 'Movie_ID', 'Movie_Title', 'Rating', 'Review_Date', 'Review_Title', 'Review_Text', 'Helpful_Votes', 'Total_Votes']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Movie_Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Helpful_Votes</th>\n",
       "      <th>Total_Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9637661</td>\n",
       "      <td>tt6751668</td>\n",
       "      <td>Parasite</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23 February 2024</td>\n",
       "      <td>Solid Film Craftsmanship, Trash Story</td>\n",
       "      <td>I'm genuinely baffled this film won not only b...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5510542</td>\n",
       "      <td>tt6751668</td>\n",
       "      <td>Parasite</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26 February 2020</td>\n",
       "      <td>MASTERPIECE</td>\n",
       "      <td>Just watch it. It has everything; entertainmen...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5182892</td>\n",
       "      <td>tt6751668</td>\n",
       "      <td>Parasite</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12 October 2019</td>\n",
       "      <td>First Hit: I really enjoyed this story as it d...</td>\n",
       "      <td>First Hit: I really enjoyed this story as it d...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5499682</td>\n",
       "      <td>tt6751668</td>\n",
       "      <td>Parasite</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21 February 2020</td>\n",
       "      <td>If you love cliché stories this movie is not f...</td>\n",
       "      <td>I was not expecting that much of this movie. N...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6094155</td>\n",
       "      <td>tt6751668</td>\n",
       "      <td>Parasite</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14 September 2020</td>\n",
       "      <td>Amazing.</td>\n",
       "      <td>Good acting, cinematography, twists and screen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Review_ID   Movie_ID Movie_Title  Rating        Review_Date  \\\n",
       "0   9637661  tt6751668    Parasite     5.0   23 February 2024   \n",
       "1   5510542  tt6751668    Parasite    10.0   26 February 2020   \n",
       "2   5182892  tt6751668    Parasite    10.0    12 October 2019   \n",
       "3   5499682  tt6751668    Parasite     9.0   21 February 2020   \n",
       "4   6094155  tt6751668    Parasite     8.0  14 September 2020   \n",
       "\n",
       "                                        Review_Title  \\\n",
       "0              Solid Film Craftsmanship, Trash Story   \n",
       "1                                        MASTERPIECE   \n",
       "2  First Hit: I really enjoyed this story as it d...   \n",
       "3  If you love cliché stories this movie is not f...   \n",
       "4                                           Amazing.   \n",
       "\n",
       "                                         Review_Text  Helpful_Votes  \\\n",
       "0  I'm genuinely baffled this film won not only b...            3.0   \n",
       "1  Just watch it. It has everything; entertainmen...            3.0   \n",
       "2  First Hit: I really enjoyed this story as it d...           24.0   \n",
       "3  I was not expecting that much of this movie. N...            2.0   \n",
       "4  Good acting, cinematography, twists and screen...            0.0   \n",
       "\n",
       "   Total_Votes  \n",
       "0          8.0  \n",
       "1          5.0  \n",
       "2         40.0  \n",
       "3          5.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_pickle('../Dataset/others_reviews_df.pkl')\n",
    "\n",
    "# Display available columns and the first rows\n",
    "print(\"Available columns:\", df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of `Review_Text` for KeyBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing and Using `en_core_web_sm`\n",
    "\n",
    "`en_core_web_sm` is a lightweight English language model provided by **spaCy**. It includes essential NLP features such as:\n",
    "- **Tokenization**: Splits text into individual words.\n",
    "- **Part-of-Speech (POS) Tagging**: Assigns grammatical categories to words.\n",
    "- **Lemmatization**: Converts words to their base forms.\n",
    "- **Named Entity Recognition (NER)**: Identifies entities like names, dates, and locations.\n",
    "\n",
    "In our case, we use `en_core_web_sm` specifically for **lemmatization**, which helps standardize words by reducing them to their root form. This improves the quality of keyword extraction with **KeyBERT**, as it avoids redundant variations of the same word.\n",
    "\n",
    "Before using it, we need to install the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy model 'en_core_web_sm' is already installed.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Check if en_core_web_sm is already installed\n",
    "try:\n",
    "    spacy.load(\"en_core_web_sm\")\n",
    "    print(\"spaCy model 'en_core_web_sm' is already installed.\")\n",
    "# Install the model if it's not already installed\n",
    "except OSError:\n",
    "    print(\"Downloading 'en_core_web_sm' model...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    print(\"Model 'en_core_web_sm' installed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the reviews \n",
    "\n",
    "To prepare the review text for keyword extraction with KeyBERT, we apply several preprocessing steps:\n",
    "- Convert all text to **lowercase**.\n",
    "- Remove **punctuation** and **special characters**.\n",
    "- Remove **common stopwords** to focus on meaningful words.\n",
    "- Apply **lemmatization** or **stemming** to standardize word forms.\n",
    "- (**Optional**) Filter out very short reviews that may not provide useful keywords.\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "Both Lemmization and Stemming reduce words to their base forms, but with key differences:\n",
    "- Lemmatization uses a linguistic dictionary to find the base form (lemma) of a word. It is more accurate but slower.\n",
    "    - Example: “running” → “run”, “better” → “good”.\n",
    "- Stemming removes suffixes without considering the meaning, sometimes producing incorrect word forms. It is faster but less precise.\n",
    "    - Example: “running” → “runn”, “better” → “better”.\n",
    "\n",
    "For KeyBERT, lemmatization is preferable as it preserves readable and correct words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/manuelemustari/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load NLP tools\n",
    "nlp = spacy.load(\"en_core_web_sm\")                      # Load spaCy's English tokenizer to lemmatize text\n",
    "nltk.download('stopwords')                              # Download NLTK's stopwords to remove them from text\n",
    "stop_words = set(stopwords.words('english'))            # Get the list of stopwords in English\n",
    "stemmer = PorterStemmer()                               # Initialize Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"you'll\", 'she', 'all', 'against', 'while', 'both', 'each', 'o', 'yourself', 'can', 'our', 'very', 'those', 'will', 'shan', 'some', 'ain', 'below', 'doesn', 't', \"it'll\", 'how', 'or', 'which', 'are', 'ma', 'mightn', \"it'd\", 'we', \"we're\", 'during', 'themselves', 'he', 'ours', \"needn't\", \"haven't\", \"she's\", 'isn', 'am', 'aren', 'yourselves', 'myself', \"hasn't\", 'him', \"wouldn't\", 'through', 'hers', 'being', 'in', 'didn', 'don', \"won't\", 'theirs', 'then', \"aren't\", 'haven', \"she'll\", \"you've\", 'doing', 'needn', 'been', \"she'd\", 'won', 'by', 'should', 's', 'as', 'again', 'down', \"we've\", 'mustn', 'so', \"mightn't\", 'there', 'hadn', \"weren't\", 'because', 'at', 'their', 'who', 'with', 'few', \"they're\", 'shouldn', 'where', 'were', 'an', 'having', 'any', \"he's\", 'out', 'nor', 'other', 'here', 'of', 'does', 'hasn', 'before', \"isn't\", \"mustn't\", 'once', 'only', 'such', 'up', \"wasn't\", 'further', 'if', 'above', 'll', 'more', 'my', \"hadn't\", \"we'd\", 'a', 'wasn', 'you', 'than', \"i've\", 'most', 'not', \"i'm\", 'after', 'weren', 'couldn', \"they've\", 'yours', 'had', 'herself', \"couldn't\", 'into', \"don't\", \"he'll\", \"shan't\", \"shouldn't\", \"should've\", \"i'd\", 'be', \"i'll\", 'until', 'to', 'did', 'whom', 're', 'them', 'has', 'me', 'the', 'his', 'and', \"they'd\", \"they'll\", 'too', 'just', 'from', 'was', 'on', 'is', 'why', 'her', 'off', 'y', \"it's\", 'i', 'do', 'itself', 'm', 'himself', 'no', 've', \"doesn't\", 'when', 'it', 'about', \"you're\", \"didn't\", \"we'll\", 'under', \"you'd\", 'your', 'that', 'have', 'now', 'same', 'what', 'but', 'its', 'own', 'd', 'they', 'ourselves', 'this', 'for', \"that'll\", 'these', 'over', 'wouldn', \"he'd\", 'between'}\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text Function\n",
    "def clean_text(text):\n",
    "    \"\"\" Convert text to lowercase and remove special characters \"\"\"\n",
    "    if not isinstance(text, str):  # Handle non-string values\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuation and special characters\n",
    "    return text\n",
    "\n",
    "# Lemmization Function\n",
    "def lemmatize_text(text):\n",
    "    \"\"\" Apply lemmatization using spaCy \"\"\"\n",
    "    # Tokenize the text\n",
    "    doc = nlp(text)    \n",
    "\n",
    "    # Lemmatize each token and join             \n",
    "    return \" \".join([token.lemma_ for token in doc if token.text not in stop_words])\n",
    "\n",
    "# Stemming Function\n",
    "def stem_text(text):\n",
    "    \"\"\" Apply stemming using Porter Stemmer \"\"\"\n",
    "    # Tokenize the text\n",
    "    words = text.split()\n",
    "    # Stem each word and join\n",
    "    return \" \".join([stemmer.stem(word) for word in words if word not in stop_words])\n",
    "\n",
    "# Preprocess Reviews Function\n",
    "def preprocess_text(text, method=\"lemma\"):\n",
    "    \"\"\"\n",
    "    Preprocess text by cleaning and applying either lemmatization or stemming.\n",
    "    - 'lemma' applies lemmatization using spaCy.\n",
    "    - 'stem' applies stemming using NLTK.\n",
    "    \"\"\"\n",
    "    cleaned = clean_text(text)\n",
    "\n",
    "    if method == \"lemma\":\n",
    "        return lemmatize_text(cleaned)\n",
    "    elif method == \"stem\":\n",
    "        return stem_text(cleaned)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose 'lemma' or 'stem'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15132/15132 [12:19<00:00, 20.47it/s]\n",
      "100%|██████████| 15132/15132 [01:10<00:00, 213.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Processed_Review_Title</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Processed_Review_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solid Film Craftsmanship, Trash Story</td>\n",
       "      <td>solid film craftsmanship trash story</td>\n",
       "      <td>I'm genuinely baffled this film won not only b...</td>\n",
       "      <td>genuinely baffle film good foreign film good d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MASTERPIECE</td>\n",
       "      <td>masterpiece</td>\n",
       "      <td>Just watch it. It has everything; entertainmen...</td>\n",
       "      <td>watch everything entertainment comedy thrill h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First Hit: I really enjoyed this story as it d...</td>\n",
       "      <td>first hit really enjoy story dive hilarious ab...</td>\n",
       "      <td>First Hit: I really enjoyed this story as it d...</td>\n",
       "      <td>first hit really enjoy story dive hilarious ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you love cliché stories this movie is not f...</td>\n",
       "      <td>love clich story movie</td>\n",
       "      <td>I was not expecting that much of this movie. N...</td>\n",
       "      <td>expect much movie normally film nominate oscar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing.</td>\n",
       "      <td>amazing</td>\n",
       "      <td>Good acting, cinematography, twists and screen...</td>\n",
       "      <td>good act cinematography twist screenplay side ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Review_Title  \\\n",
       "0              Solid Film Craftsmanship, Trash Story   \n",
       "1                                        MASTERPIECE   \n",
       "2  First Hit: I really enjoyed this story as it d...   \n",
       "3  If you love cliché stories this movie is not f...   \n",
       "4                                           Amazing.   \n",
       "\n",
       "                              Processed_Review_Title  \\\n",
       "0               solid film craftsmanship trash story   \n",
       "1                                        masterpiece   \n",
       "2  first hit really enjoy story dive hilarious ab...   \n",
       "3                             love clich story movie   \n",
       "4                                            amazing   \n",
       "\n",
       "                                         Review_Text  \\\n",
       "0  I'm genuinely baffled this film won not only b...   \n",
       "1  Just watch it. It has everything; entertainmen...   \n",
       "2  First Hit: I really enjoyed this story as it d...   \n",
       "3  I was not expecting that much of this movie. N...   \n",
       "4  Good acting, cinematography, twists and screen...   \n",
       "\n",
       "                               Processed_Review_Text  \n",
       "0  genuinely baffle film good foreign film good d...  \n",
       "1  watch everything entertainment comedy thrill h...  \n",
       "2  first hit really enjoy story dive hilarious ab...  \n",
       "3  expect much movie normally film nominate oscar...  \n",
       "4  good act cinematography twist screenplay side ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Enable tqdm for pandas apply\n",
    "tqdm.pandas()\n",
    "\n",
    "# Create a copy of the original DataFrame\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Apply lemmatization to review body text\n",
    "df_processed['Processed_Review_Text'] = df_processed['Review_Text'].progress_apply(lambda x: preprocess_text(x, method=\"lemma\"))\n",
    "\n",
    "# Apply stemming to review titles\n",
    "df_processed['Processed_Review_Title'] = df_processed['Review_Title'].progress_apply(lambda x: preprocess_text(x, method=\"lemma\"))\n",
    "\n",
    "# Display a preview of the result\n",
    "df_processed[['Review_Title', 'Processed_Review_Title', 'Review_Text', 'Processed_Review_Text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the First Preprocessed Dataset\n",
    "\n",
    "After completing the text preprocessing steps, we save the resulting DataFrame as a `.pkl` file to ensure consistency with the original dataset format.  \n",
    "The output filename uses the same base name as the original file, prefixed with `preprocessed_`, allowing us to distinguish it while preserving traceability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset saved to: ../Dataset/preprocessed_others_reviews_df.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the processed DataFrame to a new pickle file\n",
    "output_path = '../Dataset/preprocessed_others_reviews_df.pkl'\n",
    "df_processed.to_pickle(output_path)\n",
    "print(f\"Preprocessed dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Dataset; `sw_reviews.pkl`\n",
    "\n",
    "We now apply the same preprocessing pipeline to the second dataset, `sw_reviews.pkl`.  \n",
    "The objective is to clean and standardize both the review text and titles using the previously defined functions:\n",
    "- Lemmatization is applied to the main review text.\n",
    "- Stemming is applied to the review titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36192/36192 [35:19<00:00, 17.07it/s] \n",
      "100%|██████████| 36192/36192 [02:44<00:00, 219.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Processed_Review_Title</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Processed_Review_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Impossible to watch with fresh eyes</td>\n",
       "      <td>impossible watch fresh eye</td>\n",
       "      <td>It was a long time ago when I first saw Star W...</td>\n",
       "      <td>long time ago first see star war watch part tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's Still Just Star Wars to Me</td>\n",
       "      <td>still star war</td>\n",
       "      <td>While I will acknowledge its faults this is st...</td>\n",
       "      <td>acknowledge fault still one favorite film time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A modern myth that can't be beat</td>\n",
       "      <td>modern myth can not beat</td>\n",
       "      <td>Star Wars is a modern myth that has a story li...</td>\n",
       "      <td>star war modern myth story line can not beat t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There is a God and his name is George Lucas</td>\n",
       "      <td>god name george lucas</td>\n",
       "      <td>I saw for the first time when I was six years ...</td>\n",
       "      <td>see first time six year old way back   get old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good but over-rated.</td>\n",
       "      <td>good overrate</td>\n",
       "      <td>Frankly, I think \"Star wars\" is a great movie....</td>\n",
       "      <td>frankly think star war great movie   way first...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Review_Title      Processed_Review_Title  \\\n",
       "0          Impossible to watch with fresh eyes  impossible watch fresh eye   \n",
       "1              It's Still Just Star Wars to Me              still star war   \n",
       "2             A modern myth that can't be beat    modern myth can not beat   \n",
       "3  There is a God and his name is George Lucas       god name george lucas   \n",
       "4                         Good but over-rated.               good overrate   \n",
       "\n",
       "                                         Review_Text  \\\n",
       "0  It was a long time ago when I first saw Star W...   \n",
       "1  While I will acknowledge its faults this is st...   \n",
       "2  Star Wars is a modern myth that has a story li...   \n",
       "3  I saw for the first time when I was six years ...   \n",
       "4  Frankly, I think \"Star wars\" is a great movie....   \n",
       "\n",
       "                               Processed_Review_Text  \n",
       "0  long time ago first see star war watch part tr...  \n",
       "1  acknowledge fault still one favorite film time...  \n",
       "2  star war modern myth story line can not beat t...  \n",
       "3  see first time six year old way back   get old...  \n",
       "4  frankly think star war great movie   way first...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the second dataset\n",
    "df_sw = pd.read_pickle('../Dataset/sw_reviews_df.pkl')\n",
    "\n",
    "# Enable tqdm for pandas apply\n",
    "tqdm.pandas()\n",
    "\n",
    "# Create a processed copy\n",
    "df_sw_processed = df_sw.copy()\n",
    "\n",
    "# Apply preprocessing\n",
    "df_sw_processed['Processed_Review_Text'] = df_sw_processed['Review_Text'].progress_apply(lambda x: preprocess_text(x, method=\"lemma\"))\n",
    "df_sw_processed['Processed_Review_Title'] = df_sw_processed['Review_Title'].progress_apply(lambda x: preprocess_text(x, method=\"lemma\"))\n",
    "\n",
    "# Display a preview of the result\n",
    "df_sw_processed[['Review_Title', 'Processed_Review_Title', 'Review_Text', 'Processed_Review_Text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Second Preprocessed Dataset\n",
    "\n",
    "The preprocessed version of `sw_reviews.pkl` is saved in `.pkl` format using the same naming convention as before.  \n",
    "The file is named `preprocessed_sw_reviews.pkl` to ensure clarity and consistency across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset saved to: ../Dataset/preprocessed_sw_reviews_df.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the processed DataFrame to a new pickle file\n",
    "output_path = '../Dataset/preprocessed_sw_reviews_df.pkl'\n",
    "df_sw_processed.to_pickle(output_path)\n",
    "print(f\"Preprocessed dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Preprocessed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of cinema-related words to remove\n",
    "words_to_remove = [\n",
    "    \"actor\", \"actress\", \"artist\", \"author\", \"cast\", \"character\", \"cinema\", \"cinematography\", \n",
    "    \"director\", \"editing\", \"episode\", \"film\", \"filmmaker\", \"genre\", \"maker\", \"movie\", \n",
    "    \"opera\", \"producer\", \"production\", \"review\", \"reviewer\", \"saga\", \"scene\", \n",
    "    \"screen\", \"trilogy\", \"video\", \"visual\", \"voice\", \"writer\"\n",
    "]\n",
    "\n",
    "def clean_review_text(text, words_to_remove):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    # Match the word followed by exactly one space (optional)\n",
    "    pattern_with_space = r'\\b(' + '|'.join(re.escape(word) for word in words_to_remove) + r')\\b '\n",
    "    # Match the word alone (no space) — only if the one with space doesn't apply\n",
    "    pattern_alone = r'\\b(' + '|'.join(re.escape(word) for word in words_to_remove) + r')\\b'\n",
    "\n",
    "    # First, remove word + space (only if space is there)\n",
    "    text = re.sub(pattern_with_space, '', text, flags=re.IGNORECASE)\n",
    "    # Then remove remaining occurrences of the word if they are not followed by a space (e.g., end of text)\n",
    "    text = re.sub(pattern_alone + r'$', '', text, flags=re.IGNORECASE)  # word at end of string\n",
    "\n",
    "    # Clean multiple spaces, if any\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Preprocessed First Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Star Wars reviews: 100%|██████████| 36192/36192 [00:10<00:00, 3514.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the original dataset\n",
    "df_sw = pd.read_pickle(\"../Dataset/preprocessed_sw_reviews_df.pkl\")\n",
    "\n",
    "# Create a copy to clean\n",
    "df_sw_cleaned = df_sw.copy()\n",
    "\n",
    "# Clean the 'Processed_Review_Text' column in the copy\n",
    "tqdm.pandas(desc=\"Cleaning Star Wars reviews\")\n",
    "df_sw_cleaned[\"Processed_Review_Text\"] = df_sw_cleaned[\"Processed_Review_Text\"].progress_apply(\n",
    "    lambda x: clean_review_text(x, words_to_remove)\n",
    ")\n",
    "\n",
    "# Save the cleaned version\n",
    "df_sw_cleaned.to_pickle(\"../Dataset/custom_preprocessed_sw_reviews_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Preprocessed Second Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning others reviews: 100%|██████████| 15132/15132 [00:03<00:00, 4175.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the .pkl file\n",
    "df_others = pd.read_pickle(\"../Dataset/preprocessed_others_reviews_df.pkl\")\n",
    "\n",
    "# Create a copy to clean\n",
    "df_others_cleaned = df_others.copy()\n",
    "\n",
    "# Clean the 'Processed_Review_Text' column\n",
    "tqdm.pandas(desc=\"Cleaning others reviews\")\n",
    "df_others_cleaned[\"Processed_Review_Text\"] = df_others_cleaned[\"Processed_Review_Text\"].progress_apply(\n",
    "    lambda x: clean_review_text(x, words_to_remove)\n",
    ")\n",
    "\n",
    "# Save cleaned DataFrame to new .pkl files\n",
    "df_others_cleaned.to_pickle(\"../Dataset/custom_preprocessed_others_reviews_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test to verify if Costum worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset - Others Reviews\n",
      "Preprocessed: genuinely baffle film good foreign film good directing well screenwriting also good picture historically reserve american film film break barrier first choose self loathing end guess never long human alive always horde abysmally depressed people think hate humanity way world self righteous feel call joke film extremely well make story soulless intelligent critique capitalism egalitarianism meritocracy snob make seem point ultimate cliche play like weak melodramasoft noir movie weird film meander occasionally entertain good humor interesting situation hold brief suspense interesting part see korean culture cinema love visit time movie trash overall message movie life suck even try amaze director even reconcile conflict within sure try hard make great movie film try hard even   oscar one work hard decade gain knowledge skill able pull know fact make rich hate success ever try remain dreamer never strive great director really feel way success achievement never accept oscar donate money charity live destitute life hey life suck many people even try give break entire premise movie joke immature sad one must love movie   hour life waste\n",
      "Custom Preprocessed: genuinely baffle good foreign good directing well screenwriting also good picture historically reserve american break barrier first choose self loathing end guess never long human alive always horde abysmally depressed people think hate humanity way world self righteous feel call joke extremely well make story soulless intelligent critique capitalism egalitarianism meritocracy snob make seem point ultimate cliche play like weak melodramasoft noir weird meander occasionally entertain good humor interesting situation hold brief suspense interesting part see korean culture love visit time trash overall message life suck even try amaze even reconcile conflict within sure try hard make great try hard even oscar one work hard decade gain knowledge skill able pull know fact make rich hate success ever try remain dreamer never strive great really feel way success achievement never accept oscar donate money charity live destitute life hey life suck many people even try give break entire premise joke immature sad one must love hour life waste\n",
      "\n",
      "\n",
      "Dataset - Star Wars Reviews\n",
      "Preprocessed: long time ago first see star war watch part trilogy early eighty tv lucas cgi alter editsthere much add not already litter internet countless book become ingrained popular culture impossible watch fresh eye great see son watch first time doubt child enjoy toothe story dreamer luke skywalker must try save princess leia evil clutch darth vader could awful bmovie strength great bold script memorial character fantastic effect costume john williams timeless orchestral score princess laser alien creature spaceship good old fashioned tale good versus evil really not much likeit inspire filmmaker parody imitate numerous film book game change way scifi make remain timeless charming classicif ever see five film lifetime one\n",
      "Custom Preprocessed: long time ago first see star war watch part early eighty tv lucas cgi alter editsthere much add not already litter internet countless book become ingrained popular culture impossible watch fresh eye great see son watch first time doubt child enjoy toothe story dreamer luke skywalker must try save princess leia evil clutch darth vader could awful bmovie strength great bold script memorial fantastic effect costume john williams timeless orchestral score princess laser alien creature spaceship good old fashioned tale good versus evil really not much likeit inspire parody imitate numerous book game change way scifi make remain timeless charming classicif ever see five lifetime one\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original and cleaned DataFrames\n",
    "original_others = pd.read_pickle(\"../Dataset/preprocessed_others_reviews_df.pkl\")\n",
    "original_sw = pd.read_pickle(\"../Dataset/preprocessed_sw_reviews_df.pkl\")\n",
    "cleaned_others = pd.read_pickle(\"../Dataset/custom_preprocessed_others_reviews_df.pkl\")\n",
    "cleaned_sw = pd.read_pickle(\"../Dataset/custom_preprocessed_sw_reviews_df.pkl\")\n",
    "\n",
    "# Function to print a clean comparison for one matching review\n",
    "def print_clean_comparison(original_df, cleaned_df, dataset_name):\n",
    "    for idx, row in original_df.iterrows():\n",
    "        original_text = str(row[\"Processed_Review_Text\"])\n",
    "        if \"movie\" in original_text.lower():\n",
    "            # Get the cleaned text using iloc to ensure it's a single string (by row position)\n",
    "            cleaned_text = str(cleaned_df.iloc[idx][\"Processed_Review_Text\"])\n",
    "            print(f\"\\nDataset - {dataset_name}\")\n",
    "            print(f\"Preprocessed: {original_text}\")\n",
    "            print(f\"Custom Preprocessed: {cleaned_text}\\n\")\n",
    "            break\n",
    "\n",
    "# Run for both datasets\n",
    "print_clean_comparison(original_others, cleaned_others, \"Others Reviews\")\n",
    "print_clean_comparison(original_sw, cleaned_sw, \"Star Wars Reviews\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
