{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662213f8",
   "metadata": {},
   "source": [
    "# KeyBERT with Sentiment-aware Embedding Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d2118e",
   "metadata": {},
   "source": [
    "### Setup: Installing and Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "510ac332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keybert is already installed.\n",
      "Installing sentence-transformers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (3.3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (4.67.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/manuelemustari/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "transformers is already installed.\n",
      "torch is already installed.\n",
      "numpy is already installed.\n",
      "emoji is already installed.\n",
      "tqdm is already installed.\n",
      "vaderSentiment.vaderSentiment is already installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"keybert\", \"sentence-transformers\", \"transformers\", \"torch\", \"numpy\", \"emoji\", \"tqdm\",\n",
    "    \"vaderSentiment.vaderSentiment\"\n",
    "]\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip if it's not already installed.\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"{package} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Check and install missing packages\n",
    "for package in required_packages:\n",
    "    install_package(package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c140c4",
   "metadata": {},
   "source": [
    "# Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8677e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch neural network module â€” used to define the MLP that projects sentiment vectors\n",
    "import torch.nn as nn\n",
    "\n",
    "# SentenceTransformer is used to generate dense semantic embeddings for full documents or keywords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# HuggingFace Transformers: \n",
    "# - AutoTokenizer tokenizes input text for the sentiment model\n",
    "# - AutoModelForSequenceClassification runs the sentiment classification model (e.g., RoBERTa)\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# PyTorch's LayerNorm is used for normalizing the output of the MLP\n",
    "from torch.nn import LayerNorm \n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d9a454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentEmbedderVADER(nn.Module):\n",
    "    \"\"\"\n",
    "    Embedding model that fuses semantic embeddings with sentiment scores\n",
    "    computed entirely using VADER for both documents and candidate phrases.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    base_model : str\n",
    "        SentenceTransformer model name for semantic embeddings (default \"all-MiniLM-L6-v2\").\n",
    "\n",
    "    sentiment_mode : str\n",
    "        How to handle sentiment scores:\n",
    "        - \"linear\": use raw sentiment compound scores (scaled)\n",
    "        - \"nonlinear\": project sentiment scores with MLP to semantic space\n",
    "\n",
    "    combination_mode : str\n",
    "        How to combine semantic and sentiment embeddings:\n",
    "        - \"concat\", \"add\", \"nonlinear\"\n",
    "\n",
    "    beta : float\n",
    "        Scaling factor for sentiment influence.\n",
    "\n",
    "    device : str\n",
    "        Device for computation (\"cpu\" or \"cuda\").\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 base_model=\"all-MiniLM-L6-v2\",\n",
    "                 sentiment_mode=\"linear\",\n",
    "                 combination_mode=\"concat\",\n",
    "                 beta=0.5,\n",
    "                 device=\"cpu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.sentiment_mode = sentiment_mode\n",
    "        self.combination_mode = combination_mode\n",
    "        self.beta = beta\n",
    "\n",
    "        self.base = SentenceTransformer(base_model, device=device)\n",
    "        self.dim = self.base.get_sentence_embedding_dimension()\n",
    "\n",
    "        self.vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "        if sentiment_mode == \"nonlinear\":\n",
    "            self.sent_proj = nn.Sequential(\n",
    "                nn.Linear(1, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, self.dim),\n",
    "                nn.Tanh(),\n",
    "                nn.LayerNorm(self.dim)\n",
    "            ).to(device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_sentiment_score(self, texts):\n",
    "        \"\"\"\n",
    "        Compute sentiment compound score from VADER for a list of texts.\n",
    "\n",
    "        Returns tensor shape (batch_size, 1) normalized to [0,1] and scaled by beta.\n",
    "        \"\"\"\n",
    "        scores = [self.vader_analyzer.polarity_scores(t)['compound'] for t in texts]\n",
    "        norm_scores = [(s + 1) / 2 for s in scores]  # Normalize from [-1,1] to [0,1]\n",
    "        return torch.tensor(norm_scores, dtype=torch.float32, device=self.device).unsqueeze(1) * self.beta\n",
    "\n",
    "    def encode(self, texts, candidates=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Encode texts and optionally candidates with semantic + VADER sentiment embeddings.\n",
    "\n",
    "        Returns:\n",
    "            - If candidates is None: semantic + sentiment embeddings of texts\n",
    "            - Else: tuple (text embeddings, candidate embeddings)\n",
    "        \"\"\"\n",
    "\n",
    "        base_emb = self.base.encode(texts, convert_to_tensor=True, **kwargs).to(self.device)\n",
    "        doc_sent = self._get_sentiment_score(texts)  # shape (batch, 1)\n",
    "\n",
    "        if self.sentiment_mode == \"nonlinear\":\n",
    "            doc_sent_emb = self.sent_proj(doc_sent)\n",
    "        else:\n",
    "            doc_sent_emb = doc_sent\n",
    "\n",
    "        if candidates is None:\n",
    "            if self.sentiment_mode == \"linear\" and self.combination_mode == \"concat\":\n",
    "                return torch.cat([base_emb, doc_sent_emb], dim=1).cpu().numpy()\n",
    "            elif self.sentiment_mode == \"nonlinear\":\n",
    "                if self.combination_mode == \"add\":\n",
    "                    return (base_emb + doc_sent_emb).cpu().numpy()\n",
    "                elif self.combination_mode == \"nonlinear\":\n",
    "                    return (base_emb + doc_sent_emb + base_emb * doc_sent_emb).cpu().numpy()\n",
    "                elif self.combination_mode == \"concat\":\n",
    "                    return torch.cat([base_emb, doc_sent_emb], dim=1).cpu().numpy()\n",
    "            else:\n",
    "                return base_emb.cpu().numpy()\n",
    "\n",
    "        # Compute candidate embeddings + sentiment\n",
    "        cand_emb = self.base.encode(candidates, convert_to_tensor=True, **kwargs).to(self.device)\n",
    "        cand_sent = self._get_sentiment_score(candidates)\n",
    "\n",
    "        if self.sentiment_mode == \"nonlinear\":\n",
    "            cand_sent_emb = self.sent_proj(cand_sent)\n",
    "        else:\n",
    "            cand_sent_emb = cand_sent\n",
    "\n",
    "        if self.sentiment_mode == \"linear\" and self.combination_mode == \"concat\":\n",
    "            combined_cand_emb = torch.cat([cand_emb, cand_sent_emb], dim=1)\n",
    "        elif self.sentiment_mode == \"nonlinear\":\n",
    "            if self.combination_mode == \"add\":\n",
    "                combined_cand_emb = cand_emb + cand_sent_emb\n",
    "            elif self.combination_mode == \"nonlinear\":\n",
    "                combined_cand_emb = cand_emb + cand_sent_emb + cand_emb * cand_sent_emb\n",
    "            elif self.combination_mode == \"concat\":\n",
    "                combined_cand_emb = torch.cat([cand_emb, cand_sent_emb], dim=1)\n",
    "        else:\n",
    "            combined_cand_emb = cand_emb\n",
    "\n",
    "        return base_emb.cpu().numpy(), combined_cand_emb.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d991b",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1533b",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a98035fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b3dccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614721e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60b95ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DOCUMENT ===\n",
      "This film was absolutely amazing. The story was heartfelt, the acting superb, and the visuals breathtaking.\n",
      "\n",
      "=== BASE KeyBERT (semantic-only) ===\n",
      "breathtaking    score: 0.4218\n",
      "superb          score: 0.3783\n",
      "heartfelt       score: 0.3348\n",
      "film            score: 0.3296\n",
      "acting          score: 0.2912\n",
      "\n",
      "=== SENTIMENT-AWARE KeyBERT ===\n",
      "[sentiment_mode = 'linear', combination_mode = 'concat']\n",
      "breathtaking    score: 0.5335\n",
      "amazing         score: 0.4463\n",
      "superb          score: 0.4017\n",
      "film            score: 0.3563\n",
      "story           score: 0.2930\n",
      "\n",
      "[sentiment_mode = 'nonlinear', combination_mode = 'concat']\n",
      "breathtaking    score: 0.5335\n",
      "amazing         score: 0.4463\n",
      "superb          score: 0.4017\n",
      "film            score: 0.3563\n",
      "story           score: 0.2930\n",
      "\n",
      "[sentiment_mode = 'nonlinear', combination_mode = 'add']\n",
      "breathtaking    score: 0.5335\n",
      "amazing         score: 0.4463\n",
      "superb          score: 0.4017\n",
      "film            score: 0.3563\n",
      "story           score: 0.2930\n",
      "\n",
      "[sentiment_mode = 'nonlinear', combination_mode = 'nonlinear']\n",
      "breathtaking    score: 0.5335\n",
      "amazing         score: 0.4463\n",
      "superb          score: 0.4017\n",
      "film            score: 0.3563\n",
      "story           score: 0.2930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def compare_keyword_outputs(doc, top_n=5, beta=10.0, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Compare keyword extraction outputs between base KeyBERT and all sentiment-aware configurations.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=== DOCUMENT ===\")\n",
    "    print(doc)\n",
    "    print()\n",
    "\n",
    "    # Run KeyBERT base (semantic-only)\n",
    "    print(\"=== BASE KeyBERT (semantic-only) ===\")\n",
    "    base_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
    "    kw_base = KeyBERT(model=base_model)\n",
    "    keywords = kw_base.extract_keywords(doc, top_n=top_n)\n",
    "    for kw, score in keywords:\n",
    "        print(f\"{kw:15s} score: {score:.4f}\")\n",
    "    print()\n",
    "\n",
    "    # Define combinations to test\n",
    "    sentiment_modes = [\"linear\", \"nonlinear\"]\n",
    "    combination_modes = [\"concat\", \"add\", \"nonlinear\"]\n",
    "\n",
    "    print(\"=== SENTIMENT-AWARE KeyBERT ===\")\n",
    "    for sent_mode in sentiment_modes:\n",
    "        for comb_mode in combination_modes:\n",
    "\n",
    "            # Skip invalid: linear + add or nonlinear\n",
    "            if sent_mode == \"linear\" and comb_mode != \"concat\":\n",
    "                continue\n",
    "\n",
    "            print(f\"[sentiment_mode = '{sent_mode}', combination_mode = '{comb_mode}']\")\n",
    "\n",
    "            try:\n",
    "                # Instantiate SentimentEmbedder with VADER integration\n",
    "                sent_model = SentimentEmbedderVADER(\n",
    "                    sentiment_mode=sent_mode,\n",
    "                    combination_mode=comb_mode,\n",
    "                    beta=beta,\n",
    "                    device=device\n",
    "                )\n",
    "\n",
    "                kw_model = KeyBERT(model=sent_model)\n",
    "                keywords = kw_model.extract_keywords(doc, top_n=top_n)\n",
    "\n",
    "                for kw, score in keywords:\n",
    "                    print(f\"{kw:15s} score: {score:.4f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: {type(e).__name__}: {e}\")\n",
    "\n",
    "            print()\n",
    "\n",
    "# Example usage with your document:\n",
    "doc = \"This film was absolutely amazing. The story was heartfelt, the acting superb, and the visuals breathtaking.\"\n",
    "compare_keyword_outputs(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf9f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
